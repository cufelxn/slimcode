Set < String > allSelectedItems = getSelectedRows ( ) ; if ( allSelectedItems == null || allSelectedItems . isEmpty ( ) ) { return null ; } for ( String selectedItem : allSelectedItems ) { List < Integer > rowIndex = TreeItemUtil . rowIndexStringToList ( selectedItem ) ; return getTreeModel ( ) . getExampleData ( rowIndex ) ; } return null ; }<CODESPLIT>Get the example which is selected in the tree .
if ( ! mDimEnabled ) { return ; } if ( mDimView == null ) { mDimView = makeDimView ( ) ; } if ( ! mDimView . isShown ( ) ) { mDimView . setVisibility ( VISIBLE ) ; mDimView . setBackgroundColor ( mDimColor ) ; } mDimView . setAlpha ( alpha ) ; }<CODESPLIT>Set the dim - behind layer a specific opacity .
if ( isFound ( ) ) throw new IllegalStateException ( "Extract can only be called once" ) ; extractSW . start ( ) ; SPTEntry currEdge = sptEntry ; setEndNode ( currEdge . adjNode ) ; boolean nextEdgeValid = EdgeIterator . Edge . isValid ( currEdge . edge ) ; int nextEdge ; while ( nextEdgeValid ) { nextEdgeValid = EdgeIterator . Edge . isValid ( currEdge . parent . edge ) ; nextEdge = nextEdgeValid ? currEdge . parent . edge : EdgeIterator . NO_EDGE ; processEdge ( currEdge . edge , currEdge . adjNode , nextEdge ) ; currEdge = currEdge . parent ; } setFromNode ( currEdge . adjNode ) ; reverseOrder ( ) ; extractSW . stop ( ) ; return setFound ( true ) ; }<CODESPLIT>Extracts the Path from the shortest - path - tree determined by sptEntry .
target [ offset ] = ( byte ) ( value >>> 24 ) ; target [ offset + 1 ] = ( byte ) ( value >>> 16 ) ; target [ offset + 2 ] = ( byte ) ( value >>> 8 ) ; target [ offset + 3 ] = ( byte ) value ; return Integer . BYTES ; }<CODESPLIT>Writes the given 32 - bit Integer to the given byte array at the given offset .
validator . expectIndexMatch ( n , getJSType ( n . getFirstChild ( ) ) , getJSType ( n . getLastChild ( ) ) ) ; ensureTyped ( n ) ; }<CODESPLIT>Visits a GETELEM node .
if ( type instanceof Class ) { return ( ( Class ) type ) ; } else if ( type instanceof ParameterizedType ) { java . lang . reflect . Type rawParamterizedType = ( ( ParameterizedType ) type ) . getRawType ( ) ; return getTypedClass ( rawParamterizedType ) ; } else if ( type instanceof TypeVariable ) { java . lang . reflect . Type upperBound = ( ( TypeVariable ) type ) . getBounds ( ) [ 0 ] ; return getTypedClass ( upperBound ) ; } throw new IllegalArgumentException ( "Error while finding generic class for :" + type ) ; }<CODESPLIT>Gets the typed class .
fileStore . state ( ) . checkOpen ( ) ; return pathService . toUri ( uri , path . toAbsolutePath ( ) ) ; }<CODESPLIT>Gets the URI of the given path in this file system .
if ( activityInterface == null ) { activityInterface = new ActivityInterface ( apiKey , sharedSecret , transport ) ; } return activityInterface ; }<CODESPLIT>Get the ActivityInterface .
final List < ProcessAdvice > beforeRequestProcessAdvices = new ArrayList < > ( ) ; final Method invokeHolder = getInvokeHolder ( ) ; final Class < ? > processorClass = invokeHolder . getDeclaringClass ( ) ; if ( null != processorClass && processorClass . isAnnotationPresent ( Before . class ) ) { final Class < ? extends ProcessAdvice > [ ] bcs = processorClass . getAnnotation ( Before . class ) . value ( ) ; for ( int i = 0 ; i < bcs . length ; i ++ ) { final Class < ? extends ProcessAdvice > bc = bcs [ i ] ; final ProcessAdvice beforeRequestProcessAdvice = BeanManager . getInstance ( ) . getReference ( bc ) ; beforeRequestProcessAdvices . add ( beforeRequestProcessAdvice ) ; } } if ( invokeHolder . isAnnotationPresent ( Before . class ) ) { final Class < ? extends ProcessAdvice > [ ] bcs = invokeHolder . getAnnotation ( Before . class ) . value ( ) ; for ( int i = 0 ; i < bcs . length ; i ++ ) { final Class < ? extends ProcessAdvice > bc = bcs [ i ] ; final ProcessAdvice beforeRequestProcessAdvice = BeanManager . getInstance ( ) . getReference ( bc ) ; beforeRequestProcessAdvices . add ( beforeRequestProcessAdvice ) ; } } this . beforeRequestProcessAdvices = beforeRequestProcessAdvices ; }<CODESPLIT>Initializes before process advices .
jsFactory = new JsonFactory ( ) ; jsFactory . configure ( JsonParser . Feature . ALLOW_COMMENTS , true ) ; jsFactory . configure ( JsonParser . Feature . ALLOW_SINGLE_QUOTES , true ) ; jsFactory . configure ( JsonParser . Feature . ALLOW_NON_NUMERIC_NUMBERS , true ) ; }<CODESPLIT>Creates the JsonFactory .
handler     looper           sendMessageDelayed ( obtainMessage ( ) , THREAD_LEAK_CLEANING_MS ) ; } } ; handler . sendMessageDelayed ( handler . obtainMessage ( ) , THREAD_LEAK_CLEANING_MS ) ; }<CODESPLIT>Prior to Android 5 HandlerThread always keeps a stack local reference to the last message that was sent to it . This method makes sure that stack local reference never stays there for too long by sending new messages to it every second .
if ( buttons == null ) buttonsAtBottom ( ) ; Element e = new Input ( Input . Reset , "Reset" , label ) ; if ( extendRow ) addField ( null , e ) ; else buttons . add ( e ) ; }<CODESPLIT>Add a reset button .
return ( ( AudioManager ) context . getSystemService ( Context . AUDIO_SERVICE ) ) . getStreamMaxVolume ( AudioManager . STREAM_MUSIC ) ; }<CODESPLIT>Returns maximum volume the media volume can have
final ISREInstall defaultSRE = getDefaultSRE ( ) ; final String defaultId = defaultSRE == null ? null : defaultSRE . getId ( ) ; int defaultIndex = - 1 ; if ( defaultId != null ) { for ( int i = 0 ; defaultIndex == - 1 && i < this . sreTable . getItemCount ( ) ; ++ i ) { if ( defaultId . equals ( ( ( ISREInstall ) this . sreTable . getItem ( i ) . getData ( ) ) . getId ( ) ) ) { defaultIndex = i ; } } } final String normedDefaultId = Strings . nullToEmpty ( defaultId ) ; boolean defaultIsRemoved = false ; for ( final ISREInstall sre : sres ) { if ( this . sreArray . remove ( sre ) && sre . getId ( ) . equals ( normedDefaultId ) ) { defaultIsRemoved = true ; } } refreshSREListUI ( ) ; if ( defaultIsRemoved ) { if ( this . sreTable . getItemCount ( ) == 0 ) { setSelection ( null ) ; } else { if ( defaultIndex < 0 ) { defaultIndex = 0 ; } else if ( defaultIndex >= this . sreTable . getItemCount ( ) ) { defaultIndex = this . sreTable . getItemCount ( ) - 1 ; } setSelection ( new StructuredSelection ( this . sreTable . getItem ( defaultIndex ) . getData ( ) ) ) ; } } this . sresList . refresh ( true ) ; if ( defaultIsRemoved ) { fireDefaultSREChanged ( ) ; } updateUI ( ) ; }<CODESPLIT>Removes the given SREs from the table .
WikiUser result = null ; try { Properties props = getProperties ( wikiId ) ; result = new WikiUser ( ) ; result . setUsername ( props . getProperty ( "user" ) ) ; result . setEmail ( props . getProperty ( "email" ) ) ; Crypt pcf = new Crypt ( props . getProperty ( "cypher" ) , props . getProperty ( "salt" ) ) ; result . setPassword ( pcf . decrypt ( props . getProperty ( "secret" ) ) ) ; } catch ( FileNotFoundException e ) { String msg = help ( wikiId , siteurl ) ; LOGGER . log ( Level . SEVERE , msg ) ; } catch ( IOException e ) { LOGGER . log ( Level . SEVERE , e . getMessage ( ) ) ; } catch ( GeneralSecurityException e ) { LOGGER . log ( Level . SEVERE , e . getMessage ( ) ) ; } return result ; }<CODESPLIT>get the Wiki user for the given wikiid
int retryCount = 0 ; do { T next = delegate . next ( ) ; if ( ! alreadyGenerated . contains ( next ) ) { alreadyGenerated . add ( next ) ; return next ; } retryCount ++ ; } while ( retryCount <= numberOfRetries ) ; throw new IllegalStateException ( on ( " " ) . join ( "Exhausted" , numberOfRetries , "retries trying to generate unique value" ) ) ; }<CODESPLIT>Returns unique &lt ; T&gt ; generated by delegate Generator&lt ; T&gt ;
return ( node . getNodeType ( ) != Node . ELEMENT_NODE || node . getNodeName ( ) . equalsIgnoreCase ( TAG_LI ) ) && ( node . getNodeType ( ) != Node . TEXT_NODE || node . getNodeValue ( ) . trim ( ) . length ( ) == 0 ) ; }<CODESPLIT>Checks if a given node is allowed or not as a child of a &lt ; ul&gt ; or &lt ; ol&gt ; element .
Map < Integer , Group > atomIndexPosition = new HashMap < Integer , Group > ( ) ; ProteinSequence structSeq = getProteinSequenceForStructure ( struct , atomIndexPosition ) ; SubstitutionMatrix < AminoAcidCompound > matrix = new SimpleSubstitutionMatrix < AminoAcidCompound > ( AminoAcidCompoundSet . getAminoAcidCompoundSet ( ) , ( short ) 1 , ( short ) - 1 ) ; matrix = new SimpleSubstitutionMatrix < AminoAcidCompound > ( AminoAcidCompoundSet . getAminoAcidCompoundSet ( ) , new InputStreamReader ( SimpleSubstitutionMatrix . class . getResourceAsStream ( "/matrices/blosum100.txt" ) ) , "blosum100" ) ; SequencePair < ProteinSequence , AminoAcidCompound > pair = Alignments . getPairwiseAlignment ( seq , structSeq , PairwiseSequenceAlignerType . GLOBAL , new SimpleGapPenalty ( ) , matrix ) ; AlignedSequence < ProteinSequence , AminoAcidCompound > alignedSeq = pair . getQuery ( ) ; AlignedSequence < ProteinSequence , AminoAcidCompound > alignedStruct = pair . getTarget ( ) ; assert ( alignedSeq . getLength ( ) == alignedStruct . getLength ( ) ) ; ResidueNumber [ ] ca = new ResidueNumber [ seq . getLength ( ) ] ; for ( int pos = alignedSeq . getStart ( ) . getPosition ( ) ; pos <= alignedSeq . getEnd ( ) . getPosition ( ) ; pos ++ ) { if ( alignedSeq . isGap ( pos ) ) { int structIndex = alignedStruct . getSequenceIndexAt ( pos ) - 1 ; assert ( structIndex > 0 ) ; Group g = atomIndexPosition . get ( structIndex ) ; logger . warn ( "Chain {} residue {} in the Structure {} has no corresponding amino acid in the sequence." , g . getChainId ( ) , g . getResidueNumber ( ) . toString ( ) , g . getChain ( ) . getStructure ( ) . getPDBCode ( ) ) ; continue ; } if ( ! alignedStruct . isGap ( pos ) ) { int seqIndex = alignedSeq . getSequenceIndexAt ( pos ) - 1 ; int structIndex = alignedStruct . getSequenceIndexAt ( pos ) - 1 ; Group g = atomIndexPosition . get ( structIndex ) ; assert ( 0 <= seqIndex && seqIndex < ca . length ) ; ca [ seqIndex ] = g . getResidueNumber ( ) ; } } return ca ; }<CODESPLIT>Given a sequence and the corresponding Structure get the ResidueNumber for each residue in the sequence .
"unchecked" } ) public static IMeta mergeMeta ( IMetaData < ? , ? > metaData1 , IMetaData < ? , ? > metaData2 ) { Map < String , Object > map1 = ( ( Map < String , Object > ) metaData1 ) ; Set < Entry < String , Object > > set1 = map1 . entrySet ( ) ; Map < String , Object > map2 = ( ( Map < String , Object > ) metaData2 ) ; Set < Entry < String , Object > > set2 = map2 . entrySet ( ) ; Map < String , Object > rep = new HashMap < String , Object > ( ) ; for ( Entry < String , Object > entry1 : set1 ) { String key1 = entry1 . getKey ( ) ; if ( map2 . containsKey ( key1 ) ) { Object value1 = map1 . get ( key1 ) ; Object value2 = map2 . get ( key1 ) ; if ( value1 instanceof Double ) { if ( Double . valueOf ( value1 . toString ( ) ) . doubleValue ( ) < Double . valueOf ( value2 . toString ( ) ) . doubleValue ( ) ) { rep . put ( key1 , value2 ) ; } } else if ( value1 instanceof Integer ) { if ( Integer . valueOf ( value1 . toString ( ) ) . intValue ( ) < Integer . valueOf ( value2 . toString ( ) ) . intValue ( ) ) { rep . put ( key1 , value2 ) ; } } else if ( value1 instanceof Long ) { if ( Long . valueOf ( value1 . toString ( ) ) . longValue ( ) < Long . valueOf ( value2 . toString ( ) ) . longValue ( ) ) { rep . put ( key1 , value2 ) ; } } if ( value1 instanceof Boolean ) { if ( ! Boolean . valueOf ( value1 . toString ( ) ) && Boolean . valueOf ( value2 . toString ( ) ) ) { rep . put ( key1 , value2 ) ; } } } } set1 . removeAll ( rep . entrySet ( ) ) ; set1 . addAll ( rep . entrySet ( ) ) ; set1 . addAll ( set2 ) ; return metaData1 ; }<CODESPLIT>Merges the two Meta objects
while ( allResults . size ( ) < arg1 && nextResultsAvailable ( ) ) { moveNextResults ( ) ; } return Collections . unmodifiableList ( allResults . subList ( arg0 , arg1 ) ) ; }<CODESPLIT>Returns a sub - list in the range specified loading more results as necessary .
message . setMetadata ( "cwf.pub.node" , nodeId ) ; message . setMetadata ( "cwf.pub.channel" , channel ) ; message . setMetadata ( "cwf.pub.event" , UUID . randomUUID ( ) . toString ( ) ) ; message . setMetadata ( "cwf.pub.when" , System . currentTimeMillis ( ) ) ; message . setMetadata ( "cwf.pub.recipients" , recipients ) ; return message ; }<CODESPLIT>Adds publication - specific metadata to the message .
this . checkForBatchExecution ( ) ; GraphRequest < T > req = new GraphRequest < T > ( object , params , this . mapper , this . < T > createMappingChain ( type ) ) ; this . graphRequests . add ( req ) ; return req ; }<CODESPLIT>The actual implementation of this after we ve converted to proper Jackson JavaType
if ( length < 251 ) { buf [ position ++ ] = ( byte ) length ; } else if ( length < 65536 ) { buf [ position ++ ] = ( byte ) 0xfc ; buf [ position ++ ] = ( byte ) length ; buf [ position ++ ] = ( byte ) ( length >>> 8 ) ; } else if ( length < 16777216 ) { buf [ position ++ ] = ( byte ) 0xfd ; buf [ position ++ ] = ( byte ) length ; buf [ position ++ ] = ( byte ) ( length >>> 8 ) ; buf [ position ++ ] = ( byte ) ( length >>> 16 ) ; } else { buf [ position ++ ] = ( byte ) 0xfe ; buf [ position ++ ] = ( byte ) length ; buf [ position ++ ] = ( byte ) ( length >>> 8 ) ; buf [ position ++ ] = ( byte ) ( length >>> 16 ) ; buf [ position ++ ] = ( byte ) ( length >>> 24 ) ; buf [ position ++ ] = ( byte ) ( length >>> 32 ) ; buf [ position ++ ] = ( byte ) ( length >>> 40 ) ; buf [ position ++ ] = ( byte ) ( length >>> 48 ) ; buf [ position ++ ] = ( byte ) ( length >>> 54 ) ; } }<CODESPLIT>Write length .
if ( isEmpty ( items ) ) { return new ArrayList < > ( ) ; } List < TResult > result = new ArrayList < > ( items . size ( ) ) ; for ( TSource item : items ) { TResult mappedItem = mapper . map ( item ) ; result . add ( mappedItem ) ; } return result ; }<CODESPLIT>Projects each element of a collection into a new collection .
serializeElement ( "real" , String . valueOf ( real . doubleValue ( ) ) , handler ) ; }<CODESPLIT>Serialize a Number as a real element .
application  BaseApplet . getSharedInstance ( ) . getApplication ( )   oldResources  application . getResourceBundle ( )  application . getResources ( null , true )  this . setupActions ( targetAction )   menuBar                     return new Dimension ( super . getMaximumSize ( ) . width , super . getPreferredSize ( ) . height ) ; } } ; menuBar . setOpaque ( false ) ; JMenu menu ; char [ ] rgchItemShortcuts = new char [ 20 ] ; menu = this . addMenu ( menuBar , ThinMenuConstants . FILE ) ; this . addMenuItem ( menu , ThinMenuConstants . PRINT , rgchItemShortcuts ) ; menu . addSeparator ( ) ; this . addMenuItem ( menu , ThinMenuConstants . LOGON , rgchItemShortcuts ) ; this . addMenuItem ( menu , ThinMenuConstants . LOGOUT , rgchItemShortcuts ) ; this . addMenuItem ( menu , ThinMenuConstants . CHANGE_PASSWORD , rgchItemShortcuts ) ; menu . addSeparator ( ) ; this . addMenuItem ( menu , ThinMenuConstants . CLOSE , rgchItemShortcuts ) ; rgchItemShortcuts = new char [ 20 ] ; menu = this . addMenu ( menuBar , ThinMenuConstants . EDIT ) ; this . addMenuItem ( menu , ThinMenuConstants . CUT , rgchItemShortcuts ) ; this . addMenuItem ( menu , ThinMenuConstants . COPY , rgchItemShortcuts ) ; this . addMenuItem ( menu , ThinMenuConstants . PASTE , rgchItemShortcuts ) ; menu . addSeparator ( ) ; this . addMenuItem ( menu , ThinMenuConstants . PREFERENCES , rgchItemShortcuts ) ; if ( oldResources != null ) application . setResourceBundle ( oldResources ) ; if ( bAddHelpMenu ) menu = this . addHelpMenu ( menuBar ) ; return menuBar ; }<CODESPLIT>Setup the standard menu items .
final Preferences prefs = Preferences . userNodeForPackage ( RoadNetworkConstants . class ) ; if ( prefs != null ) { return prefs . get ( "LANE_COUNT_ATTR_NAME" , DEFAULT_ATTR_LANE_COUNT ) ; } return DEFAULT_ATTR_LANE_COUNT ; }<CODESPLIT>Replies the preferred name for the number of lanes of the roads .
nsrollbackcmd obj = new nsrollbackcmd ( ) ; options option = new options ( ) ; option . set_args ( nitro_util . object_to_string_withoutquotes ( args ) ) ; nsrollbackcmd [ ] response = ( nsrollbackcmd [ ] ) obj . get_resources ( service , option ) ; return response ; }<CODESPLIT>Use this API to fetch all the nsrollbackcmd resources that are configured on netscaler . This uses nsrollbackcmd_args which is a way to provide additional arguments while fetching the resources .
if ( ! useList || i < 0 ) { return i ; } int j = 0 ; PatternRule rule = ( PatternRule ) this . rule ; for ( int k = 0 ; k < i ; k ++ ) { j += rule . getElementNo ( ) . get ( k ) ; } return j ; }<CODESPLIT>Gets the index of the element indexed by i adding any offsets because of the phrases in the rule .
if ( _proxyHostsWhiteList == null || _proxyHostsWhiteList . size ( ) == 0 ) return new String [ 0 ] ; String [ ] hosts = new String [ _proxyHostsWhiteList . size ( ) ] ; hosts = ( String [ ] ) _proxyHostsWhiteList . toArray ( hosts ) ; return hosts ; }<CODESPLIT>Get proxy host white list .
if ( this . metatypeAds == null ) this . metatypeAds = new LinkedList < MetatypeAd > ( ) ; for ( MetatypeAd ad : metatypeAds ) if ( ad . getID ( ) . equals ( metatypeAd . getID ( ) ) ) return false ; this . metatypeAds . add ( metatypeAd ) ; return true ; }<CODESPLIT>Adds a metatype AD .
if ( mInputStream . available ( ) >= n ) { return mInputStream . skip ( n ) ; } mInputStream . close ( ) ; mPos += n ; try { mObject = mClient . getObject ( mBucketName , mKey , null , null , null , null , mPos , null ) ; mInputStream = new BufferedInputStream ( mObject . getDataInputStream ( ) ) ; } catch ( ServiceException e ) { throw new IOException ( e ) ; } return n ; }<CODESPLIT>This method leverages the ability to open a stream from GCS from a given offset . When the underlying stream has fewer bytes buffered than the skip request the stream is closed and a new stream is opened starting at the requested offset .
Name name = calledMethodName ( tree ) ; if ( name != null ) { Names names = name . table . names ; return name == names . _super ; } else { return false ; } }<CODESPLIT>Is this a call to super?
StringBuilder dump = new StringBuilder ( ) ; dump . append ( "Timestamp : " ) . append ( ISO8601 . getTimestamp ( ) ) . append ( "\n" ) ; dump . append ( "fromMethod : " ) . append ( fromMethod ) . append ( "\n" ) ; dump . append ( "Method : " ) . append ( request . getMethod ( ) ) . append ( '\n' ) ; dump . append ( "Scheme : " ) . append ( request . getScheme ( ) ) . append ( '\n' ) ; dump . append ( "URI : " ) . append ( request . getRequestURI ( ) ) . append ( '\n' ) ; dump . append ( "Query-String : " ) . append ( request . getQueryString ( ) ) . append ( '\n' ) ; dump . append ( "Auth-Type : " ) . append ( request . getAuthType ( ) ) . append ( '\n' ) ; dump . append ( "Remote-Addr : " ) . append ( request . getRemoteAddr ( ) ) . append ( '\n' ) ; dump . append ( "Scheme : " ) . append ( request . getScheme ( ) ) . append ( '\n' ) ; dump . append ( "Content-Type : " ) . append ( request . getContentType ( ) ) . append ( '\n' ) ; dump . append ( "Content-Length: " ) . append ( request . getContentLength ( ) ) . append ( '\n' ) ; if ( includeHeaders ) { dump . append ( "Headers :\n" ) ; Enumeration < String > headers = request . getHeaderNames ( ) ; while ( headers . hasMoreElements ( ) ) { String header = headers . nextElement ( ) ; dump . append ( "\t" ) . append ( header ) . append ( ": " ) . append ( request . getHeader ( header ) ) . append ( '\n' ) ; } } return ( dump . toString ( ) ) ; }<CODESPLIT>Build a String containing a short multi - line dump of an HTTP request .
validateNotNull ( stringToCheck , argumentName ) ; if ( stringToCheck . length ( ) == 0 || ( trim && stringToCheck . trim ( ) . length ( ) == 0 ) ) { throw new NullArgumentException ( argumentName + IS_EMPTY ) ; } }<CODESPLIT>Validates that the string is not null and not an empty string .
JPanel _panel = new JPanel ( ) ; _panel . setLayout ( new BoxLayout ( _panel , BoxLayout . Y_AXIS ) ) ; return _panel ; }<CODESPLIT>Create a panel that lays out components vertically .
if ( analyzer instanceof FileTypeAnalyzer ) { final FileTypeAnalyzer fileTypeAnalyzer = ( FileTypeAnalyzer ) analyzer ; return fileTypeAnalyzer . accept ( dependency . getActualFile ( ) ) ; } return true ; }<CODESPLIT>Determines if the analyzer can analyze the given dependency .
registeredServiceClasses . put ( serviceClass . getSimpleName ( ) , serviceClass ) ; Settings . Services . addAvailableOption ( serviceClass . getSimpleName ( ) ) ; }<CODESPLIT>Registers a service enabling the service layer to automatically start autorun servies .
String result = this . getPageContent ( pageTitle , "&rvsection=" + sectionNumber , false ) ; return result ; }<CODESPLIT>get the text for the given section
if ( x . length != y . length ) throw new IllegalArgumentException ( String . format ( "Arrays have different length: x[%d], y[%d]" , x . length , y . length ) ) ; return 1 - Math . cor ( x , y ) ; }<CODESPLIT>Pearson correlation distance between the two arrays of type int .
Projection projection = ProjectionFactory . getProjection ( ProjectionConstants . EPSG_WORLD_GEODETIC_SYSTEM ) ; return getTileGrid ( point , zoom , projection ) ; }<CODESPLIT>Get the tile grid for the location specified as WGS84
ArrayList < VectorLayer > list = new ArrayList < VectorLayer > ( ) ; for ( Layer < ? > layer : layers ) { if ( layer instanceof VectorLayer ) { list . add ( ( VectorLayer ) layer ) ; } } return list ; }<CODESPLIT>Return a list containing all vector layers within this model .
if ( centered ) { innerProduct ( y , x ) ; } else { xref = CalcPoint . clonePoint3dArray ( x ) ; xtrans = CalcPoint . centroid ( xref ) ; logger . debug ( "x centroid: " + xtrans ) ; xtrans . negate ( ) ; CalcPoint . translate ( new Vector3d ( xtrans ) , xref ) ; yref = CalcPoint . clonePoint3dArray ( y ) ; ytrans = CalcPoint . centroid ( yref ) ; logger . debug ( "y centroid: " + ytrans ) ; ytrans . negate ( ) ; CalcPoint . translate ( new Vector3d ( ytrans ) , yref ) ; innerProduct ( yref , xref ) ; } calcRmsd ( wsum ) ; }<CODESPLIT>Calculates the RMSD value for superposition of y onto x . This requires the coordinates to be precentered .
if ( Section_Type . featOkTst && ( ( Section_Type ) jcasType ) . casFeat_sectionHeading == null ) jcasType . jcas . throwFeatMissing ( "sectionHeading" , "de.julielab.jules.types.Section" ) ; jcasType . ll_cas . ll_setRefValue ( addr , ( ( Section_Type ) jcasType ) . casFeatCode_sectionHeading , jcasType . ll_cas . ll_getFSRef ( v ) ) ; }<CODESPLIT>setter for sectionHeading - sets the title of the section
SxmpParser parser = new SxmpParser ( version ) ; Operation operation = null ; try { operation = parser . parse ( is ) ; } catch ( SxmpParsingException e ) { if ( e . getOperation ( ) != null && e . getOperation ( ) . getType ( ) != null ) { logger . warn ( "Unable to fully parse XML into a request, returning ErrorResponse; error: " + e . getMessage ( ) + ", parsed: " + e . getOperation ( ) ) ; return new ErrorResponse ( e . getOperation ( ) . getType ( ) , e . getErrorCode ( ) . getIntValue ( ) , e . getErrorMessage ( ) ) ; } else { throw new SAXException ( e . getMessage ( ) , e ) ; } } try { if ( ! ( operation instanceof Request ) ) { throw new SxmpErrorException ( SxmpErrorCode . UNSUPPORTED_OPERATION , "A session can only process requests" ) ; } Request req = ( Request ) operation ; if ( req . getAccount ( ) == null ) { throw new SxmpErrorException ( SxmpErrorCode . MISSING_REQUIRED_ELEMENT , "A request must include account credentials" ) ; } if ( ! processor . authenticate ( req . getAccount ( ) ) ) { throw new SxmpErrorException ( SxmpErrorCode . AUTHENTICATION_FAILURE , "Authentication failure" ) ; } if ( operation instanceof SubmitRequest ) { return processor . submit ( req . getAccount ( ) , ( SubmitRequest ) operation ) ; } else if ( operation instanceof DeliverRequest ) { return processor . deliver ( req . getAccount ( ) , ( DeliverRequest ) operation ) ; } else if ( operation instanceof DeliveryReportRequest ) { return processor . deliveryReport ( req . getAccount ( ) , ( DeliveryReportRequest ) operation ) ; } else { throw new SxmpErrorException ( SxmpErrorCode . UNSUPPORTED_OPERATION , "Unsupported operation request type" ) ; } } catch ( SxmpErrorException e ) { logger . warn ( e . getMessage ( ) ) ; return new ErrorResponse ( operation . getType ( ) , e . getErrorCode ( ) . getIntValue ( ) , e . getErrorMessage ( ) ) ; } catch ( Throwable t ) { logger . error ( "Major uncaught throwable while processing request, generating an ErrorResponse" , t ) ; return new ErrorResponse ( operation . getType ( ) , SxmpErrorCode . GENERIC . getIntValue ( ) , "Generic error while processing request" ) ; } }<CODESPLIT>Processes an InputStream that contains a request . Does its best to only produce a Response that can be written to an OutputStream . Any exception this method throws should be treated as fatal and no attempt should be made to print out valid XML as a response .
if ( redirectUrls . contains ( url ) ) { throw new PushSenderException ( "The site contains an infinite redirect loop! Duplicate url: " + url ) ; } else { redirectUrls . add ( url ) ; } HttpURLConnection httpURLConnection = null ; try { final String credentials = pushApplicationId + ':' + masterSecret ; final String encoded = Base64 . encodeBytes ( credentials . getBytes ( UTF_8 ) ) ; httpURLConnection = ( HttpURLConnection ) HttpRequestUtil . post ( url , encoded , jsonPayloadObject , UTF_8 , proxy , customTrustStore , connectionSettings ) ; final int statusCode = httpURLConnection . getResponseCode ( ) ; logger . log ( Level . INFO , String . format ( "HTTP Response code from UnifiedPush Server: %s" , statusCode ) ) ; if ( isRedirect ( statusCode ) ) { String redirectURL = httpURLConnection . getHeaderField ( "Location" ) ; logger . log ( Level . INFO , String . format ( "Performing redirect to '%s'" , redirectURL ) ) ; submitPayload ( redirectURL , pushConfiguration . getConnectionSettings ( ) , jsonPayloadObject , pushApplicationId , masterSecret , callback , redirectUrls ) ; } else if ( statusCode >= 400 ) { logger . log ( Level . SEVERE , "The Unified Push Server returned status code: " + statusCode ) ; throw new PushSenderHttpException ( statusCode ) ; } else { if ( callback != null ) { callback . onComplete ( ) ; } } } catch ( PushSenderHttpException pshe ) { throw pshe ; } catch ( Exception e ) { logger . log ( Level . INFO , "Error happening while trying to send the push delivery request" , e ) ; throw new PushSenderException ( e . getMessage ( ) , e ) ; } finally { if ( httpURLConnection != null ) { httpURLConnection . disconnect ( ) ; } } }<CODESPLIT>The actual method that does the real send and connection handling
if ( children == null || children . size ( ) == 0 ) return EMPTY_NAMES ; String [ ] arr = new String [ children . size ( ) ] ; for ( int i = 0 ; i < arr . length ; i ++ ) { arr [ i ] = ( ( RamResourceCore ) children . get ( i ) ) . getName ( ) ; } return arr ; }<CODESPLIT>Gibt den Feldnamen children zurueck .
Interpreter . debug ( "getIndex: " , array , ", index=" , index ) ; try { if ( array instanceof List ) return ( ( List < ? > ) array ) . get ( index ) ; Object val = Array . get ( array , index ) ; return Primitive . wrap ( val , Types . arrayElementType ( array . getClass ( ) ) ) ; } catch ( IndexOutOfBoundsException e1 ) { int len = array instanceof List ? ( ( List < ? > ) array ) . size ( ) : Array . getLength ( array ) ; throw new UtilTargetError ( "Index " + index + " out-of-bounds for length " + len , e1 ) ; } }<CODESPLIT>Get object from array or list at index .
aaakcdaccount addresource = new aaakcdaccount ( ) ; addresource . kcdaccount = resource . kcdaccount ; addresource . keytab = resource . keytab ; addresource . realmstr = resource . realmstr ; addresource . delegateduser = resource . delegateduser ; addresource . kcdpassword = resource . kcdpassword ; addresource . usercert = resource . usercert ; addresource . cacert = resource . cacert ; return addresource . add_resource ( client ) ; }<CODESPLIT>Use this API to add aaakcdaccount .
if ( TraceComponent . isAnyTracingEnabled ( ) && tc . isEntryEnabled ( ) ) SibTr . entry ( this , tc , "lockExclusive" , this ) ; boolean interrupted = false ; while ( ! tryLockExclusive ( ) ) { try { if ( TraceComponent . isAnyTracingEnabled ( ) && tc . isDebugEnabled ( ) ) SibTr . debug ( this , tc , "Waiting to get exclusive lock" ) ; wait ( 1000 ) ; } catch ( InterruptedException e ) { interrupted = true ; } } while ( iLockCount > 0 ) { try { if ( TraceComponent . isAnyTracingEnabled ( ) && tc . isDebugEnabled ( ) ) SibTr . debug ( this , tc , "Waiting for lock count to reach 0 " + iLockCount ) ; wait ( 1000 ) ; } catch ( InterruptedException e ) { interrupted = true ; } } if ( interrupted ) { Thread . currentThread ( ) . interrupt ( ) ; } if ( TraceComponent . isAnyTracingEnabled ( ) && tc . isEntryEnabled ( ) ) SibTr . exit ( this , tc , "lockExclusive" ) ; }<CODESPLIT>This method locks the mutex so no other lockers can get the lock .
this . cpOptionValueLocalService = cpOptionValueLocalService ; }<CODESPLIT>Sets the cp option value local service .
PackageDeclaration pkg = type . getPackage ( ) ; return pkg != null ? '/' + pkg . getQualifiedName ( ) . replace ( '.' , '/' ) : "/" ; }<CODESPLIT>Infers the Struts module path from the given controller class .
int [ ] leapMonths = this . getLeapMonths ( ) ; int elapsedYears = ( cycle - 1 ) * 60 + yearOfCycle - 1 ; int index = 2 * ( ( elapsedYears - leapMonths [ 0 ] ) / 3 ) ; int lm = 0 ; while ( ( index < leapMonths . length ) ) { int test = leapMonths [ index ] ; if ( test < elapsedYears ) { index += Math . max ( 2 * ( ( elapsedYears - test ) / 3 ) , 2 ) ; } else if ( test > elapsedYears ) { break ; } else { lm = leapMonths [ index + 1 ] ; break ; } } return lm ; }<CODESPLIT>number of leap month or zero if no leap year
if ( snippetId == null ) { throw new RuntimeException ( "snippetId can't be null" ) ; } Response response = get ( Response . Status . OK , null , "snippets" , snippetId ) ; Snippet snippet = response . readEntity ( Snippet . class ) ; if ( downloadContent ) { snippet . setContent ( getSnippetContent ( snippet . getId ( ) ) ) ; } return snippet ; }<CODESPLIT>Get a specific Snippet .
int value ; int ix ; if ( codePoint >= 0 ) { if ( codePoint < 0x0d800 || ( codePoint > 0x0dbff && codePoint <= 0x0ffff ) ) { ix = index [ codePoint >> UTRIE2_SHIFT_2 ] ; ix = ( ix << UTRIE2_INDEX_SHIFT ) + ( codePoint & UTRIE2_DATA_MASK ) ; value = data32 [ ix ] ; return value ; } if ( codePoint <= 0xffff ) { ix = index [ UTRIE2_LSCP_INDEX_2_OFFSET + ( ( codePoint - 0xd800 ) >> UTRIE2_SHIFT_2 ) ] ; ix = ( ix << UTRIE2_INDEX_SHIFT ) + ( codePoint & UTRIE2_DATA_MASK ) ; value = data32 [ ix ] ; return value ; } if ( codePoint < highStart ) { ix = ( UTRIE2_INDEX_1_OFFSET - UTRIE2_OMITTED_BMP_INDEX_1_LENGTH ) + ( codePoint >> UTRIE2_SHIFT_1 ) ; ix = index [ ix ] ; ix += ( codePoint >> UTRIE2_SHIFT_2 ) & UTRIE2_INDEX_2_MASK ; ix = index [ ix ] ; ix = ( ix << UTRIE2_INDEX_SHIFT ) + ( codePoint & UTRIE2_DATA_MASK ) ; value = data32 [ ix ] ; return value ; } if ( codePoint <= 0x10ffff ) { value = data32 [ highValueIndex ] ; return value ; } } return errorValue ; }<CODESPLIT>Get the value for a code point as stored in the Trie2 .
MBeanServer server = getMBeanServer ( ) ; ObjectName objName = new ObjectName ( name ) ; return server . getAttribute ( objName , attrName ) ; }<CODESPLIT>Get MBean attribute object
if  items . size ( ) <= selectedIndex || selectedIndex < - 1             selectedIndex      oldSelection          selectedIndex  if  selectedIndex == - 1   updateText ( "" )   else  updateText ( items . get ( selectedIndex ) . toString ( ) )   runOnGUIThreadIfExistsOtherwiseRunDirect ( new Runnable ( ) { public void run ( ) { for ( Listener listener : listeners ) { listener . onSelectionChanged ( selectedIndex , oldSelection ) ; } } } ) ; invalidate ( ) ; }<CODESPLIT>Programmatically selects one item in the combo box which causes the displayed text to change to match the label of the selected index .
return getStats ( METHOD_GET_PHOTO_STATS , "photo_id" , photoId , date ) ; }<CODESPLIT>Get the number of views comments and favorites on a photo for a given date .
Validator . notNull ( getDocumentStatusOptions , "getDocumentStatusOptions cannot be null" ) ; String [ ] pathSegments = { "v1/environments" , "collections" , "documents" } ; String [ ] pathParameters = { getDocumentStatusOptions . environmentId ( ) , getDocumentStatusOptions . collectionId ( ) , getDocumentStatusOptions . documentId ( ) } ; RequestBuilder builder = RequestBuilder . get ( RequestBuilder . constructHttpUrl ( getEndPoint ( ) , pathSegments , pathParameters ) ) ; builder . query ( "version" , versionDate ) ; Map < String , String > sdkHeaders = SdkCommon . getSdkHeaders ( "discovery" , "v1" , "getDocumentStatus" ) ; for ( Entry < String , String > header : sdkHeaders . entrySet ( ) ) { builder . header ( header . getKey ( ) , header . getValue ( ) ) ; } builder . header ( "Accept" , "application/json" ) ; return createServiceCall ( builder . build ( ) , ResponseConverterUtils . getObject ( DocumentStatus . class ) ) ; }<CODESPLIT>Get document details .
return new Pager < Issue > ( this , Issue . class , itemsPerPage , null , "projects" , getProjectIdOrPath ( projectIdOrPath ) , "merge_requests" , mergeRequestIid , "closes_issues" ) ; }<CODESPLIT>Get a Pager containing all the issues that would be closed by merging the provided merge request .
if ( DEBUG ) { String exceptionStr = "" ; if ( e != null && e . length == 1 ) { StringWriter sw = new StringWriter ( ) ; PrintWriter pw = new PrintWriter ( sw ) ; e [ 0 ] . printStackTrace ( pw ) ; pw . flush ( ) ; exceptionStr = "exception = " + sw . toString ( ) ; } System . err . println ( "[" + sSdf . format ( new Date ( ) ) + "]" + "-" + "[" + clazz . getSimpleName ( ) + "] " + msg + " " + exceptionStr ) ; } }<CODESPLIT>To output the error log message to the error out
HtmlTree htmltree = new HtmlTree ( HtmlTag . TH , nullCheck ( body ) ) ; if ( styleClass != null ) htmltree . addStyle ( styleClass ) ; htmltree . addAttr ( HtmlAttr . SCOPE , nullCheck ( scope ) ) ; return htmltree ; }<CODESPLIT>Generates a TH tag with style class and scope attributes and some content .
TypedArray typedArray = getContext ( ) . getTheme ( ) . obtainStyledAttributes ( themeResourceId , new int [ ] { R . attr . materialDialogDividerMargin } ) ; setDividerMargin ( typedArray . getDimensionPixelSize ( 0 , 0 ) ) ; }<CODESPLIT>Obtains the left and right margin of dividers from a specific theme .
this . getScreenFieldView ( ) . setDefaultButton ( button == null ? null : button . getScreenFieldView ( ) ) ; }<CODESPLIT>Set the default button for this basepanel .
if ( k < 0 || k >= size ( root ) ) throw new IllegalArgumentException ( ) ; RedBlackTreeNode < Key , Value > x = select ( root , k ) ; return x . getKey ( ) ; }<CODESPLIT>Return the kth smallest key in the symbol table .
lock . writeLock ( ) . lock ( ) ; try { newSessionRequests . add ( request ) ; } finally { lock . writeLock ( ) . unlock ( ) ; } }<CODESPLIT>Adds a request handler to this queue .
return withWriter ( newPrintWriter ( stream ) , closure ) ; }<CODESPLIT>Create a new PrintWriter for this OutputStream . The writer is passed to the closure and will be closed before this method returns .
addRoute ( new Route ( urlPattern , true ) , actorClass ) ; }<CODESPLIT>Add a URL pattern to the routing table .
if ( ! isActive ) { handleLibraryInactive ( callback ) ; return ; } if ( project == null && defaultProject == null ) { handleFailure ( null , new IllegalStateException ( "No project specified, but no default project found" ) ) ; return ; } if ( ! isNetworkConnected ( ) ) { KeenLogging . log ( "Not sending events because there is no network connection. " + "Events will be retried next time `sendQueuedEvents` is called." ) ; handleFailure ( callback , new Exception ( "Network not connected." ) ) ; return ; } KeenProject useProject = ( project == null ? defaultProject : project ) ; try { String projectId = useProject . getProjectId ( ) ; Map < String , List < Object > > eventHandles = eventStore . getHandles ( projectId ) ; Map < String , List < Map < String , Object > > > events = buildEventMap ( projectId , eventHandles ) ; String response = publishAll ( useProject , events ) ; if ( response != null ) { try { handleAddEventsResponse ( eventHandles , response ) ; } catch ( Exception e ) { KeenLogging . log ( "Error handling response to batch publish: " + e . getMessage ( ) ) ; } } handleSuccess ( callback ) ; } catch ( Exception e ) { handleFailure ( callback , e ) ; } }<CODESPLIT>Synchronously sends all queued events for the given project . This method will immediately publish the events to the Keen server in the current thread .
return getThreadPool ( ) == null ? - 1 : ( ( getThreadPool ( ) . getQueue ( ) instanceof ArrayBlockingQueue ) ? ( ( ArrayBlockingQueue ) getThreadPool ( ) . getQueue ( ) ) . size ( ) + ( ( ArrayBlockingQueue ) getThreadPool ( ) . getQueue ( ) ) . remainingCapacity ( ) : - 1 ) ; }<CODESPLIT>this should only be used as an estimate
SimpleNode jjtn000 = new SimpleNode ( JJTTREEROOT ) ; boolean jjtc000 = true ; jjtree . openNodeScope ( jjtn000 ) ; Tree t ; try { t = TreeNode ( ) ; jjtree . closeNodeScope ( jjtn000 , true ) ; jjtc000 = false ; { if ( true ) return new AuxiliaryTree ( t , requiresFoot ) ; } } catch ( Throwable jjte000 ) { if ( jjtc000 ) { jjtree . clearNodeScope ( jjtn000 ) ; jjtc000 = false ; } else { jjtree . popNode ( ) ; } if ( jjte000 instanceof RuntimeException ) { { if ( true ) throw ( RuntimeException ) jjte000 ; } } if ( jjte000 instanceof ParseException ) { { if ( true ) throw ( ParseException ) jjte000 ; } } { if ( true ) throw ( Error ) jjte000 ; } } finally { if ( jjtc000 ) { jjtree . closeNodeScope ( jjtn000 , true ) ; } } throw new Error ( "Missing return statement in function" ) ; }<CODESPLIT>the argument says whether there must be a foot node on the aux tree .
INodeDirectory newParent = null ; writeLock ( ) ; try { try { newParent = rootDir . addToParent ( src , newNode , parentINode , false , propagateModTime , childIndex ) ; cacheName ( newNode ) ; } catch ( FileNotFoundException e ) { return null ; } if ( newParent == null ) return null ; if ( ! newNode . isDirectory ( ) ) { INodeFile newF = ( INodeFile ) newNode ; BlockInfo [ ] blocks = newF . getBlocks ( ) ; for ( int i = 0 ; i < blocks . length ; i ++ ) { newF . setBlock ( i , getFSNamesystem ( ) . blocksMap . addINodeForLoading ( blocks [ i ] , newF ) ) ; } } } finally { writeUnlock ( ) ; } return newParent ; }<CODESPLIT>Add node to parent node when loading the image .
this . lock ( )  try  if  this . elementUnderEdit != null   Utils . safeSwingBlockingCall ( new Runnable ( ) { public void run ( ) { endEdit ( false ) ; } } ) ; } final List < int [ ] > selectedPaths = new ArrayList < int [ ] > ( ) ; for ( final Topic t : this . selectedTopics ) { selectedPaths . add ( t . getPositionPath ( ) ) ; } this . selectedTopics . clear ( ) ; final MindMap oldModel = this . model ; this . model = assertNotNull ( "Model must not be null" , model ) ; for ( final PanelAwarePlugin p : MindMapPluginRegistry . getInstance ( ) . findFor ( PanelAwarePlugin . class ) ) { p . onPanelModelChange ( this , oldModel , this . model ) ; } doLayout ( ) ; revalidate ( ) ; boolean selectionChanged = false ; for ( final int [ ] posPath : selectedPaths ) { final Topic topic = this . model . findForPositionPath ( posPath ) ; if ( topic == null ) { selectionChanged = true ; } else if ( ! MindMapUtils . isHidden ( topic ) ) { this . selectedTopics . add ( topic ) ; } } if ( selectionChanged ) { fireNotificationSelectionChanged ( ) ; } repaint ( ) ; } finally { this . unlock ( ) ; if ( notifyModelChangeListeners ) { fireNotificationMindMapChanged ( true ) ; } } }<CODESPLIT>Set model for the panel allows to notify listeners optionally .
LoadBalancerMetadata loadBalancerMetadata = findByRef ( loadBalancer ) ; loadBalancerClient . delete ( loadBalancerMetadata . getDataCenterId ( ) , loadBalancerMetadata . getId ( ) ) ; return new OperationFuture < > ( loadBalancer , new NoWaitingJobFuture ( ) ) ; }<CODESPLIT>Delete load balancer
checkNotNull ( request , "request should not be null." ) ; checkStringNotEmpty ( request . getSnapshotId ( ) , "request snapshotId should no be empty." ) ; InternalRequest internalRequest = this . createRequest ( request , HttpMethodName . GET , SNAPSHOT_PREFIX , request . getSnapshotId ( ) ) ; return invokeHttpClient ( internalRequest , GetSnapshotResponse . class ) ; }<CODESPLIT>Getting the detail information of specified snapshot .
try { BugsnagAppender . addExcludedLoggerPattern ( "org.apache.catalina.core.ContainerBase." + "\\[Tomcat.*\\][.]\\[.*\\][.]\\[/.*\\][.]\\[.*\\]" ) ; BugsnagAppender . addExcludedLoggerPattern ( "org.eclipse.jetty.server.HttpChannel" ) ; BugsnagAppender . addExcludedLoggerPattern ( "io.undertow.request" ) ; } catch ( NoClassDefFoundError ignored ) { } }<CODESPLIT>If using Logback stop any configured appender from creating Bugsnag reports for Spring log messages as they effectively duplicate error reports for unhandled exceptions .
if ( null == base ) { throw new AssertionError ( "" ) ; } for ( int i = 0 ; i < base . length ; i ++ ) { if ( null == base [ i ] ) { continue ; } final IConceptSet set = data [ i ] = new SparseConceptHashSet ( ) ; set . addAll ( base [ i ] ) ; if ( null != relationships . data [ i ] ) { set . removeAll ( relationships . data [ i ] ) ; } } }<CODESPLIT>This should only ever be called when the relationships wrap an initial state and no other methods have been called .
E result = null ; Set < Class < ? extends E > > foundClasses = reflections . getSubTypesOf ( type ) ; Set < Class < ? extends E > > endpointClasses = new HashSet < > ( ) ; for ( Class < ? extends E > clazz : foundClasses ) { if ( ! Modifier . isAbstract ( clazz . getModifiers ( ) ) ) { endpointClasses . add ( clazz ) ; } } Iterator < Class < ? extends E > > iterator = endpointClasses . iterator ( ) ; while ( iterator . hasNext ( ) ) { Class < ? extends E > next = iterator . next ( ) ; if ( StringUtils . startsWithIgnoreCase ( next . getName ( ) , "com.github.davidcarboni.restolino.routes." ) ) { iterator . remove ( ) ; } } if ( endpointClasses . size ( ) != 0 ) { if ( endpointClasses . size ( ) > 1 ) { log . info ( "Warning: found multiple candidates for {} endpoint: {}" , name , endpointClasses ) ; } try { result = endpointClasses . iterator ( ) . next ( ) . newInstance ( ) ; } catch ( Exception e ) { log . info ( "Error: cannot instantiate {} endpoint class {}" , name , endpointClasses . iterator ( ) . next ( ) ) ; e . printStackTrace ( ) ; } } return result ; }<CODESPLIT>Locates a single endpoint class .
if ( TraceComponent . isAnyTracingEnabled ( ) && tc . isEntryEnabled ( ) ) SibTr . entry ( tc , "writtenStartedFlush" ) ; String key = SIMPUtils . getRemoteGetKey ( stream . getRemoteMEUuid ( ) , stream . getGatheringTargetDestUuid ( ) ) ; StreamInfo sinfo = streamTable . get ( key ) ; if ( ( sinfo != null ) && sinfo . streamId . equals ( stream . streamId ) ) { synchronized ( sinfo ) { sinfo . item = ( AOStartedFlushItem ) startedFlushItem ; } } else { SIErrorException e = new SIErrorException ( nls . getFormattedMessage ( "INTERNAL_MESSAGING_ERROR_CWSIP0001" , new Object [ ] { "com.ibm.ws.sib.processor.impl.AnycastOutputHandler" , "1:2858:1.89.4.1" } , null ) ) ; FFDCFilter . processException ( e , "com.ibm.ws.sib.processor.impl.AnycastOutputHandler.writtenStartedFlush" , "1:2865:1.89.4.1" , this ) ; SibTr . exception ( tc , e ) ; SibTr . error ( tc , "INTERNAL_MESSAGING_ERROR_CWSIP0001" , new Object [ ] { "com.ibm.ws.sib.processor.impl.AnycastOutputHandler" , "1:2872:1.89.4.1" } ) ; if ( TraceComponent . isAnyTracingEnabled ( ) && tc . isEntryEnabled ( ) ) SibTr . exit ( tc , "writtenStartedFlush" , e ) ; throw e ; } if ( TraceComponent . isAnyTracingEnabled ( ) && tc . isEntryEnabled ( ) ) SibTr . exit ( tc , "writtenStartedFlush" ) ; }<CODESPLIT>Callback when the Item that records that flush has been started has been committed to persistent storage
List < Report > subreports = new ArrayList < Report > ( ) ; Band band = reportLayout . getDetailBand ( ) ; for ( int i = 0 , rows = band . getRowCount ( ) ; i < rows ; i ++ ) { List < BandElement > list = band . getRow ( i ) ; for ( int j = 0 , size = list . size ( ) ; j < size ; j ++ ) { BandElement be = list . get ( j ) ; if ( be instanceof ReportBandElement ) { subreports . add ( ( ( ReportBandElement ) be ) . getReport ( ) ) ; } } } return subreports ; }<CODESPLIT>Get detail band subreports for a report layout
return new ApiAppList ( httpClient . withAuth ( auth ) . get ( BASE_URI + API_APP_LIST_URI ) . asJson ( ) ) ; }<CODESPLIT>Retrieves a paged list of API apps for the authenticated account .
try { if ( pVm != null ) { Class clazz = pVm . getClass ( ) ; Method method = clazz . getMethod ( "detach" ) ; method . setAccessible ( true ) ; method . invoke ( pVm ) ; } } catch ( InvocationTargetException e ) { throw new ProcessingException ( "Error while detaching" , e , options ) ; } catch ( NoSuchMethodException e ) { throw new ProcessingException ( "Error while detaching" , e , options ) ; } catch ( IllegalAccessException e ) { throw new ProcessingException ( "Error while detaching" , e , options ) ; } }<CODESPLIT>Detach from the virtual machine
for ( Class < ? > c : classes ) { if ( c == null ) { throw new NullPointerException ( "Null class not allowed" ) ; } excludedClasses . add ( c ) ; } return this ; }<CODESPLIT>Exclude any object that extends from these classes .
this . sampleMin = min ; this . sampleMax = max ; this . numSamples = total ; this . scores = new double [ numSamples ] ; }<CODESPLIT>Specifies how focal lengths are sampled on a log scale . Remember 1 . 0 = nominal length
for ( int nb = 0 ; nb < bg . numNbsT1 ( v ) ; nb ++ ) { if ( nb == excl1 || nb == excl2 ) { continue ; } VarTensor nbMsg = msgs [ bg . opposingT1 ( v , nb ) ] ; prod . elemMultiply ( nbMsg ) ; } }<CODESPLIT>Computes the product of all messages being sent to a node optionally excluding messages sent from another node or two .
for ( int i = itemAddStates . size ( ) - 1 ; i >= 0 ; i -- ) { ItemState istate = itemAddStates . get ( i ) ; if ( istate . getData ( ) . getQPath ( ) . equals ( itemPath ) ) return istate ; } return null ; }<CODESPLIT>Find last ItemState .
synchronized ( dispatchers ) { if ( dispatchers . containsKey ( dispatcherId ) ) { return ; } dispatchers . put ( dispatcherId , dispatcher ) ; } }<CODESPLIT>Registering custom dispatcher
IntList order = new IntList ( D . size ( ) ) ; ListUtils . addRange ( order , 0 , D . size ( ) , 1 ) ; final double lambda_adj = lambda / ( D . size ( ) * epochs ) ; int [ ] owned = new int [ K ] ; int assigned_positive_instances = 0 ; int [ ] assignments = new int [ D . size ( ) ] ; Arrays . fill ( assignments , - 1 ) ; Vec dots = new DenseVector ( W . rows ( ) ) ; long t = 0 ; for ( int epoch = 0 ; epoch < epochs ; epoch ++ ) { Collections . shuffle ( order ) ; for ( int i : order ) { t ++ ; double eta = 1 / ( lambda_adj * t ) ; Vec x_i = D . getDataPoint ( i ) . getNumericalValues ( ) ; int y_i = ( D . getDataPointCategory ( i ) * 2 - 1 ) * sign_mul ; b . copyTo ( dots ) ; W . multiply ( x_i , 1.0 , dots ) ; if ( y_i == - 1 ) { for ( int k = 0 ; k < K ; k ++ ) if ( dots . get ( k ) > - 1 ) { W . getRowView ( k ) . mutableSubtract ( eta , x_i ) ; b . increment ( k , - eta ) ; } } else { int k_true_max = 0 ; for ( int k = 1 ; k < dots . length ( ) ; k ++ ) if ( dots . get ( k ) > dots . get ( k_true_max ) ) k_true_max = k ; if ( dots . get ( k_true_max ) < 1 ) { int z = ASSIGN ( dots , i , k_true_max , owned , assignments , assigned_positive_instances ) ; W . getRowView ( z ) . mutableAdd ( eta , x_i ) ; b . increment ( z , eta ) ; if ( assignments [ i ] < 0 ) assigned_positive_instances ++ ; else owned [ assignments [ i ] ] -- ; owned [ z ] ++ ; assignments [ i ] = z ; } } W . mutableMultiply ( 1 - 1.0 / t ) ; b . mutableMultiply ( 1 - 1.0 / t ) ; } } }<CODESPLIT>Training procedure that can be applied to each version of the CPM sub - problem .
appfwfieldtype obj = new appfwfieldtype ( ) ; appfwfieldtype [ ] response = ( appfwfieldtype [ ] ) obj . get_resources ( service ) ; return response ; }<CODESPLIT>Use this API to fetch all the appfwfieldtype resources that are configured on netscaler .
delay  this . currentDelaySeconds . get ( )  channelReadyPromise . addListener ( new GenericFutureListener < Future < Channel > > ( ) { public void operationComplete ( final Future < Channel > future ) { final long updatedDelay = future . isSuccess ( ) ? 0 : Math . max ( Math . min ( delay * 2 , MAX_CONNECT_DELAY_SECONDS ) , MIN_CONNECT_DELAY_SECONDS ) ; ApnsChannelFactory . this . currentDelaySeconds . compareAndSet ( delay , updatedDelay ) ; } } )  this . bootstrapTemplate . config ( ) . group ( ) . schedule ( new Runnable ( ) { public void run ( ) { final Bootstrap bootstrap = ApnsChannelFactory . this . bootstrapTemplate . clone ( ) . channelFactory ( new AugmentingReflectiveChannelFactory < > ( ClientChannelClassUtil . getSocketChannelClass ( ApnsChannelFactory . this . bootstrapTemplate . config ( ) . group ( ) ) , CHANNEL_READY_PROMISE_ATTRIBUTE_KEY , channelReadyPromise ) ) ; final ChannelFuture connectFuture = bootstrap . connect ( ) ; connectFuture . addListener ( new GenericFutureListener < ChannelFuture > ( ) { public void operationComplete ( final ChannelFuture future ) { if ( ! future . isSuccess ( ) ) { tryFailureAndLogRejectedCause ( channelReadyPromise , future . cause ( ) ) ; } } } ) ; connectFuture . channel ( ) . closeFuture ( ) . addListener ( new GenericFutureListener < ChannelFuture > ( ) { public void operationComplete ( final ChannelFuture future ) { channelReadyPromise . tryFailure ( new IllegalStateException ( "Channel closed before HTTP/2 preface completed." ) ) ; } } ) ; } } , delay , TimeUnit . SECONDS ) ; return channelReadyPromise ; }<CODESPLIT>Creates and connects a new channel . The initial connection attempt may be delayed to accommodate exponential back - off requirements .
List < String > args = new ArrayList < String > ( ) ; File optionFile = new File ( optionFileName ) ; StringWriter stringWriter = new StringWriter ( ) ; try { InputStream inputStream = new FileInputStream ( optionFile ) ; IOUtils . copy ( inputStream , stringWriter ) ; } catch ( FileNotFoundException e ) { System . err . println ( "Error reading options file: " + e . getMessage ( ) ) ; System . exit ( 1 ) ; } catch ( IOException e ) { System . err . println ( "Error reading options file: " + e . getMessage ( ) ) ; System . exit ( 1 ) ; } String string = stringWriter . toString ( ) ; StringTokenizer stringTokenizer = new StringTokenizer ( string ) ; while ( stringTokenizer . hasMoreTokens ( ) ) { args . add ( stringTokenizer . nextToken ( ) ) ; } return args ; }<CODESPLIT>Load options from a file
try { this . currentJob = this . jobQueue . take ( ) ; ExecutionContext context = new ExecutionContext ( ) ; try { this . executionContextManager . initialize ( context ) ; } catch ( ExecutionContextException e ) { throw new RuntimeException ( "Failed to initialize Job " + this . currentJob + " execution context" , e ) ; } this . currentJob . run ( ) ; } catch ( InterruptedException e ) { } finally { this . execution . removeContext ( ) ; } }<CODESPLIT>Execute one job .
getLocals ( ) . put ( name , model ) ; return this ; }<CODESPLIT>Binds an object to the response .
byte [ ] result = null ; if ( offset != null ) { result = m_map . get ( offset ) ; } return ( result ) ; }<CODESPLIT>This method retrieves a byte array containing the data at the given offset in the block . If no data is found at the given offset this method returns null .
MetaClass metaClass = InvokerHelper . getMetaClass ( objectUnderInspection ) ; List metaMethods = metaClass . getMetaMethods ( ) ; Object [ ] result = new Object [ metaMethods . size ( ) ] ; int i = 0 ; for ( Iterator iter = metaMethods . iterator ( ) ; iter . hasNext ( ) ; i ++ ) { MetaMethod metaMethod = ( MetaMethod ) iter . next ( ) ; result [ i ] = methodInfo ( metaMethod ) ; } return result ; }<CODESPLIT>Get info about instance and class Methods that are dynamically added through Groovy .
String [ ] periods = pollers . split ( ",\\s*" ) ; long [ ] result = new long [ periods . length ] ; boolean errors = false ; Logger logger = LoggerFactory . getLogger ( Pollers . class ) ; for ( int i = 0 ; i < periods . length ; ++ i ) { String period = periods [ i ] ; try { result [ i ] = Long . parseLong ( period ) ; if ( result [ i ] <= 0 ) { logger . error ( "Invalid polling interval: {} must be positive." , period ) ; errors = true ; } } catch ( NumberFormatException e ) { logger . error ( "Cannot parse '{}' as a long: {}" , period , e . getMessage ( ) ) ; errors = true ; } } if ( errors || periods . length == 0 ) { logger . info ( "Using a default configuration for poller intervals: {}" , join ( DEFAULT_PERIODS ) ) ; return DEFAULT_PERIODS ; } else { return result ; } }<CODESPLIT>Parse the content of the system property that describes the polling intervals and in case of errors use the default of one poller running every minute .
Objects . requireNonNull ( value ) ; int i = 0 ; boolean hasFooter = false ; for ( i = _footerKeys . size ( ) - 1 ; i >= 0 ; i -- ) { String oldKey = _footerKeys . get ( i ) ; if ( oldKey . equalsIgnoreCase ( key ) ) { if ( hasFooter ) { _footerKeys . remove ( i ) ; _footerValues . remove ( i ) ; } else { hasFooter = true ; _footerValues . set ( i , value ) ; } } } if ( ! hasFooter ) { _footerKeys . add ( key ) ; _footerValues . add ( value ) ; } }<CODESPLIT>Sets a footer replacing an already - existing footer
if ( m_elemContext . m_startTagOpen ) { final String patchedName = patchName ( name ) ; final String localName = getLocalName ( patchedName ) ; final String uri = getNamespaceURI ( patchedName , false ) ; addAttributeAlways ( uri , localName , patchedName , "CDATA" , value , false ) ; } }<CODESPLIT>Adds the given attribute to the set of collected attributes but only if there is a currently open element .
if ( isEmpty ( htmlPart ) && isEmpty ( textPart ) ) { throw new IllegalArgumentException ( "Missing email content" ) ; } final MimeMessage msg = new MimeMessage ( session ) ; msg . setSubject ( subject ) ; msg . setFrom ( new InternetAddress ( from ) ) ; msg . setContent ( createMultiPart ( ) ) ; msg . setRecipients ( Message . RecipientType . TO , InternetAddress . parse ( recipients , false ) ) ; return msg ; }<CODESPLIT>Creates a MimeMessage containing given Multipart . Subject sender and content and session will be set .
int timeIndex = model . getTimeIndex ( startTime ) ; ArrayList < RandomVariable > liborsAtTimeIndex = new ArrayList < > ( ) ; int firstLiborIndex = model . getLiborPeriodDiscretization ( ) . getTimeIndexNearestGreaterOrEqual ( startTime ) ; double firstLiborTime = model . getLiborPeriodDiscretization ( ) . getTime ( firstLiborIndex ) ; if ( firstLiborTime > startTime ) { liborsAtTimeIndex . add ( model . getLIBOR ( startTime , startTime , firstLiborTime ) ) ; } double [ ] times = new double [ firstLiborTime == startTime ? ( model . getNumberOfLibors ( ) - firstLiborIndex ) : ( model . getNumberOfLibors ( ) - firstLiborIndex + 1 ) ] ; times [ 0 ] = 0 ; int indexOffset = firstLiborTime == startTime ? 0 : 1 ; for ( int i = firstLiborIndex ; i < model . getNumberOfLibors ( ) ; i ++ ) { liborsAtTimeIndex . add ( model . getLIBOR ( timeIndex , i ) ) ; times [ i - firstLiborIndex + indexOffset ] = model . getLiborPeriodDiscretization ( ) . getTime ( i ) - startTime ; } RandomVariable [ ] libors = liborsAtTimeIndex . toArray ( new RandomVariable [ liborsAtTimeIndex . size ( ) ] ) ; return ForwardCurveInterpolation . createForwardCurveFromForwards ( name , times , libors , model . getLiborPeriodDiscretization ( ) . getTimeStep ( firstLiborIndex ) ) ; }<CODESPLIT>Create a forward curve from forwards given by a LIBORMonteCarloModel .
Validator . notNull ( deleteWordOptions , "deleteWordOptions cannot be null" ) ; String [ ] pathSegments = { "v1/customizations" , "words" } ; String [ ] pathParameters = { deleteWordOptions . customizationId ( ) , deleteWordOptions . word ( ) } ; RequestBuilder builder = RequestBuilder . delete ( RequestBuilder . constructHttpUrl ( getEndPoint ( ) , pathSegments , pathParameters ) ) ; Map < String , String > sdkHeaders = SdkCommon . getSdkHeaders ( "text_to_speech" , "v1" , "deleteWord" ) ; for ( Entry < String , String > header : sdkHeaders . entrySet ( ) ) { builder . header ( header . getKey ( ) , header . getValue ( ) ) ; } return createServiceCall ( builder . build ( ) , ResponseConverterUtils . getVoid ( ) ) ; }<CODESPLIT>Delete a custom word .
float newx = playerX + x ; float newy = playerY + y ; if ( blocked ( newx , newy ) ) { if ( blocked ( newx , playerY ) ) { if ( blocked ( playerX , newy ) ) { return false ; } else { playerY = newy ; return true ; } } else { playerX = newx ; return true ; } } else { playerX = newx ; playerY = newy ; return true ; } }<CODESPLIT>Try to move in the direction specified . If it s blocked try sliding . If that doesn t work just don t bother
try { this . messages . clear ( ) ; this . dataLogger . prepareForRead ( ) ; this . dataLogger . recover ( this ) ; } catch ( Exception e ) { throw new DelegatedRuntimeException ( e ) ; } }<CODESPLIT>recovers the dataRecorder all messages are removed and all the messsages of the logger are recoverd
synchronized ( mAudioSources ) { for ( GVRAudioSource source : mAudioSources ) { source . setListener ( null ) ; } mAudioSources . clear ( ) ; } }<CODESPLIT>Remove all of the audio sources from the audio manager . This will stop all sound from playing .
NumberVector . Factory < V > factory = null ; if ( in instanceof VectorTypeInformation ) { factory = ( NumberVector . Factory < V > ) ( ( VectorTypeInformation < V > ) in ) . getFactory ( ) ; } if ( factory == null ) { try { Field f = in . getRestrictionClass ( ) . getField ( "FACTORY" ) ; factory = ( NumberVector . Factory < V > ) f . get ( null ) ; } catch ( Exception e ) { LoggingUtil . warning ( "Cannot determine factory for type " + in . getRestrictionClass ( ) , e ) ; } } return factory ; }<CODESPLIT>Try to guess the appropriate factory .
if ( ! rootDir . exists ( ) ) rootDir . mkdirs ( ) ; if ( ! rootSaveDir . exists ( ) ) rootSaveDir . mkdirs ( ) ; if ( paths == null ) paths = Maps . newHashMap ( ) ; if ( labelRootDirs == null ) labelRootDirs = Lists . newArrayList ( ) ; for ( int i = 0 ; i < numLabels ; i ++ ) { paths . put ( i , new ArrayList < File > ( ) ) ; labelRootDirs . add ( new File ( rootDir , String . valueOf ( i ) ) ) ; } while ( dataSetIterator . hasNext ( ) ) { DataSet next = dataSetIterator . next ( ) ; if ( miniBatchSize < 0 ) miniBatchSize = next . numExamples ( ) ; for ( int i = 0 ; i < next . numExamples ( ) ; i ++ ) { DataSet currExample = next . get ( i ) ; if ( ! labelRootDirs . get ( currExample . outcome ( ) ) . exists ( ) ) labelRootDirs . get ( currExample . outcome ( ) ) . mkdirs ( ) ; File example = new File ( labelRootDirs . get ( currExample . outcome ( ) ) , String . valueOf ( paths . get ( currExample . outcome ( ) ) . size ( ) ) ) ; currExample . save ( example ) ; paths . get ( currExample . outcome ( ) ) . add ( example ) ; } } int numsSaved = 0 ; while ( ! paths . isEmpty ( ) ) { List < DataSet > miniBatch = new ArrayList < > ( ) ; while ( miniBatch . size ( ) < miniBatchSize && ! paths . isEmpty ( ) ) { for ( int i = 0 ; i < numLabels ; i ++ ) { if ( paths . get ( i ) != null && ! paths . get ( i ) . isEmpty ( ) ) { DataSet d = new DataSet ( ) ; d . load ( paths . get ( i ) . remove ( 0 ) ) ; miniBatch . add ( d ) ; } else paths . remove ( i ) ; } } if ( ! rootSaveDir . exists ( ) ) rootSaveDir . mkdirs ( ) ; if ( ! miniBatch . isEmpty ( ) ) { DataSet merge = DataSet . merge ( miniBatch ) ; if ( dataNormalization != null ) dataNormalization . transform ( merge ) ; merge . save ( new File ( rootSaveDir , String . format ( "dataset-%d.bin" , numsSaved ++ ) ) ) ; } } }<CODESPLIT>Generate a balanced dataset minibatch fileset .
double gpsTime = unixTime - 315964800 ; gpsTime += countleaps ( gpsTime , true ) - 1 ; return isleap ( gpsTime ) ; }<CODESPLIT>Test to see if a unixtime second is a leap second
final String sPropertyName = SUN_XML_HEADERS ; _setProperty ( aMarshaller , sPropertyName , sXMLHeaders ) ; }<CODESPLIT>Set the Sun specific XML header string .
apiTS  System . currentTimeMillis ( )   message     bridgeId  apiTS    requestMessageString  gson . toJson ( message )  httpClient . sendBridgeAlive ( keepAliveEventUrl , token , requestMessageString , new CallStatsHttp2ResponseListener ( ) { public void onResponse ( Response response ) { int responseStatus = response . code ( ) ; BridgeKeepAliveResponse keepAliveResponse ; try { String responseString = response . body ( ) . string ( ) ; keepAliveResponse = gson . fromJson ( responseString , BridgeKeepAliveResponse . class ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; throw new RuntimeException ( e ) ; } catch ( JsonSyntaxException e ) { logger . error ( "Json Syntax Exception " + e . getMessage ( ) , e ) ; e . printStackTrace ( ) ; throw new RuntimeException ( e ) ; } httpClient . setDisrupted ( false ) ; if ( responseStatus == CallStatsResponseStatus . RESPONSE_STATUS_SUCCESS ) { keepAliveStatusListener . onSuccess ( ) ; } else if ( responseStatus == CallStatsResponseStatus . INVALID_AUTHENTICATION_TOKEN ) { stopKeepAliveSender ( ) ; keepAliveStatusListener . onKeepAliveError ( CallStatsErrors . AUTH_ERROR , keepAliveResponse . getMsg ( ) ) ; } else { httpClient . setDisrupted ( true ) ; } } public void onFailure ( Exception e ) { logger . info ( "Response exception " + e . toString ( ) ) ; httpClient . setDisrupted ( true ) ; } } ) ; }<CODESPLIT>Send keep alive bridge message .
sOutput                    final String revision = queryParams . get ( QueryParameter . REVISION ) ; final String wrap = queryParams . get ( QueryParameter . WRAP ) ; final String doNodeId = queryParams . get ( QueryParameter . OUTPUT ) ; final boolean wrapResult = ( wrap == null ) ? false : wrap . equalsIgnoreCase ( YESSTRING ) ; final boolean nodeid = ( doNodeId == null ) ? false : doNodeId . equalsIgnoreCase ( YESSTRING ) ; final Long rev = revision == null ? null : Long . valueOf ( revision ) ; serialize ( resourceName , nodeId , rev , nodeid , output , wrapResult ) ; } } ; return sOutput ; }<CODESPLIT>This method is responsible to deliver the whole XML resource addressed by a unique node id .
if ( mors == null ) { return new ManagedEntity [ 0 ] ; } ManagedEntity [ ] mes = new ManagedEntity [ mors . length ] ; for ( int i = 0 ; i < mors . length ; i ++ ) { mes [ i ] = createExactManagedEntity ( sc , mors [ i ] ) ; } return mes ; }<CODESPLIT>Given a ServerConnection and an array of MORs return an array of MEs
return key -> { String result = null ; if ( formatter != null ) { result = formatter . getAttributes ( ) . get ( key ) ; } if ( result == null ) { CmsXmlContent content = contentSupplier . get ( ) ; if ( content != null ) { result = content . getHandler ( ) . getParameter ( key ) ; } } return result ; } ; }<CODESPLIT>Helper method to create a string template source for a given formatter and content .
ByteBuffer cdb = ByteBuffer . allocate ( DEFAULT_CDB_LENGTH ) ; cdb . put ( opCode ) ; cdb . position ( LOGICAL_BLOCK_ADDRESS_OFFSET ) ; cdb . putInt ( logicalBlockAddress ) ; cdb . position ( TRANSFER_LENGTH_OFFSET ) ; cdb . putShort ( transferLength ) ; cdb . rewind ( ) ; return cdb ; }<CODESPLIT>Creates the Command Descriptor Block for a given Operation Message .
long rc = fillAppRead ( ) ; if ( rc <= 0 ) { return rc ; } return ByteBuffers . move ( appRead , dsts , offset , length ) ; }<CODESPLIT>Reads ByteBuffer from peer . Starts handshaking if needed .
if ( inFirstSegment ( segments , offset , 4 ) ) { segments [ 0 ] . putInt ( offset , value ) ; } else { setIntMultiSegments ( segments , offset , value ) ; } }<CODESPLIT>set int from segments .
try { return ( Optional . ofNullable ( getUser ( username ) ) ) ; } catch ( GitLabApiException glae ) { return ( GitLabApi . createOptionalFromException ( glae ) ) ; } }<CODESPLIT>Lookup a user by username and return an Optional instance .
String componentPropName = GatewayConfigProperties . COMPONENT_PREFIX + IRateLimiterComponent . class . getSimpleName ( ) ; setConfigProperty ( componentPropName , ESRateLimiterComponent . class . getName ( ) ) ; setConfigProperty ( componentPropName + ".client.type" , "jest" ) ; setConfigProperty ( componentPropName + ".client.protocol" , "${apiman.es.protocol}" ) ; setConfigProperty ( componentPropName + ".client.host" , "${apiman.es.host}" ) ; setConfigProperty ( componentPropName + ".client.port" , "${apiman.es.port}" ) ; setConfigProperty ( componentPropName + ".client.username" , "${apiman.es.username}" ) ; setConfigProperty ( componentPropName + ".client.password" , "${apiman.es.password}" ) ; }<CODESPLIT>The rate limiter component .
int dimCounter = 0 ; Point3d point = new Point3d ( 0 , 0 , 0 ) ; for ( int z = 0 ; z < grid [ 0 ] [ 0 ] . length ; z ++ ) { for ( int y = 0 ; y < grid [ 0 ] . length ; y ++ ) { for ( int x = 0 ; x < grid . length ; x ++ ) { if ( dimCounter == gridPoint ) { point . x = minx + latticeConstant * x ; point . y = miny + latticeConstant * y ; point . z = minz + latticeConstant * z ; return point ; } dimCounter ++ ; } } } return point ; }<CODESPLIT>Method calculates coordinates from a given grid array position .
if ( null == color ) { _color = COLOR ; } else { color . set ( COLOR ) ; } }<CODESPLIT>Defines the color that will be used to colorize the section in a clock .
Lockable < V > eventWrapper = sharedBuffer . getEvent ( eventId ) ; if ( eventWrapper != null ) { if ( eventWrapper . release ( ) ) { sharedBuffer . removeEvent ( eventId ) ; } else { sharedBuffer . upsertEvent ( eventId , eventWrapper ) ; } } }<CODESPLIT>Decreases the reference counter for the given event so that it can be removed once the reference counter reaches 0 .
String sql ; if ( forPaginator ) { sql = metaModel . getDialect ( ) . formSelect ( null , null , fullQuery , orderBys , limit , offset ) ; } else { sql = fullQuery != null ? fullQuery : metaModel . getDialect ( ) . formSelect ( metaModel . getTableName ( ) , null , subQuery , orderBys , limit , offset ) ; } if ( showParameters ) { StringBuilder sb = new StringBuilder ( sql ) . append ( ", with parameters: " ) ; join ( sb , params , ", " ) ; sql = sb . toString ( ) ; } return sql ; }<CODESPLIT>Use to see what SQL will be sent to the database .
Source s = null ; TransformerFactoryImpl processor = handler . getStylesheetProcessor ( ) ; URIResolver uriresolver = processor . getURIResolver ( ) ; if ( uriresolver != null ) { String href = getHref ( ) ; String base = handler . getBaseIdentifier ( ) ; s = uriresolver . resolve ( href , base ) ; } return s ; }<CODESPLIT>Get the Source object for the included or imported stylesheet module obtained from the user s URIResolver if there is no user provided URIResolver null is returned .
if ( Journal_Type . featOkTst && ( ( Journal_Type ) jcasType ) . casFeat_title == null ) jcasType . jcas . throwFeatMissing ( "title" , "de.julielab.jules.types.Journal" ) ; return jcasType . ll_cas . ll_getStringValue ( addr , ( ( Journal_Type ) jcasType ) . casFeatCode_title ) ; }<CODESPLIT>getter for title - gets Full journal title C
if ( o != null && o instanceof Val ) { return Cast . as ( o ) ; } return new Val ( o ) ; }<CODESPLIT>Convenience method for creating a Convertible Object
for ( String term : words ) { if ( ! term . equals ( IteratorFactory . EMPTY_TOKEN ) ) { int dimension = basis . getDimension ( term ) ; if ( dimension == - 1 ) continue ; meaning . set ( dimension , weighting . weight ( distance , windowSize ) ) ; ++ distance ; } } }<CODESPLIT>Adds a feature for each word in the context that has a valid dimension . Feature are scored based on the context word s distance from the focus word .
try { if ( config . commandLogging ) { Log . d ( config . commandLoggingTag , "getViews()" ) ; } return viewFetcher . getViews ( null , false ) ; } catch ( Exception e ) { e . printStackTrace ( ) ; return null ; } }<CODESPLIT>Returns an ArrayList of all the View objects located in the focused Activity or Dialog .
if ( keepWeightVectors ) { SparseDoubleVector weightVec = vertexToWeightVector . get ( vertex ) ; if ( weightVec == null ) { synchronized ( this ) { weightVec = vertexToWeightVector . get ( vertex ) ; if ( weightVec == null ) { weightVec = computeWeightVector ( g , vertex ) ; vertexToWeightVector . put ( vertex , weightVec ) ; } } } return weightVec ; } else return computeWeightVector ( g , vertex ) ; }<CODESPLIT>Returns the normalized weight vector for the specified row to be used in edge comparisons . The weight vector is normalized by the number of edges from the row with positive weights and includes a weight for the row to itself which reflects the similarity of the keystone nod .
int rowsToRead = Math . min ( ( int ) batch . count ( ) , rows . length ) ; List < TypeDescription > fieldTypes = schema . getChildren ( ) ; for ( int fieldIdx = 0 ; fieldIdx < selectedFields . length ; fieldIdx ++ ) { int orcIdx = selectedFields [ fieldIdx ] ; readField ( rows , fieldIdx , fieldTypes . get ( orcIdx ) , batch . cols [ orcIdx ] , rowsToRead ) ; } return rowsToRead ; }<CODESPLIT>Fills an ORC batch into an array of Row .
return new ArrayList < ICalProperty > ( component . getProperties ( ) . values ( ) ) ; }<CODESPLIT>Gets the properties to marshal . Child classes can override this for better control over which properties are marshalled .
double tau = 0 ; for ( int i = j ; i < numRows ; i ++ ) { double d = u [ i ] /= max ; tau += d * d ; } tau = Math . sqrt ( tau ) ; if ( u [ j ] < 0 ) tau = - tau ; return tau ; }<CODESPLIT>Normalizes elements in u by dividing by max and computes the norm2 of the normalized array u . Adjust the sign of the returned value depending on the size of the first element in u . Normalization is done to avoid overflow .
try { String url = featureSettings . getJiraBaseUrl ( ) + ( featureSettings . getJiraBaseUrl ( ) . endsWith ( "/" ) ? "" : "/" ) + String . format ( EPIC_REST_SUFFIX , epicKey ) ; ResponseEntity < String > responseEntity = makeRestCall ( url ) ; String responseBody = responseEntity . getBody ( ) ; JSONObject issue = ( JSONObject ) parser . parse ( responseBody ) ; if ( issue == null ) { return null ; } return saveEpic ( issue , epicMap , false ) ; } catch ( ParseException pe ) { LOGGER . error ( "Parser exception when parsing teams" , pe ) ; } catch ( HygieiaException e ) { LOGGER . error ( "Error in calling JIRA API" , e ) ; } return null ; }<CODESPLIT>Get Epic using Jira API
PanelModel model = getComponentModel ( ) ; if ( model . layoutConstraints != null ) { return model . layoutConstraints . get ( child ) ; } return null ; }<CODESPLIT>Retrieves the layout constraints for the given component if they have been set .
Set < Map . Entry < String , Set < String > > > entries = map . entrySet ( ) ; Map < String , Set < String > > rMap = new HashMap < String , Set < String > > ( entries . size ( ) ) ; for ( Map . Entry < String , Set < String > > me : entries ) { String k = me . getKey ( ) ; Set < String > transList = me . getValue ( ) ; for ( String trans : transList ) { Set < String > entry = rMap . get ( trans ) ; if ( entry == null ) { Set < String > toAdd = new LinkedHashSet < String > ( 6 ) ; toAdd . add ( k ) ; rMap . put ( trans , toAdd ) ; } else { entry . add ( k ) ; } } } return rMap ; }<CODESPLIT>Returns a reversed map of the current map .
lock . lock ( ) ; try { if ( refreshToken != null ) { Preconditions . checkArgument ( jsonFactory != null && transport != null && clientAuthentication != null && tokenServerEncodedUrl != null , "Please use the Builder and call setJsonFactory, setTransport, setClientAuthentication" + " and setTokenServerUrl/setTokenServerEncodedUrl" ) ; } this . refreshToken = refreshToken ; } finally { lock . unlock ( ) ; } return this ; }<CODESPLIT>Sets the refresh token .
if ( mEGLDisplay == EGL14 . EGL_NO_DISPLAY ) { Log . d ( TAG , "NOTE: makeCurrent w/o display" ) ; } if ( ! EGL14 . eglMakeCurrent ( mEGLDisplay , eglSurface , eglSurface , mEGLContext ) ) { throw new RuntimeException ( "eglMakeCurrent failed" ) ; } }<CODESPLIT>Makes our EGL context current using the supplied surface for both draw and read .
return navigateOrDefault ( defaultValue , source , paths ) ; }<CODESPLIT>Use navigateOrDefault which is a much better name .
entityCache . removeResult ( CommerceWarehouseItemModelImpl . ENTITY_CACHE_ENABLED , CommerceWarehouseItemImpl . class , commerceWarehouseItem . getPrimaryKey ( ) ) ; finderCache . clearCache ( FINDER_CLASS_NAME_LIST_WITH_PAGINATION ) ; finderCache . clearCache ( FINDER_CLASS_NAME_LIST_WITHOUT_PAGINATION ) ; clearUniqueFindersCache ( ( CommerceWarehouseItemModelImpl ) commerceWarehouseItem , true ) ; }<CODESPLIT>Clears the cache for the commerce warehouse item .
MPPReader reader = new MPPReader ( ) ; m_project = reader . read ( input ) ; String varDataFileName ; String projectDirName ; int mppFileType = NumberHelper . getInt ( m_project . getProjectProperties ( ) . getMppFileType ( ) ) ; switch ( mppFileType ) { case 8 : { projectDirName = " 1" ; varDataFileName = "FixDeferFix 0" ; break ; } case 9 : { projectDirName = " 19" ; varDataFileName = "Var2Data" ; break ; } case 12 : { projectDirName = " 112" ; varDataFileName = "Var2Data" ; break ; } case 14 : { projectDirName = " 114" ; varDataFileName = "Var2Data" ; break ; } default : { throw new IllegalArgumentException ( "Unsupported file type " + mppFileType ) ; } } FileInputStream is = new FileInputStream ( input ) ; POIFSFileSystem fs = new POIFSFileSystem ( is ) ; is . close ( ) ; DirectoryEntry root = fs . getRoot ( ) ; m_projectDir = ( DirectoryEntry ) root . getEntry ( projectDirName ) ; Map < String , String > replacements = new HashMap < String , String > ( ) ; for ( Task task : m_project . getTasks ( ) ) { mapText ( task . getName ( ) , replacements ) ; } processReplacements ( ( ( DirectoryEntry ) m_projectDir . getEntry ( "TBkndTask" ) ) , varDataFileName , replacements , true ) ; replacements . clear ( ) ; for ( Resource resource : m_project . getResources ( ) ) { mapText ( resource . getName ( ) , replacements ) ; mapText ( resource . getInitials ( ) , replacements ) ; } processReplacements ( ( DirectoryEntry ) m_projectDir . getEntry ( "TBkndRsc" ) , varDataFileName , replacements , true ) ; replacements . clear ( ) ; ProjectProperties properties = m_project . getProjectProperties ( ) ; mapText ( properties . getProjectTitle ( ) , replacements ) ; processReplacements ( m_projectDir , "Props" , replacements , true ) ; replacements . clear ( ) ; mapText ( properties . getProjectTitle ( ) , replacements ) ; mapText ( properties . getSubject ( ) , replacements ) ; mapText ( properties . getAuthor ( ) , replacements ) ; mapText ( properties . getKeywords ( ) , replacements ) ; mapText ( properties . getComments ( ) , replacements ) ; processReplacements ( root , "\005SummaryInformation" , replacements , false ) ; replacements . clear ( ) ; mapText ( properties . getManager ( ) , replacements ) ; mapText ( properties . getCompany ( ) , replacements ) ; mapText ( properties . getCategory ( ) , replacements ) ; processReplacements ( root , "\005DocumentSummaryInformation" , replacements , false ) ; FileOutputStream os = new FileOutputStream ( output ) ; fs . writeFilesystem ( os ) ; os . flush ( ) ; os . close ( ) ; fs . close ( ) ; }<CODESPLIT>Process an MPP file to make it anonymous .
final boolean isTraceOn = TraceComponent . isAnyTracingEnabled ( ) ; if ( isTraceOn && tc . isEntryEnabled ( ) ) { Tr . entry ( tc , "setRollbackOnly" , this ) ; } LocalTransactionCoordinator lCoord = getLocalCoord ( ) ; if ( lCoord != null ) { lCoord . setRollbackOnly ( ) ; } else { try { txService . setRollbackOnly ( ) ; } catch ( Exception e ) { FFDCFilter . processException ( e , CLASS_NAME + ".setRollbackOnly" , "556" , this ) ; throw new IllegalStateException ( "No active transaction" ) ; } } if ( isTraceOn && tc . isEntryEnabled ( ) ) { Tr . exit ( tc , "setRollbackOnly" ) ; } }<CODESPLIT>Marks the current local or global transaction to be rolled back
if ( content . contains ( "\"reason\":\"missing\"" ) ) { return true ; } LOGGER . debug ( "Design document not found, error is {}" , content ) ; return false ; }<CODESPLIT>Analyses the content of a 404 response to see if it is legible for retry .
Preconditions . checkArgument ( m_tableTasks . size ( ) == serialized . length ) ; Preconditions . checkArgument ( outputBuffers . size ( ) == serialized . length ) ; final List < ListenableFuture < ? > > writeFutures = new ArrayList < ListenableFuture < ? > > ( outputBuffers . size ( ) ) ; Iterator < DBBPool . BBContainer > containerIter = outputBuffers . iterator ( ) ; int serializedIndex = 0 ; for ( SnapshotTableTask task : m_tableTasks ) { final DBBPool . BBContainer container = containerIter . next ( ) ; final ByteBuffer buf = container . b ( ) ; buf . limit ( serialized [ serializedIndex ++ ] + task . m_target . getHeaderSize ( ) ) ; buf . position ( 0 ) ; Callable < DBBPool . BBContainer > valueForTarget = Callables . returning ( container ) ; if ( task . m_filters != null ) { for ( SnapshotDataFilter filter : task . m_filters ) { valueForTarget = filter . filter ( valueForTarget ) ; } } ListenableFuture < ? > writeFuture = task . m_target . write ( valueForTarget , m_tableId ) ; if ( writeFuture != null ) { writeFutures . add ( writeFuture ) ; } } return Futures . allAsList ( writeFutures ) ; }<CODESPLIT>Finalize the output buffers and write them to the corresponding data targets
return graph [ atomToIndex . get ( atom ) ] . length == 1 ; }<CODESPLIT>Is the atom terminal having only one connection .
if ( result . failed ( ) ) { message . reply ( new JsonObject ( ) . putString ( "status" , "error" ) . putString ( "message" , result . cause ( ) . getMessage ( ) ) ) ; } else { message . reply ( new JsonObject ( ) . putString ( "status" , "ok" ) ) ; } } } ; }<CODESPLIT>Creates a platform undeploy handler .
PhotoSetList < PhotoSet > setList = new PhotoSetList < PhotoSet > ( ) ; PoolList < Pool > poolList = new PoolList < Pool > ( ) ; PhotoAllContext allContext = new PhotoAllContext ( ) ; Map < String , Object > parameters = new HashMap < String , Object > ( ) ; parameters . put ( "method" , METHOD_GET_ALL_CONTEXTS ) ; parameters . put ( "photo_id" , photoId ) ; Response response = transport . get ( transport . getPath ( ) , parameters , apiKey , sharedSecret ) ; if ( response . isError ( ) ) { throw new FlickrException ( response . getErrorCode ( ) , response . getErrorMessage ( ) ) ; } Collection < Element > photosElement = response . getPayloadCollection ( ) ; for ( Element setElement : photosElement ) { if ( setElement . getTagName ( ) . equals ( "set" ) ) { PhotoSet pset = new PhotoSet ( ) ; pset . setTitle ( setElement . getAttribute ( "title" ) ) ; pset . setSecret ( setElement . getAttribute ( "secret" ) ) ; pset . setId ( setElement . getAttribute ( "id" ) ) ; pset . setFarm ( setElement . getAttribute ( "farm" ) ) ; pset . setPrimary ( setElement . getAttribute ( "primary" ) ) ; pset . setServer ( setElement . getAttribute ( "server" ) ) ; pset . setViewCount ( Integer . parseInt ( setElement . getAttribute ( "view_count" ) ) ) ; pset . setCommentCount ( Integer . parseInt ( setElement . getAttribute ( "comment_count" ) ) ) ; pset . setCountPhoto ( Integer . parseInt ( setElement . getAttribute ( "count_photo" ) ) ) ; pset . setCountVideo ( Integer . parseInt ( setElement . getAttribute ( "count_video" ) ) ) ; setList . add ( pset ) ; allContext . setPhotoSetList ( setList ) ; } else if ( setElement . getTagName ( ) . equals ( "pool" ) ) { Pool pool = new Pool ( ) ; pool . setTitle ( setElement . getAttribute ( "title" ) ) ; pool . setId ( setElement . getAttribute ( "id" ) ) ; pool . setUrl ( setElement . getAttribute ( "url" ) ) ; pool . setIconServer ( setElement . getAttribute ( "iconserver" ) ) ; pool . setIconFarm ( setElement . getAttribute ( "iconfarm" ) ) ; pool . setMemberCount ( Integer . parseInt ( setElement . getAttribute ( "members" ) ) ) ; pool . setPoolCount ( Integer . parseInt ( setElement . getAttribute ( "pool_count" ) ) ) ; poolList . add ( pool ) ; allContext . setPoolList ( poolList ) ; } } return allContext ; }<CODESPLIT>Returns all visble sets and pools the photo belongs to .
Map < String , Object > propReturn = null ; if ( properties != null ) { propReturn = new Hashtable < String , Object > ( ) ; for ( int i = 1 ; ; i ++ ) { String strFieldNumber = DBParams . FIELD + Integer . toString ( i ) ; String strFieldName = ( String ) properties . get ( strFieldNumber ) ; if ( strFieldName == null ) break ; Record record = this . getMainRecord ( ) ; if ( strFieldName . indexOf ( '.' ) != - 1 ) { record = this . getRecord ( strFieldName . substring ( 0 , strFieldName . indexOf ( '.' ) ) ) ; strFieldName = strFieldName . substring ( strFieldName . indexOf ( '.' ) + 1 ) ; } BaseField field = null ; if ( record != null ) field = record . getField ( strFieldName ) ; if ( field != null ) propReturn . put ( strFieldNumber , field . getData ( ) ) ; } } return propReturn ; }<CODESPLIT>GetFieldData Method .
BlockGuard . getThreadPolicy ( ) . onNetwork ( ) ; connect0 ( address , port ) ; connectedAddress = address ; connectedPort = port ; connected = true ; }<CODESPLIT>Connects a datagram socket to a remote destination . This associates the remote address with the local socket so that datagrams may only be sent to this destination and received from this destination .
pos ++ ; if ( pos == length ) { throw new IllegalStateException ( "Unexpected end of DN: " + dn ) ; } switch ( chars [ pos ] ) { case '"' : case '\\' : case ',' : case '=' : case '+' : case '<' : case '>' : case '#' : case ';' : case ' ' : case '*' : case '%' : case '_' : return chars [ pos ] ; default : return getUTF8 ( ) ; } }<CODESPLIT>returns escaped char
if ( expression . startsWith ( Citrus . VALIDATION_MATCHER_PREFIX ) && expression . endsWith ( Citrus . VALIDATION_MATCHER_SUFFIX ) ) { return expression . substring ( Citrus . VALIDATION_MATCHER_PREFIX . length ( ) , expression . length ( ) - Citrus . VALIDATION_MATCHER_SUFFIX . length ( ) ) ; } return expression ; }<CODESPLIT>Cut off validation matchers prefix and suffix .
SortedSet < TypeElement > result = get ( implementingClasses , typeElement ) ; SortedSet < TypeElement > intfcs = allSubClasses ( typeElement , false ) ; Iterator < TypeElement > subInterfacesIter = intfcs . iterator ( ) ; while ( subInterfacesIter . hasNext ( ) ) { Iterator < TypeElement > implementingClassesIter = implementingClasses ( subInterfacesIter . next ( ) ) . iterator ( ) ; while ( implementingClassesIter . hasNext ( ) ) { TypeElement c = implementingClassesIter . next ( ) ; if ( ! result . contains ( c ) ) { result . add ( c ) ; } } } return result ; }<CODESPLIT>Return the set of classes which implement the interface passed .
correct &= validation . correct ; if ( ! validate ) return ; errors . addAll ( validation . errors ) ; warnings . addAll ( validation . warnings ) ; }<CODESPLIT>Adds a validation result to this .
StringBuffer buf = new StringBuffer ( 100 ) ; MetaFieldInfo [ ] fields = toMetaFieldInfoArray ( obj , null , true ) ; for ( int i = 0 ; i < fields . length ; i ++ ) { MetaFieldInfo field = fields [ i ] ; buf . append ( field . name ) ; buf . append ( "=" ) ; if ( field . actualValue != null && field . actualValue . getClass ( ) . equals ( String . class ) ) { buf . append ( '"' ) ; buf . append ( field . value ) ; buf . append ( '"' ) ; } else { buf . append ( field . value ) ; } if ( i + 1 < fields . length ) buf . append ( "," ) ; } return buf . toString ( ) ; }<CODESPLIT>Creates a string for an object based on the MetaField annotations .
if ( clazz . isArray ( ) ) { return getArrayClassName ( clazz . getComponentType ( ) ) + "[]" ; } return clazz . getName ( ) ; }<CODESPLIT>Formats the class name with trailing square brackets .
if ( ! isInitialized ( ) ) { return ; } BlockScanInfo info = blockMap . get ( block ) ; if ( info != null ) { LOG . warn ( "Adding an already existing block " + block ) ; delBlockInfo ( info ) ; } info = new BlockScanInfo ( block ) ; info . lastScanTime = getNewBlockScanTime ( ) ; addBlockInfo ( info ) ; adjustThrottler ( ) ; }<CODESPLIT>Adds block to list of blocks
if ( ( x > getArrayWidth ( ) ) || ( y > getArrayHeight ( ) ) || ( x < 0 ) || ( y < 0 ) ) { throw new IllegalArgumentException ( ) ; } return image [ x ] [ y ] ; }<CODESPLIT>Gets a tile of the XPM Image .
final Item item = new Item ( BinType . BIT_ARRAY , name , this . byteOrder ) ; item . bitLenExpression = assertExpressionChars ( bitLenExpression ) ; item . sizeExpression = assertExpressionChars ( sizeExpression ) ; this . addItem ( item ) ; return this ; }<CODESPLIT>Add named bit array where each bit length is calculated through expression .
PatternMatcherInput input = new PatternMatcherInput ( strInput ) ; Perl5Matcher matcher = new Perl5Matcher ( ) ; int compileOptions = caseSensitive ? 0 : Perl5Compiler . CASE_INSENSITIVE_MASK ; compileOptions += Perl5Compiler . SINGLELINE_MASK ; if ( offset < 1 ) offset = 1 ; Pattern pattern = getPattern ( strPattern , compileOptions ) ; if ( offset <= strInput . length ( ) ) input . setCurrentOffset ( offset - 1 ) ; if ( offset <= strInput . length ( ) ) { Array matches = new ArrayImpl ( ) ; while ( matcher . contains ( input , pattern ) ) { int match = matcher . getMatch ( ) . beginOffset ( 0 ) + 1 ; if ( ! matchAll ) { return new Double ( match ) ; } matches . appendEL ( match ) ; } if ( matches . size ( ) != 0 ) { return matches ; } } return 0 ; }<CODESPLIT>return index of the first occurence of the pattern in input text
ServiceReference < ? > [ ] references = getBundleContext ( ) . getServiceReferences ( ( String ) null , filter ) ; if ( isEmptyOrNull ( references ) ) { return null ; } if ( references . length == 1 ) { return getBundleContext ( ) . getService ( references [ 0 ] ) ; } throw new RuntimeException ( "Too many services registered for filter: " + filter ) ; }<CODESPLIT>Checks the OSGi ServiceRegistry if a service matching the given filter is present .
if ( _tevent != null ) { _tevent . postEvent ( event ) ; } else if ( _omgr != null ) { _omgr . postEvent ( event ) ; } else { log . info ( "Dropping event for non- or no longer managed object" , "oid" , getOid ( ) , "class" , getClass ( ) . getName ( ) , "event" , event ) ; } }<CODESPLIT>Posts the specified event either to our dobject manager or to the compound event for which we are currently transacting .
return ExtendedIdentifiers . createExtendedIdentifier ( IfmapStrings . ICS_METADATA_NS_URI , IfmapStrings . ICS_METADATA_PREFIX , "overlay-manager-group" , name ) ; }<CODESPLIT>Create a overlay - manager - group identifier that is an extended identity identifier .
DoubleMatrix result = A . dup ( ) ; int info = NativeBlas . dpotrf ( 'U' , A . rows , result . data , 0 , A . rows ) ; if ( info < 0 ) { throw new LapackArgumentException ( "DPOTRF" , - info ) ; } else if ( info > 0 ) { throw new LapackPositivityException ( "DPOTRF" , "Minor " + info + " was negative. Matrix must be positive definite." ) ; } clearLower ( result ) ; return result ; }<CODESPLIT>Compute Cholesky decomposition of A
final Throwable throwable = new Throwable ( ) ; final StackTraceElement [ ] stackElements = throwable . getStackTrace ( ) ; if ( null == stackElements ) { LOGGER . log ( Level . WARN , "Empty call stack" ) ; return false ; } final boolean matchAllMethod = "*" . equals ( methodName ) ; for ( int i = 1 ; i < stackElements . length ; i ++ ) { if ( stackElements [ i ] . getClassName ( ) . equals ( className ) ) { return matchAllMethod ? true : stackElements [ i ] . getMethodName ( ) . equals ( methodName ) ; } } return false ; }<CODESPLIT>Checks the current method is whether invoked by a caller specified by the given class name and method name .
return executeCommand ( "setflag" , name , value ) ; }<CODESPLIT>set JVM command line flag
Expression < ? > flag = Expressions . template ( expr . getType ( ) , prefix + "{0}" , expr ) ; return queryMixin . addFlag ( new QueryFlag ( position , flag ) ) ; }<CODESPLIT>Add the given prefix and expression as a general query flag
SocketChannel channel = ( SocketChannel ) c ; InetSocketAddress hostAddress = channel . localAddress ( ) ; InetSocketAddress remoteAddress = getRemoteAddress ( channel ) ; String scheme = channel . pipeline ( ) . get ( SslHandler . class ) != null ? "https" : "http" ; return new ConnectionInfo ( hostAddress , remoteAddress , scheme ) ; }<CODESPLIT>Retrieve the connection information from the current connection directly
SortedSet < String > domainRanges = null ; if ( serializedCache != null ) { if ( serializedCache . containsKey ( pdpDomainName ) ) { domainRanges = serializedCache . get ( pdpDomainName ) ; } } boolean shouldRequestDomainRanges = checkDomainRanges ( domainRanges ) ; try { if ( shouldRequestDomainRanges ) { URL u = new URL ( server + "getPDPDomain?pdpId=" + pdpDomainName ) ; logger . info ( "Fetching {}" , u ) ; InputStream response = URLConnectionTools . getInputStream ( u ) ; String xml = JFatCatClient . convertStreamToString ( response ) ; domainRanges = XMLUtil . getDomainRangesFromXML ( xml ) ; if ( domainRanges != null ) cache ( pdpDomainName , domainRanges ) ; } } catch ( MalformedURLException e ) { logger . error ( "Problem generating PDP request URL for " + pdpDomainName , e ) ; throw new IllegalArgumentException ( "Invalid PDP name: " + pdpDomainName , e ) ; } String pdbId = null ; List < ResidueRange > ranges = new ArrayList < ResidueRange > ( ) ; for ( String domainRange : domainRanges ) { SubstructureIdentifier strucId = new SubstructureIdentifier ( domainRange ) ; if ( pdbId == null ) { pdbId = strucId . getPdbId ( ) ; } else if ( ! pdbId . equals ( strucId . getPdbId ( ) ) ) { throw new RuntimeException ( "Don't know how to take the union of domains from multiple PDB IDs." ) ; } ranges . addAll ( strucId . getResidueRanges ( ) ) ; } return new PDPDomain ( pdpDomainName , ranges ) ; }<CODESPLIT>Get a StructureIdentifier representing the specified PDP domain .
if ( searchView != null ) { return searchView . getContext ( ) ; } else if ( supportView != null ) { return supportView . getContext ( ) ; } throw new IllegalStateException ( ERROR_NO_SEARCHVIEW ) ; }<CODESPLIT>Returns the context the view is running in through which it can access the current theme resources etc .
if ( ring . getAtomCount ( ) < 8 ) return false ; for ( IBond bond : ring . bonds ( ) ) { boolean found = false ; for ( IAtomContainer other : rs . atomContainers ( ) ) { if ( ring == other ) continue ; if ( other . contains ( bond ) ) { found = true ; break ; } } if ( ! found ) return true ; } return false ; }<CODESPLIT>Check if a ring in a ring set is a macro cycle . We define this as a ring with > = 10 atom and has at least one bond that isn t contained in any other rings .
try { if ( entity == null ) { return null ; } T result = ( T ) persistentClass . newInstance ( ) ; populate ( entity , result ) ; return result ; } catch ( InstantiationException e ) { throw new RuntimeException ( e ) ; } catch ( IllegalAccessException e ) { throw new RuntimeException ( e ) ; } }<CODESPLIT>Convert a value from Google representation to a Java value
getAuthenticationConfig ( props ) ; if ( cacheEnabled ) { authCacheServiceRef . activate ( cc ) ; } else { authCacheServiceRef . deactivate ( cc ) ; } }<CODESPLIT>Based on the configuration properties the auth cache should either be active or not .
query  readTime                   if  documents == null     documentSet   if  documents == null   documents  documentSet . toList ( )      Collections . unmodifiableList ( documents )             Collections . unmodifiableList ( documentChanges )          documentSet . size ( )           if  this == o       if  o == null || getClass ( ) != o . getClass ( )        that     o   Objects . equals ( query , that . query )  Objects . equals ( this . size ( ) , that . size ( ) )  Objects . equals ( this . getDocumentChanges ( ) , that . getDocumentChanges ( ) )  Objects . equals ( this . getDocuments ( ) , that . getDocuments ( ) )         return Objects . hash ( query , this . getDocumentChanges ( ) , this . getDocuments ( ) ) ; } } ; }<CODESPLIT>Creates a new QuerySnapshot representing a snapshot of a Query with changed documents .
MethodRefHamp methodHamp = null ; try { methodHamp = readMethod ( hIn ) ; } catch ( Throwable e ) { log . log ( Level . FINER , e . toString ( ) , e ) ; skipArgs ( hIn ) ; return true ; } MethodRefAmp method = methodHamp . getMethod ( ) ; ClassLoader loader = methodHamp . getClassLoader ( ) ; Thread thread = Thread . currentThread ( ) ; thread . setContextClassLoader ( loader ) ; Object [ ] args = readArgs ( methodHamp , hIn ) ; if ( log . isLoggable ( _logLevel ) ) { log . log ( _logLevel , this + " send-r " + method . getName ( ) + debugArgs ( args ) + " {to:" + method + ", " + headers + "}" ) ; } SendMessage_N sendMessage = new SendMessage_N ( outbox , headers , method . serviceRef ( ) , method . method ( ) , args ) ; long timeout = 1000L ; try { sendMessage . offer ( timeout ) ; } catch ( Throwable e ) { log . fine ( e . toString ( ) ) ; if ( log . isLoggable ( Level . FINEST ) ) { log . log ( Level . FINEST , e . toString ( ) , e ) ; } } return true ; }<CODESPLIT>The send message is a on - way call to a service .
if ( file . getProperty ( PARAM_REMOTE_PATH ) . endsWith ( "/" ) ) { return file . getName ( service ) ; } if ( file . getProperty ( PARAM_REMOTE_PATH ) . contains ( "/" ) ) { String [ ] tmp = file . getProperty ( PARAM_REMOTE_PATH ) . split ( "/" ) ; return tmp [ tmp . length - 1 ] ; } return file . getProperty ( PARAM_REMOTE_PATH ) ; }<CODESPLIT>Checks if the remote file path contains also the remote file name . If it s not specified the name of the local file will be used .
final MetricGroup buffers = addGroup ( "buffers" ) ; buffers . gauge ( "inputQueueLength" , new InputBuffersGauge ( task ) ) ; buffers . gauge ( "outputQueueLength" , new OutputBuffersGauge ( task ) ) ; buffers . gauge ( "inPoolUsage" , new InputBufferPoolUsageGauge ( task ) ) ; buffers . gauge ( "outPoolUsage" , new OutputBufferPoolUsageGauge ( task ) ) ; }<CODESPLIT>Initialize Buffer Metrics for a task .
try { new Region ( this . rect ) . doubleClick ( fileName ) ; } catch ( Exception ex ) { throw new QTasteException ( ex . getMessage ( ) , ex ) ; } }<CODESPLIT>Simulates a double click on the specified image of the area .
if ( sseKey != null && this . sseAwsKeyManagementParams != null ) { throw new IllegalArgumentException ( "Either SSECustomerKey or SSEAwsKeyManagementParams must not be set at the same time." ) ; } this . destinationSSECustomerKey = sseKey ; }<CODESPLIT>Sets the optional customer - provided server - side encryption key to use to encrypt the destination object being copied .
Toast . makeText ( this , t . getMessage ( ) , LENGTH_LONG ) . show ( ) ; }<CODESPLIT>show any error messages posted to the bus .
JTable . DropLocation loc = table . getDropLocation ( ) ; if ( loc == null ) { return ; } Color color = ( Color ) style . get ( context , "Table.dropLineColor" ) ; Color shortColor = ( Color ) style . get ( context , "Table.dropLineShortColor" ) ; if ( color == null && shortColor == null ) { return ; } Rectangle rect ; rect = getHDropLineRect ( loc ) ; if ( rect != null ) { int x = rect . x ; int w = rect . width ; if ( color != null ) { extendRect ( rect , true ) ; g . setColor ( color ) ; g . fillRect ( rect . x , rect . y , rect . width , rect . height ) ; } if ( ! loc . isInsertColumn ( ) && shortColor != null ) { g . setColor ( shortColor ) ; g . fillRect ( x , rect . y , w , rect . height ) ; } } rect = getVDropLineRect ( loc ) ; if ( rect != null ) { int y = rect . y ; int h = rect . height ; if ( color != null ) { extendRect ( rect , false ) ; g . setColor ( color ) ; g . fillRect ( rect . x , rect . y , rect . width , rect . height ) ; } if ( ! loc . isInsertRow ( ) && shortColor != null ) { g . setColor ( shortColor ) ; g . fillRect ( rect . x , y , rect . width , h ) ; } } }<CODESPLIT>Paint the drop lines if any .
rule . accept ( this ) ; if ( notSupported ) { log . warn ( "Not Supported Translation of: " + errors ) ; errors . clear ( ) ; } DatalogProgram dp = datalogFactory . getDatalogProgram ( ) ; dp . appendRule ( facts ) ; return dp ; }<CODESPLIT>Translate the swrl_rule Return a datalog program containing the supported datalog facts
val inflated = CompressionUtils . inflate ( decodedBytes ) ; if ( ! StringUtils . isEmpty ( inflated ) ) { return inflated ; } return CompressionUtils . decodeByteArrayToString ( decodedBytes ) ; }<CODESPLIT>Inflate authn request string .
if ( ! propertyFile . exists ( ) ) { generateProjectPropertiesFile ( name , propertyFile , false , properties , true ) ; } return create ( name , propertyFile , filesystemFramework ) ; }<CODESPLIT>Create and generate file with the given properties if not null
final LogContext embeddedLogContext = Holder . LOG_CONTEXT ; final Configurator configurator = embeddedLogContext . getLogger ( "" ) . detach ( Configurator . ATTACHMENT_KEY ) ; if ( configurator instanceof PropertyConfigurator ) { final LogContextConfiguration logContextConfiguration = ( ( PropertyConfigurator ) configurator ) . getLogContextConfiguration ( ) ; clearLogContext ( logContextConfiguration ) ; } else if ( configurator instanceof LogContextConfiguration ) { clearLogContext ( ( LogContextConfiguration ) configurator ) ; } else { final List < String > loggerNames = Collections . list ( embeddedLogContext . getLoggerNames ( ) ) ; for ( String name : loggerNames ) { final Logger logger = embeddedLogContext . getLoggerIfExists ( name ) ; if ( logger != null ) { final Handler [ ] handlers = logger . clearHandlers ( ) ; if ( handlers != null ) { for ( Handler handler : handlers ) { handler . close ( ) ; } } logger . setFilter ( null ) ; logger . setUseParentFilters ( false ) ; logger . setUseParentHandlers ( true ) ; logger . setLevel ( Level . INFO ) ; } } } }<CODESPLIT>Attempts to clear the global log context used for embedded servers .
return Blocking . blockForSingle ( delegate . execute ( ) , timeout , timeUnit ) ; }<CODESPLIT>Executes the API request in a synchronous fashion using the given timeout .
byte [ ] bytes = this . bytes ; byte [ ] sourceMap = this . sourceMap ; String filename = this . filename ; InputStream result = null ; if ( bytes != null ) { result = new ByteArrayInputStream ( bytes ) ; if ( sourceMapResult != null && sourceMapSize > 0 ) { sourceMapResult . setValue ( sourceMap ) ; } } else if ( filename != null ) { ICacheManager cmgr = ( ( IAggregator ) request . getAttribute ( IAggregator . AGGREGATOR_REQATTRNAME ) ) . getCacheManager ( ) ; File file = new File ( cmgr . getCacheDir ( ) , filename ) ; if ( sourceMapSize == 0 ) { result = new FileInputStream ( file ) ; } else { CacheData data ; ObjectInputStream is = new ObjectInputStream ( new FileInputStream ( file ) ) ; try { data = ( CacheData ) is . readObject ( ) ; } catch ( ClassNotFoundException e ) { throw new IOException ( e . getMessage ( ) , e ) ; } finally { IOUtils . closeQuietly ( is ) ; } bytes = data . bytes ; sourceMap = data . sourceMap ; if ( sourceMapResult != null ) { sourceMapResult . setValue ( sourceMap ) ; } result = new ByteArrayInputStream ( bytes ) ; } } else { throw new IOException ( ) ; } return result ; }<CODESPLIT>Return an input stream to the layer . Has side effect of setting the appropriate Content - Type Content - Length and Content - Encoding headers in the response .
if ( getIgnoreByMatches ( ) == null ) { setIgnoreByMatches ( new ArrayList < WebElement > ( ) ) ; for ( By by : getIgnoreRowsMatching ( ) ) { getIgnoreByMatches ( ) . addAll ( table . findElements ( by ) ) ; } } if ( getIncludeByMatches ( ) == null ) { setIncludeByMatches ( new ArrayList < WebElement > ( ) ) ; for ( By by : getIncludeOnlyRowsMatching ( ) ) { getIncludeByMatches ( ) . addAll ( table . findElements ( by ) ) ; } } }<CODESPLIT>Does the table comparison
setError ( null ) ; try { return this . inlineDiffDisplayer . display ( this . diffManager . diff ( previous , next , null ) ) ; } catch ( DiffException e ) { setError ( e ) ; return null ; } }<CODESPLIT>Builds an in - line diff between two versions of a list of elements .
CompletableFuture < MessageSet > future = new CompletableFuture < > ( ) ; channel . getApi ( ) . getThreadPool ( ) . getExecutorService ( ) . submit ( ( ) -> { try { List < Message > messages = new ArrayList < > ( ) ; Optional < Message > untilMessage = getMessagesAroundAsStream ( channel , around ) . peek ( messages :: add ) . filter ( condition ) . findFirst ( ) ; future . complete ( new MessageSetImpl ( untilMessage . map ( message -> messages ) . orElse ( Collections . emptyList ( ) ) ) ) ; } catch ( Throwable t ) { future . completeExceptionally ( t ) ; } } ) ; return future ; }<CODESPLIT>Gets messages in the given channel around a given message in any channel until one that meets the given condition is found . If no message matches the condition an empty set is returned . The given message will be part of the result in addition to the messages around if it was sent in the given channel and is matched against the condition and will abort retrieval . Half of the messages will be older than the given message and half of the messages will be newer . If there aren t enough older or newer messages the halves will not be same - sized . It s also not guaranteed to be perfectly balanced .
try { byte [ ] rawClassBytes ; rawClassBytes = new byte [ stream . available ( ) ] ; stream . read ( rawClassBytes ) ; boolean one = contains ( rawClassBytes , SIP_APPLICATION_BYTES ) ; boolean two = contains ( rawClassBytes , ANNOTATION_BYTES ) ; if ( one && two ) return true ; } catch ( Exception e ) { } return false ; }<CODESPLIT>Determine if this stream contains SipApplication annotations
final Map < String , Object > jobDataMap = new HashMap < String , Object > ( ) ; try { int ind = 0 ; for ( JmxOption option : JmxOptions . getOptions ( ) ) { option . process ( jobDataMap , String . valueOf ( params [ ind ++ ] ) ) ; } for ( Argument arg : this . remoteProgram . getArguments ( ) ) { arg . setValueUsingParser ( String . valueOf ( params [ ind ++ ] ) ) ; } } catch ( Exception e ) { throw new MBeanException ( e ) ; } return jobDataMap ; }<CODESPLIT>Initialize the JobDataMap with the Program arguments
Token t = getNextToken ( ) ; if ( t . tokenType != TokenType . VALUE ) { throw new IllegalStateException ( "Unexpected token " + t ) ; } buf . append ( t . getValue ( ) ) ; t = getNextToken ( ) ; if ( t . tokenType == TokenType . EOL ) { return ; } else if ( t . tokenType == TokenType . TRAILING_BACKSLASH ) { Vopt ( buf ) ; } }<CODESPLIT>Vopt = EOL V
if ( sValue != null ) _addHeader ( sName , sValue ) ; }<CODESPLIT>Add the passed header as is .
return cal ( numberList , DoubleStream :: max ) ; }<CODESPLIT>Max number .
if ( statusReturnCode != - 1 ) { return statusReturnCode ; } try { final ProposalResponsePayloadDeserializer proposalResponsePayloadDeserializer = getProposalResponsePayloadDeserializer ( ) ; statusReturnCode = proposalResponsePayloadDeserializer . getExtension ( ) . getResponseStatus ( ) ; return statusReturnCode ; } catch ( InvalidArgumentException e ) { throw e ; } catch ( Exception e ) { throw new InvalidArgumentException ( e ) ; } }<CODESPLIT>getChaincodeActionResponseStatus returns the what chaincode executions set as the return status .
generate ( queue , null ) ; }<CODESPLIT>Generates the source or class file for a list of classes . The decision to generate a source file or a class file is based upon the compiler s options . Generation stops if an error occurs while writing files .
try { return new EnhancedMimeType ( primary , sub , encoding , version , parameters ) ; } catch ( final MimeTypeParseException ex ) { throw new RuntimeException ( "Failed to create versioned mime type: " + primary + "/" + sub , ex ) ; } }<CODESPLIT>Creates an instance with all data and exceptions wrapped to runtime exceptions .
Long result = toNullableLong ( value ) ; return result != null ? ( long ) result : defaultValue ; }<CODESPLIT>Converts value into integer or returns default when conversion is not possible .
if ( TRANSACTION_READ_COMMITTED . equals ( iso ) ) { isolation = Connection . TRANSACTION_READ_COMMITTED ; } else if ( TRANSACTION_READ_UNCOMMITTED . equals ( iso ) ) { isolation = Connection . TRANSACTION_READ_UNCOMMITTED ; } else if ( TRANSACTION_REPEATABLE_READ . equals ( iso ) ) { isolation = Connection . TRANSACTION_REPEATABLE_READ ; } else if ( TRANSACTION_SERIALIZABLE . equals ( iso ) ) { isolation = Connection . TRANSACTION_SERIALIZABLE ; } else { throw new JspTagException ( Resources . getMessage ( "TRANSACTION_INVALID_ISOLATION" ) ) ; } }<CODESPLIT>Setter method for the transaction isolation level .
try { initTraversal ( root ) ; curNode = root ; pushScope ( root ) ; traverseBranch ( root , null ) ; popScope ( ) ; } catch ( Error | Exception unexpectedException ) { throwUnexpectedException ( unexpectedException ) ; } }<CODESPLIT>Traverses a parse tree recursively .
String path = String . format ( "/workspaces/%s/tags" , workspace ) ; return new CollectionRequest < Tag > ( this , Tag . class , path , "GET" ) ; }<CODESPLIT>Returns the compact tag records for all tags in the workspace .
return Sequence ( ! peek ( ) . isCliQuery ( ) , JsonParameter ( JsonObject ( ) ) , peek ( ) . setOperation ( Operation . FIND ) , peek ( ) . setCriteria ( match ( ) ) ) ; }<CODESPLIT>A find query only given as criterion . Leave it to MongoDB s own parser to handle it .
final E element = l . item ; final Node < E > prev = l . prev ; l . item = null ; l . prev = null ; last = prev ; if ( prev == null ) first = null ; else prev . next = null ; size -- ; modCount ++ ; return element ; }<CODESPLIT>Unlinks non - null last node l .
env . put ( Context . SECURITY_AUTHENTICATION , "simple" ) ; env . put ( Context . SECURITY_PRINCIPAL , userDn ) ; env . put ( Context . SECURITY_CREDENTIALS , new String ( pwd ) ) ; }<CODESPLIT>Sets the environment properties needed for a simple username + password authenticated jndi connection .
return client . sendRpcAndWait ( SERVICE , "createTeam" , name , tag ) ; }<CODESPLIT>Create a new ranked team with the specified name and tag
Pattern p = null ; if ( File . separatorChar == '\\' ) { p = Pattern . compile ( "\\*?(.+\\\\)*.+" ) ; } else if ( File . separatorChar == '/' ) { p = Pattern . compile ( "\\*?(.+/)*.+" ) ; } else { throw new ProblemException ( "This platform uses the unsupported " + File . separatorChar + " as file separator character. Please add support for it!" ) ; } Matcher m = p . matcher ( s ) ; if ( ! m . matches ( ) ) { throw new ProblemException ( "The string \"" + s + "\" is not a proper file name." ) ; } }<CODESPLIT>Verify that a source file name is valid .
for ( Entry < TransactionType , ShardingTransactionManager > entry : transactionManagerMap . entrySet ( ) ) { entry . getValue ( ) . close ( ) ; } }<CODESPLIT>Close sharding transaction managers .
StringBuilder sb = new StringBuilder ( ) ; sb . append ( percentage ) ; sb . append ( "% [" ) ; for ( int i = 0 ; i < 100 ; i ++ ) { if ( percentage == 100 || i < percentage - 1 ) { sb . append ( "=" ) ; } else if ( i == percentage - 1 ) { sb . append ( ">" ) ; } else { sb . append ( " " ) ; } } sb . append ( "] " ) ; return sb . toString ( ) ; }<CODESPLIT>Generates the progress bar for the given percentage
Set < T > dependencies = blockedBy . get ( element ) ; if ( dependencies != null ) { for ( T dependency : dependencies ) { resolve ( dependency , result ) ; } blockedBy . remove ( element ) ; result . add ( element ) ; } }<CODESPLIT>Resolves an element .
CamundaOut param = modelInstance . newInstance ( CamundaOut . class ) ; param . setCamundaSource ( source ) ; param . setCamundaTarget ( target ) ; addExtensionElement ( param ) ; return myself ; }<CODESPLIT>Sets a camunda out parameter to pass a variable from a sub process instance to the super process instance
Node result = IR . name ( "arguments" ) ; if ( isAddingTypes ( ) ) { result . setJSType ( argumentsTypeSupplier . get ( ) ) ; } return result ; }<CODESPLIT>Creates a reference to arguments with the type specified in externs or unknown if the externs for it weren t included .
Date date = null ; DateFormat df = new SimpleDateFormat ( "yyyy-MM-dd" ) ; try { date = df . parse ( dateString ) ; } catch ( ParseException ex ) { System . out . println ( ex . fillInStackTrace ( ) ) ; } return date ; }<CODESPLIT>Takes a String and converts it to a Date
return checkResult ( cusolverRfSetNumericPropertiesNative ( handle , zero , boost ) ) ; }<CODESPLIT>CUSOLVERRF set and get numeric properties
return obj instanceof String ? quote ( ( String ) obj ) : obj ; }<CODESPLIT>Turn the given Object into a String with single quotes if it is a String ; keeping the Object as - is else .
final UniqueIdType uid_type = UniqueId . stringToUniqueIdType ( type ) ; switch ( uid_type ) { case METRIC : return metrics . deleteAsync ( name ) ; case TAGK : return tag_names . deleteAsync ( name ) ; case TAGV : return tag_values . deleteAsync ( name ) ; default : throw new IllegalArgumentException ( "Unrecognized UID type: " + uid_type ) ; } }<CODESPLIT>Attempts to delete the given UID name mapping from the storage table as well as the local cache .
if ( config . commandLogging ) { Log . d ( config . commandLoggingTag , "scrollDownList(" + index + ")" ) ; } return scroller . scrollList ( waiter . waitForAndGetView ( index , ListView . class ) , Scroller . DOWN , false ) ; }<CODESPLIT>Scrolls down a ListView matching the specified index .
AnnotationTypeElementDocImpl result = ( AnnotationTypeElementDocImpl ) methodMap . get ( meth ) ; if ( result != null ) { if ( treePath != null ) result . setTreePath ( treePath ) ; } else { result = new AnnotationTypeElementDocImpl ( this , meth , treePath ) ; methodMap . put ( meth , result ) ; } }<CODESPLIT>Create the AnnotationTypeElementDoc for a MethodSymbol . Should be called only on symbols representing annotation type elements .
return internal_call ( method , null , 0 , true , arguments ) ; }<CODESPLIT>Call a method on the remote Pyro object this proxy is for .
float average = total == 0 ? 0 : 1F * value / total ; return PERCENT_FORMATTER . format ( average ) ; }<CODESPLIT>Returns value converted to percentage format .
return geometryOperation ( expr . getType ( ) , SpatialOps . TRANSLATE , expr , ConstantImpl . create ( deltax ) , ConstantImpl . create ( deltay ) ) ; }<CODESPLIT>Translates the geometry to a new location using the numeric parameters as offsets .
try { HttpGet httpGet = new HttpGet ( url ) ; httpGet . addHeader ( "accept" , "application/xml" ) ; final DigestedResponse response = DigestedResponseReader . requestContent ( httpClient , httpGet , CHARSET ) ; if ( response . getStatusCode ( ) >= 500 ) { throw new TVRageException ( ApiExceptionType . HTTP_503_ERROR , url ) ; } else if ( response . getStatusCode ( ) >= 300 ) { throw new TVRageException ( ApiExceptionType . HTTP_404_ERROR , url ) ; } return response . getContent ( ) . getBytes ( DEFAULT_CHARSET ) ; } catch ( IOException ex ) { throw new TVRageException ( ApiExceptionType . MAPPING_FAILED , UNABLE_TO_PARSE , url , ex ) ; } }<CODESPLIT>Get content from URL in byte array
for ( char c : value . toCharArray ( ) ) { if ( ! Character . isDigit ( c ) ) { return false ; } } return true ; }<CODESPLIT>Returns a boolean indicating whether the given string value is numeric .
GET                 final Map < String , String > fooObj = new HashMap < > ( ) ; fooObj . put ( "foo" , "bar" ) ; return fooObj ; }<CODESPLIT>Controller to just support pinging .
if ( jsonConfig . isEventTriggeringEnabled ( ) ) { for ( Iterator listeners = jsonConfig . getJsonEventListeners ( ) . iterator ( ) ; listeners . hasNext ( ) ; ) { JsonEventListener listener = ( JsonEventListener ) listeners . next ( ) ; try { listener . onArrayStart ( ) ; } catch ( RuntimeException e ) { log . warn ( e ) ; } } } }<CODESPLIT>Fires a start of array event .
return ( ) -> { @ SuppressWarnings ( "unchecked" ) SneakyRunnable < RuntimeException > castedRunnable = ( SneakyRunnable < RuntimeException > ) runnable ; castedRunnable . run ( ) ; } ; }<CODESPLIT>Sneaky throws a Runnable lambda .
assert ( client != null && id != null ) ; final String domainsUri = client . getUserResourceInstanceUri ( BandwidthConstants . DOMAINS_URI_PATH , id ) ; final RestResponse response = client . post ( domainsUri , params ) ; final JSONObject jsonObject = toJSONObject ( client . get ( domainsUri , null ) ) ; return new Domain ( client , jsonObject ) ; }<CODESPLIT>Convenience method to return a Domain .
if ( event instanceof org . modeshape . jcr . api . observation . Event ) { try { final org . modeshape . jcr . api . observation . Event modeEvent = ( org . modeshape . jcr . api . observation . Event ) event ; final Stream . Builder < NodeType > types = Stream . builder ( ) ; for ( final NodeType type : modeEvent . getMixinNodeTypes ( ) ) { types . add ( type ) ; } types . add ( modeEvent . getPrimaryNodeType ( ) ) ; return types . build ( ) . map ( NodeType :: getName ) ; } catch ( final RepositoryException e ) { throw new RepositoryRuntimeException ( e ) ; } } return empty ( ) ; }<CODESPLIT>Get the RDF Types of the resource corresponding to this JCR Event
for ( String line : context . getFileLines ( ) ) { if ( hasHeaderSeparator ( line ) ) { break ; } processHeaderLine ( line , context . getDocumentModel ( ) ) ; } }<CODESPLIT>Process the header of the file .
boolean alive = isConnectionAlive ( ) ; if ( ! alive ) { createConnection ( url , username , password ) ; } return connection ; }<CODESPLIT>Retrieves the connection object . If the connection doesnt exist or is dead it will attempt to create a new connection .
renderNewLine ( builder , newLine ) ; for ( int i = 0 ; i < pad ; i ++ ) { builder . append ( ' ' ) ; } return builder ; }<CODESPLIT>Render some leading spaces onto a line of html .
String qPath = "/xdsl/eligibility/lines/active" ; StringBuilder sb = path ( qPath ) ; HashMap < String , Object > o = new HashMap < String , Object > ( ) ; addBody ( o , "city" , city ) ; addBody ( o , "contactName" , contactName ) ; addBody ( o , "street" , street ) ; addBody ( o , "streetNumber" , streetNumber ) ; String resp = exec ( qPath , "POST" , sb . toString ( ) , o ) ; return convertTo ( resp , t5 ) ; }<CODESPLIT>Get the active lines at given address
while ( ! operators . isEmpty ( ) ) { values . push ( getBooleanResultAsString ( operators . pop ( ) , values . pop ( ) , values . pop ( ) ) ) ; } return replaceIntegerStringByBooleanRepresentation ( values . pop ( ) ) ; }<CODESPLIT>This method takes stacks of operators and values and evaluates possible expressions This is done by popping one operator and two values applying the operator to the values and pushing the result back onto the value stack
int result ; long requestExpireTime = _requestExpireTime ; if ( requestExpireTime > 0 && requestExpireTime < CurrentTime . currentTime ( ) ) { close ( ) ; throw new ClientDisconnectException ( L . l ( "{0}: request-timeout write exp={0}s" , addressRemote ( ) , CurrentTime . currentTime ( ) - requestExpireTime ) ) ; } synchronized ( _writeLock ) { long now = CurrentTime . getCurrentTimeActual ( ) ; long expires = _socketTimeout + now ; do { result = writeNative ( _socketFd , buffer , offset , length ) ; } while ( result == JniStream . TIMEOUT_EXN && CurrentTime . getCurrentTimeActual ( ) < expires ) ; } if ( isEnd ) { closeWrite ( ) ; } return result ; }<CODESPLIT>Writes to the socket .
float ambient [ ] = { r , g , b , 255 } ; normalize ( ambient ) ; gl . glEnable ( GL2 . GL_LIGHTING ) ; gl . glEnable ( GL2 . GL_LIGHT0 ) ; gl . glLightfv ( GL2 . GL_LIGHT0 , GL2 . GL_AMBIENT , ambient , 0 ) ; }<CODESPLIT>Sets the RGB value of the ambientLight
if ( fields != null ) for ( int i = 0 ; i < fields . length ; i ++ ) multiChoiceCount = multiChoiceCount . multiply ( fields [ i ] . setMultiChoiceCount ( ) ) ; return multiChoiceCount ; }<CODESPLIT>Set the multiChoiceCount for this tuple
HttpResponse response = client . delete ( getUrl ( ) + "?force=" + forceDelete ) ; HttpClientHelpers . throwIfNotOk ( response ) ; }<CODESPLIT>Creates this directory vi the Algorithmia Data API
String appName = getApplicationName ( ) ; if ( appName == null ) return ; ConcurrentLinkedQueue < String > list = applicationMap . get ( appName ) ; if ( list == null ) { ConcurrentLinkedQueue < String > newList = new ConcurrentLinkedQueue < String > ( ) ; list = applicationMap . putIfAbsent ( appName , newList ) ; if ( list == null ) list = newList ; } list . add ( name ) ; }<CODESPLIT>Adds the metric name to an application map . This map is not a complete list of metrics owned by an application produced metrics are managed in the MetricsExtension
if ( geometryField == null || geometryField . isEmpty ( ) ) { List < String > geometryFields = getGeometryFields ( connection , location ) ; if ( geometryFields . isEmpty ( ) ) { throw new SQLException ( "The table " + location + " does not contain a Geometry field, then the extent " + "cannot be computed" ) ; } geometryField = geometryFields . get ( 0 ) ; } ResultSet rs = connection . createStatement ( ) . executeQuery ( "SELECT ST_Extent(" + TableLocation . quoteIdentifier ( geometryField ) + ") ext FROM " + location ) ; if ( rs . next ( ) ) { return ( ( Geometry ) rs . getObject ( 1 ) ) . getEnvelopeInternal ( ) ; } throw new SQLException ( "Unable to get the table extent it may be empty" ) ; }<CODESPLIT>Merge the bounding box of all geometries inside the provided table .
name  message . body ( ) . getString ( "name" )  if  name == null   message . reply ( new JsonObject ( ) . putString ( "status" , "error" ) . putString ( "message" , "No name specified." ) )       index  message . body ( ) . getInteger ( "index" )  if  index == null   message . reply ( new JsonObject ( ) . putString ( "status" , "error" ) . putString ( "message" , "No index specified." ) )     context . execute ( new Action < Object > ( ) { public Object perform ( ) { return data . getList ( formatKey ( name ) ) . get ( index ) ; } } , new Handler < AsyncResult < Object > > ( ) { public void handle ( AsyncResult < Object > result ) { if ( result . failed ( ) ) { message . reply ( new JsonObject ( ) . putString ( "status" , "error" ) . putString ( "message" , result . cause ( ) . getMessage ( ) ) ) ; } else { message . reply ( new JsonObject ( ) . putString ( "status" , "ok" ) . putValue ( "result" , result . result ( ) ) ) ; } } } ) ; }<CODESPLIT>Handles a list get .
Histogram histogram = new Histogram ( data ) ; histogram . setID ( id ) ; double [ ] lowerBound = { Math . min ( data ) , 0 } ; double [ ] upperBound = { Math . max ( data ) , 0 } ; double [ ] [ ] freq = histogram . getHistogram ( ) ; for ( int i = 0 ; i < freq . length ; i ++ ) { if ( freq [ i ] [ 1 ] > upperBound [ 1 ] ) { upperBound [ 1 ] = freq [ i ] [ 1 ] ; } } PlotCanvas canvas = new PlotCanvas ( lowerBound , upperBound ) ; canvas . getAxis ( 0 ) . setGridVisible ( false ) ; canvas . add ( histogram ) ; return canvas ; }<CODESPLIT>Create a plot canvas with the histogram plot .
if ( proportion < 0 || proportion > 1 ) { throw new RuntimeException ( "Proportion should between 0.0 - 1.0" ) ; } if ( proportion > 0.5 ) { proportion = 1 - proportion ; } List < Tuple > smallList = new ArrayList < > ( ) ; List < Tuple > largeList = new ArrayList < > ( ) ; int smallListSize = ( int ) Math . floor ( proportion * trainingData . size ( ) ) ; int ct = 0 ; Set < Integer > indices = new HashSet < > ( ) ; while ( ct < smallListSize && trainingData . size ( ) > indices . size ( ) ) { int index = ( int ) ( Math . random ( ) * ( trainingData . size ( ) - 1 ) ) ; while ( indices . contains ( index ) ) { index = ( int ) ( Math . random ( ) * ( trainingData . size ( ) - 1 ) ) ; } indices . add ( index ) ; ct ++ ; } smallList . addAll ( indices . stream ( ) . map ( trainingData :: get ) . collect ( Collectors . toList ( ) ) ) ; IntStream . range ( 0 , trainingData . size ( ) ) . filter ( x -> ! indices . contains ( x ) ) . forEach ( i -> largeList . add ( trainingData . get ( i ) ) ) ; return new ImmutablePair < > ( smallList , largeList ) ; }<CODESPLIT>Shuffle the data and split by proportion
WritableRaster wr = out . getRaster ( ) ; DataBufferByte db = ( DataBufferByte ) wr . getDataBuffer ( ) ; byte [ ] cpuArray = db . getData ( ) ; bgraBuf . clear ( ) ; bgraBuf . get ( cpuArray ) ; bgraBuf . clear ( ) ; int width = wr . getWidth ( ) ; int height = wr . getHeight ( ) ; for ( int y = 0 ; y < height / 2 ; y ++ ) { for ( int x = 0 ; x < width ; x ++ ) { int inPtr = ( y * width + x ) * 4 ; int outPtr = ( ( height - y - 1 ) * width + x ) * 4 ; byte b1 = cpuArray [ inPtr + 0 ] ; byte g1 = cpuArray [ inPtr + 1 ] ; byte r1 = cpuArray [ inPtr + 2 ] ; byte a1 = cpuArray [ inPtr + 3 ] ; byte b2 = cpuArray [ outPtr + 0 ] ; byte g2 = cpuArray [ outPtr + 1 ] ; byte r2 = cpuArray [ outPtr + 2 ] ; byte a2 = cpuArray [ outPtr + 3 ] ; cpuArray [ outPtr + 0 ] = a1 ; cpuArray [ outPtr + 1 ] = b1 ; cpuArray [ outPtr + 2 ] = g1 ; cpuArray [ outPtr + 3 ] = r1 ; cpuArray [ inPtr + 0 ] = a2 ; cpuArray [ inPtr + 1 ] = b2 ; cpuArray [ inPtr + 2 ] = g2 ; cpuArray [ inPtr + 3 ] = r2 ; } } }<CODESPLIT>Good format for java swing .
int docSize = document . size ( ) ; int [ ] [ ] [ ] data = new int [ docSize ] [ windowSize ] [ ] ; int [ ] labels = new int [ docSize ] ; if ( flags . useReverse ) { Collections . reverse ( document ) ; } for ( int j = 0 ; j < docSize ; j ++ ) { CRFDatum < List < String > , CRFLabel > d = makeDatum ( document , j , featureFactory ) ; List < List < String > > features = d . asFeatures ( ) ; for ( int k = 0 , fSize = features . size ( ) ; k < fSize ; k ++ ) { Collection < String > cliqueFeatures = features . get ( k ) ; data [ j ] [ k ] = new int [ cliqueFeatures . size ( ) ] ; int m = 0 ; for ( String feature : cliqueFeatures ) { int index = featureIndex . indexOf ( feature ) ; if ( index >= 0 ) { data [ j ] [ k ] [ m ] = index ; m ++ ; } else { } } if ( m < data [ j ] [ k ] . length ) { int [ ] f = new int [ m ] ; System . arraycopy ( data [ j ] [ k ] , 0 , f , 0 , m ) ; data [ j ] [ k ] = f ; } } IN wi = document . get ( j ) ; labels [ j ] = classIndex . indexOf ( wi . get ( AnswerAnnotation . class ) ) ; } if ( flags . useReverse ) { Collections . reverse ( document ) ; } return new Pair < int [ ] [ ] [ ] , int [ ] > ( data , labels ) ; }<CODESPLIT>Convert a document List into arrays storing the data features and labels .
if ( serviceName == null ) { throw new IllegalArgumentException ( "serviceName cannot be null" ) ; } List < Class < ? > > classes = new ArrayList < Class < ? > > ( ) ; if ( factories != null ) { List < Callable < Class < ? > > > l = factories . get ( serviceName ) ; if ( l != null ) { for ( Callable < Class < ? > > c : l ) { try { classes . add ( c . call ( ) ) ; } catch ( Exception e ) { } } } } return classes ; }<CODESPLIT>Finds all providers for the given service .
int length = buffer . bytesBefore ( BsonConstants . STRING_TERMINATION ) ; if ( length < 0 ) throw new IOException ( "string termination not found" ) ; String result = buffer . toString ( buffer . readerIndex ( ) , length , StandardCharsets . UTF_8 ) ; buffer . skipBytes ( length + 1 ) ; return result ; }<CODESPLIT>default visibility for unit test
if ( theCase == null ) throw new NullPointerException ( "Variant case cannot be null" ) ; JSType newCase = ( JSType ) theCase ; if ( cases == null ) cases = new JSType [ 1 ] ; else { JSType [ ] oldCases = cases ; cases = new JSType [ oldCases . length + 1 ] ; System . arraycopy ( oldCases , 0 , cases , 0 , oldCases . length ) ; } newCase . parent = this ; newCase . siblingPosition = cases . length - 1 ; cases [ newCase . siblingPosition ] = newCase ; }<CODESPLIT>Add a case to the variant . Note that every variant must have at least one case .
StringBuilder buf = new StringBuilder ( ) ; buf . append ( "clipVol=" ) . append ( _clipVol ) ; buf . append ( ", disabled=[" ) ; int ii = 0 ; for ( SoundType soundType : _disabledTypes ) { if ( ii ++ > 0 ) { buf . append ( ", " ) ; } buf . append ( soundType ) ; } return buf . append ( "]" ) . toString ( ) ; }<CODESPLIT>Returns a string summarizing our volume settings and disabled sound types .
Map < String , String > map = new HashMap < > ( ) ; for ( Iterator < Object > it = props . keySet ( ) . iterator ( ) ; it . hasNext ( ) ; ) { String key = ( String ) it . next ( ) ; Matcher matcher = keyPattern . matcher ( key ) ; if ( matcher . matches ( ) ) { String id = matcher . group ( 2 ) ; String propertyValue = props . getProperty ( key ) ; map . put ( id , propertyValue ) ; } } return map ; }<CODESPLIT>Returns the map where the key is the 2 group of the pattern and the value is the property value
return impl . rawUncompress ( inputAddr , inputSize , destAddr ) ; }<CODESPLIT>Zero - copy decompress using memory addresses .
this . checkIncreaseArray ( len ) ; System . arraycopy ( b , off , this . buffer , this . pos , len ) ; this . pos += len ; }<CODESPLIT>Writes a byte array content into the stream
PatchHealthCheckHttpRequest request = PatchHealthCheckHttpRequest . newBuilder ( ) . setHealthCheck ( healthCheck == null ? null : healthCheck . toString ( ) ) . setHealthCheckResource ( healthCheckResource ) . addAllFieldMask ( fieldMask ) . build ( ) ; return patchHealthCheck ( request ) ; }<CODESPLIT>Updates a HealthCheck resource in the specified project using the data included in the request . This method supports PATCH semantics and uses the JSON merge patch format and processing rules .
float noxItemMarginDefaultValue = getResources ( ) . getDimension ( R . dimen . default_nox_item_margin ) ; float noxItemMargin = attributes . getDimension ( R . styleable . nox_item_margin , noxItemMarginDefaultValue ) ; noxConfig . setNoxItemMargin ( noxItemMargin ) ; }<CODESPLIT>Configures the nox item default margin used in NoxConfig Shape and NoxItemCatalog to draw nox item instances during the onDraw execution .
return new OperationResult ( index , eventIndex , error , null ) ; }<CODESPLIT>Returns a failed operation result .
Validate . notNull ( lhs ) ; Validate . notNull ( rhs ) ; Validate . notNull ( action ) ; InsnList ret = new InsnList ( ) ; LabelNode notEqualLabelNode = new LabelNode ( ) ; ret . add ( lhs ) ; ret . add ( rhs ) ; ret . add ( new JumpInsnNode ( Opcodes . IF_ICMPNE , notEqualLabelNode ) ) ; ret . add ( action ) ; ret . add ( notEqualLabelNode ) ; return ret ; }<CODESPLIT>Compares two integers and performs some action if the integers are equal .
if ( ! checkFlagConsistency ( flags , width != UNSET ) ) { throw new IllegalArgumentException ( "invalid flags: 0x" + Integer . toHexString ( flags ) ) ; } if ( ( width < 1 || width > MAX_ALLOWED_WIDTH ) && width != UNSET ) { throw new IllegalArgumentException ( "invalid width: " + width ) ; } if ( ( precision < 0 || precision > MAX_ALLOWED_PRECISION ) && precision != UNSET ) { throw new IllegalArgumentException ( "invalid precision: " + precision ) ; } return new FormatOptions ( flags , width , precision ) ; }<CODESPLIT>Creates a options instance with the given values .
Point p = getPoint ( where , "triple click" ) ; exec . mouseAction ( p . x , p . y , 3 , OperaMouseKeys . LEFT ) ; }<CODESPLIT>Triple click is an Opera specific way of selecting a sentence .
Drawable placeholder = attributes . getDrawable ( R . styleable . nox_item_placeholder ) ; if ( placeholder == null ) { placeholder = getContext ( ) . getResources ( ) . getDrawable ( R . drawable . ic_nox ) ; } noxConfig . setPlaceholder ( placeholder ) ; }<CODESPLIT>Configures the placeholder used if there is no another placeholder configured in the NoxItem instances during the onDraw execution .
DependencyGraph . GraphPruner prunedGraph = new DependencyGraph . GraphPruner ( output . getGraph ( ) ) ; for ( Key < ? > key : invalidKeys . getInvalidOptionalKeys ( ) ) { prunedGraph . remove ( key ) ; output . removeBinding ( key ) ; } output . setGraph ( prunedGraph . update ( ) ) ; }<CODESPLIT>Prune all of the invalid optional keys from the graph . After this method all of the keys remaining in the graph are resolvable .
if ( version . equals ( Version . VERSION_1_0 ) ) { return simpleMapperParser_1_0 ; } else if ( version . equals ( Version . VERSION_1_1 ) ) { return simpleMapperParser_1_1 ; } return simpleMapperParser ; }<CODESPLIT>1 . 0 version of parser is different at simple mapperParser
FastStringWriter buf = new FastStringWriter ( ) ; String tmp = templateName . substring ( 1 , templateName . length ( ) ) ; if ( tmp . indexOf ( SLASH ) > - 1 ) { buf . append ( SLASH ) ; int i = tmp . lastIndexOf ( SLASH ) ; buf . append ( tmp . substring ( 0 , i ) ) ; buf . append ( SLASH_UNDR ) ; buf . append ( tmp . substring ( i + 1 , tmp . length ( ) ) ) ; } else { buf . append ( SLASH_UNDR ) ; buf . append ( templateName . substring ( 1 , templateName . length ( ) ) ) ; } if ( includeExtension ) { buf . append ( EXTENSION ) ; } String uri = buf . toString ( ) ; buf . close ( ) ; return uri ; }<CODESPLIT>Used to resolve template names that are not relative to a controller .
Set < String > dirList = context . getResourcePaths ( startPath ) ; if ( dirList != null ) { for ( String path : dirList ) { if ( path . startsWith ( "/WEB-INF/classes/" ) ) { } else if ( path . startsWith ( "/WEB-INF/lib/" ) ) { } else if ( path . endsWith ( "/" ) ) { scanResourcePaths ( path ) ; } else if ( path . startsWith ( "/WEB-INF/tags/" ) ) { if ( path . endsWith ( "/implicit.tld" ) ) { parseTld ( path ) ; } } else if ( path . endsWith ( TLD_EXT ) ) { parseTld ( path ) ; } } } }<CODESPLIT>Scan web application resources for TLDs recursively .
if ( listener != null ) { return listener . duringDrag ( startPoint , dragPoint , evt , inside ) ; } return true ; }<CODESPLIT>Method called during drags .
LOGGER . trace ( "createKeyRingGenerator(String, String, int)" ) ; LOGGER . trace ( "User ID: {}, Password: {}, Key Size: {}" , userId , password == null ? "not set" : "********" , keySize ) ; PGPKeyRingGenerator generator = null ; try { LOGGER . debug ( "Creating RSA key pair generator" ) ; RSAKeyPairGenerator generator1 = new RSAKeyPairGenerator ( ) ; generator1 . init ( new RSAKeyGenerationParameters ( BigInteger . valueOf ( 0x10001 ) , getSecureRandom ( ) , keySize , 12 ) ) ; LOGGER . debug ( "Generating Signing Key Pair" ) ; BcPGPKeyPair signingKeyPair = new BcPGPKeyPair ( PGPPublicKey . RSA_SIGN , generator1 . generateKeyPair ( ) , new Date ( ) ) ; LOGGER . debug ( "Generating Encyption Key Pair" ) ; BcPGPKeyPair encryptionKeyPair = new BcPGPKeyPair ( PGPPublicKey . RSA_ENCRYPT , generator1 . generateKeyPair ( ) , new Date ( ) ) ; LOGGER . debug ( "Generating Signature Key Properties" ) ; PGPSignatureSubpacketGenerator signatureSubpacketGenerator = new PGPSignatureSubpacketGenerator ( ) ; signatureSubpacketGenerator . setKeyFlags ( false , KeyFlags . SIGN_DATA | KeyFlags . CERTIFY_OTHER ) ; signatureSubpacketGenerator . setPreferredSymmetricAlgorithms ( false , getPreferredEncryptionAlgorithms ( ) ) ; signatureSubpacketGenerator . setPreferredHashAlgorithms ( false , getPreferredHashingAlgorithms ( ) ) ; signatureSubpacketGenerator . setPreferredCompressionAlgorithms ( false , getPreferredCompressionAlgorithms ( ) ) ; LOGGER . debug ( "Generating Encyption Key Properties" ) ; PGPSignatureSubpacketGenerator encryptionSubpacketGenerator = new PGPSignatureSubpacketGenerator ( ) ; encryptionSubpacketGenerator . setKeyFlags ( false , KeyFlags . ENCRYPT_COMMS | KeyFlags . ENCRYPT_STORAGE ) ; LOGGER . info ( "Creating PGP Key Ring Generator" ) ; generator = new PGPKeyRingGenerator ( PGPPublicKey . RSA_SIGN , signingKeyPair , userId , new BcPGPDigestCalculatorProvider ( ) . get ( HashAlgorithmTags . SHA1 ) , signatureSubpacketGenerator . generate ( ) , null , new BcPGPContentSignerBuilder ( PGPPublicKey . RSA_SIGN , HashAlgorithmTags . SHA256 ) , new BcPBESecretKeyEncryptorBuilder ( getEncryptionAlgorithm ( ) ) . build ( password . toCharArray ( ) ) ) ; generator . addSubKey ( encryptionKeyPair , encryptionSubpacketGenerator . generate ( ) , null ) ; } catch ( PGPException e ) { LOGGER . error ( "{}" , e . getMessage ( ) ) ; generator = null ; } return generator ; }<CODESPLIT>creates and initializes a PGP Key Ring Generator
try { SimpleDateFormat df = buildDateFormat ( pattern ) ; return df . parse ( dateString ) ; } catch ( ParseException e ) { throw new DateException ( String . format ( "Could not parse %s with pattern %s." , dateString , pattern ) , e ) ; } }<CODESPLIT>Get data from data string using the given pattern and the default date format symbols for the default locale .
synchronized ( _cacheL2 ) { if ( ! _cacheL1 . containsKey ( key ) && ! _cacheL2 . containsKey ( key ) ) { return null ; } Object retval ; Map newMap ; synchronized ( _cacheL1 ) { newMap = HashMapUtils . merge ( _cacheL1 , _cacheL2 ) ; retval = newMap . remove ( key ) ; } _cacheL1 = newMap ; _cacheL2 . clear ( ) ; _missCount = 0 ; return retval ; } }<CODESPLIT>This operation is very expensive . A full copy of the Map is created
String itemType = null ; String subType = cmdb . getConfigurationItemSubType ( ) ; String type = cmdb . getConfigurationItemType ( ) ; String hpsmSettingsSubType = hpsmSettings . getAppSubType ( ) ; String hpsmSettingsType = hpsmSettings . getAppType ( ) ; boolean typeCheck = false ; boolean subTypeCheck = false ; if ( ! "" . equals ( hpsmSettingsType ) ) { typeCheck = true ; } if ( ! "" . equals ( hpsmSettingsSubType ) ) { subTypeCheck = true ; } if ( ! typeCheck && subTypeCheck ) { if ( subType != null && subType . equals ( hpsmSettings . getAppSubType ( ) ) ) { itemType = APP_TYPE ; } else if ( subType != null && subType . equals ( hpsmSettings . getCompSubType ( ) ) ) { itemType = COMPONENT_TYPE ; } else if ( subType != null && subType . equals ( hpsmSettings . getEnvSubType ( ) ) ) { itemType = ENVIRONMENT_TYPE ; } } else if ( typeCheck && ! subTypeCheck ) { if ( type != null && type . equals ( hpsmSettings . getAppType ( ) ) ) { itemType = APP_TYPE ; } else if ( type != null && type . equals ( hpsmSettings . getCompType ( ) ) ) { itemType = COMPONENT_TYPE ; } else if ( type != null && type . equals ( hpsmSettings . getEnvType ( ) ) ) { itemType = ENVIRONMENT_TYPE ; } } else { if ( subType != null && subType . equals ( hpsmSettings . getAppSubType ( ) ) && type != null && type . equals ( hpsmSettings . getAppType ( ) ) ) { itemType = APP_TYPE ; } else if ( subType != null && subType . equals ( hpsmSettings . getCompSubType ( ) ) && type != null && type . equals ( hpsmSettings . getCompType ( ) ) ) { itemType = COMPONENT_TYPE ; } else if ( subType != null && subType . equals ( hpsmSettings . getEnvSubType ( ) ) && type != null && type . equals ( hpsmSettings . getEnvType ( ) ) ) { itemType = ENVIRONMENT_TYPE ; } } return itemType ; }<CODESPLIT>Returns the type of the configuration item .
if ( _tags . size ( ) == 1 ) { final String value = _tags . get ( 0 ) ; if ( "uuid" . equals ( value ) ) { this . uuid = _text ; } else if ( "file-application" . equals ( value ) ) { this . fileApplication = _text ; } else if ( "definition" . equals ( value ) ) { this . definitions . add ( newDefinition ( ) ) ; } } else if ( "definition" . equals ( _tags . get ( 0 ) ) ) { final AbstractDefinition curDef = this . definitions . get ( this . definitions . size ( ) - 1 ) ; curDef . readXML ( _tags . subList ( 1 , _tags . size ( ) ) , _attributes , _text ) ; } else { throw new SAXException ( "Unknown XML Tag: " + _tags + " for: " + this . installFile ) ; } }<CODESPLIT>Read event for given tags path with attributes and text .
String strRecordset = this . getBaseRecord ( ) . makeTableNames ( false ) ; KeyArea keyArea = this . getBaseRecord ( ) . getKeyArea ( 0 ) ; boolean bUseCurrentKeyValues = bUseCurrentValues ? true : keyArea . isNull ( DBConstants . TEMP_KEY_AREA , true ) ; boolean bIsQueryRecord = this . getBaseRecord ( ) . isQueryRecord ( ) ; String sFilter = keyArea . addSelectParams ( "=" , DBConstants . TEMP_KEY_AREA , false , bIsQueryRecord , bUseCurrentKeyValues , null , true , true ) ; if ( sFilter . length ( ) > 0 ) sFilter = " WHERE " + sFilter ; String strSetValues = this . getBaseRecord ( ) . getSQLFields ( DBConstants . SQL_UPDATE_TYPE , bUseCurrentValues ) ; if ( strSetValues . length ( ) == 0 ) return null ; strRecordset = "UPDATE " + strRecordset + " SET " + strSetValues + sFilter ; return strRecordset ; }<CODESPLIT>Get the SQL Update string . UPDATE table SET field1 = value1 field2 = value2 WHERE key = value
for ( Object mock : objects ) { if ( mock instanceof Class < ? > ) { verifyClass ( ( Class < ? > ) mock ) ; } else { EasyMockMethodInvocationControl invocationControl = ( EasyMockMethodInvocationControl ) MockRepository . getInstanceMethodInvocationControl ( mock ) ; if ( invocationControl != null ) { invocationControl . verify ( ) ; } else { if ( isNiceReplayAndVerifyMode ( ) && ! isEasyMocked ( mock ) ) { } else { try { org . easymock . EasyMock . verify ( mock ) ; } catch ( RuntimeException e ) { throw new RuntimeException ( mock + " is not a mock object" , e ) ; } } } } } }<CODESPLIT>Switches the mocks or classes to verify mode . Note that you must use this method when using PowerMock!
if ( mTileNotFoundImage != null ) { putTileIntoCache ( pState . getMapTile ( ) , mTileNotFoundImage , ExpirableBitmapDrawable . NOT_FOUND ) ; for ( final Handler handler : mTileRequestCompleteHandlers ) { if ( handler != null ) { handler . sendEmptyMessage ( MAPTILE_SUCCESS_ID ) ; } } } else { for ( final Handler handler : mTileRequestCompleteHandlers ) { if ( handler != null ) { handler . sendEmptyMessage ( MAPTILE_FAIL_ID ) ; } } } if ( Configuration . getInstance ( ) . isDebugTileProviders ( ) ) { Log . d ( IMapView . LOGTAG , "MapTileProviderBase.mapTileRequestFailed(): " + MapTileIndex . toString ( pState . getMapTile ( ) ) ) ; } }<CODESPLIT>Called by implementation class methods indicating that they have failed to retrieve the requested map tile . a MAPTILE_FAIL_ID message is sent .
if ( factoryId != fd . getFactoryId ( ) ) { throw new IllegalArgumentException ( "Invalid factoryId! Expected: " + fd . getFactoryId ( ) + ", Current: " + factoryId + " in path " + fullPath ) ; } if ( classId != fd . getClassId ( ) ) { throw new IllegalArgumentException ( "Invalid classId! Expected: " + fd . getClassId ( ) + ", Current: " + classId + " in path " + fullPath ) ; } }<CODESPLIT>Validates if the given factoryId and classId match the ones from the fieldDefinition
String label = input . getLabel ( ) ; if ( label == null ) { label = input . getName ( ) ; } if ( addColon && ! label . endsWith ( COLON ) ) { label += COLON ; } return label ; }<CODESPLIT>Returns the label for this component
View view = convertView ; if ( ! ( view instanceof PlaceholderView ) ) { view = new PlaceholderView ( getContext ( ) ) ; } view . setMinimumHeight ( height ) ; return view ; }<CODESPLIT>Inflates an invisible placeholder view with a specific height .
Log . info ( c , "stopService" , "Stopping LdapServer" ) ; this . server . stop ( ) ; Log . info ( c , "stopService" , "Stopping DirectoryService" ) ; service . shutdown ( ) ; Log . info ( c , "stopService" , "Ldap stopped." ) ; }<CODESPLIT>Stop the LdapServer and the Directory service . Use for JUnit teardown . If the service is not stopped then future instances with the same name cannot clean up the file directory .
if ( iMinutes == - 1 ) iMinutes = DEFAULT_CACHED_MINUTES ; cacheMinutes = iMinutes ; if ( iMinutes == 0 ) { if ( timerCache != null ) { timerCache . cancel ( ) ; timerCache = null ; this . stopCache ( ) ; } } else { if ( timerCache != null ) { timerCache . cancel ( ) ; } this . startCache ( ) ; timerTask = new DBTimerTask ( ) ; timerCache = new java . util . Timer ( ) ; timerCache . schedule ( timerTask , cacheMinutes * 60 * 1000 ) ; } }<CODESPLIT>This will set this database to start caching records until they haven t been used for iMinutes minutes .
GVRSceneObject hitObject = hit . getHitObject ( ) ; GVREventManager eventManager = getGVRContext ( ) . getEventManager ( ) ; if ( mEventOptions . contains ( EventOptions . SEND_TOUCH_EVENTS ) ) { if ( mEventOptions . contains ( EventOptions . SEND_TO_LISTENERS ) ) { eventManager . sendEvent ( this , ITouchEvents . class , "onEnter" , hitObject , hit ) ; } if ( mEventOptions . contains ( EventOptions . SEND_TO_HIT_OBJECT ) ) { eventManager . sendEvent ( hitObject , ITouchEvents . class , "onEnter" , hitObject , hit ) ; } if ( mEventOptions . contains ( EventOptions . SEND_TO_SCENE ) && ( mScene != null ) ) { eventManager . sendEvent ( mScene , ITouchEvents . class , "onEnter" , hitObject , hit ) ; } } if ( mEventOptions . contains ( EventOptions . SEND_PICK_EVENTS ) ) { if ( mEventOptions . contains ( EventOptions . SEND_TO_LISTENERS ) ) { eventManager . sendEvent ( this , IPickEvents . class , "onEnter" , hitObject , hit ) ; } if ( mEventOptions . contains ( EventOptions . SEND_TO_HIT_OBJECT ) ) { eventManager . sendEvent ( hitObject , IPickEvents . class , "onEnter" , hitObject , hit ) ; } if ( mEventOptions . contains ( EventOptions . SEND_TO_SCENE ) && ( mScene != null ) ) { eventManager . sendEvent ( mScene , IPickEvents . class , "onEnter" , hitObject , hit ) ; } } }<CODESPLIT>Propagate onEnter events to listeners
return getSendQuotaAsync ( new GetSendQuotaRequest ( ) , asyncHandler ) ; }<CODESPLIT>Simplified method form for invoking the GetSendQuota operation with an AsyncHandler .
final long l = longValue ( ) ; final short i = ( short ) l ; if ( i != l ) { throw new OtpErlangRangeException ( "Value too large for short: " + val ) ; } return i ; }<CODESPLIT>Get this number as a short .
MjdbcSQLException result = null ; String sqlState = getSqlState ( cause ) ; String sqlStatePrefix = null ; if ( sqlState != null && sqlState . length ( ) >= 2 ) { sqlStatePrefix = sqlState . substring ( 0 , 2 ) ; if ( SpringExceptionHandlerConstants . SQL_STATE_PREFIX_BAD_SQL_GRAMMAR . contains ( sqlStatePrefix ) == true ) { result = new BadSqlGrammarException ( reason , SQLState , vendorCode ) ; } else if ( SpringExceptionHandlerConstants . SQL_STATE_PREFIX_DATA_INTEGRITY_VIOLATION . contains ( sqlStatePrefix ) == true ) { result = new DataIntegrityViolationException ( reason , SQLState , vendorCode ) ; } else if ( SpringExceptionHandlerConstants . SQL_STATE_PREFIX_DATA_ACCESS_RESOURCE_FAILURE . contains ( sqlStatePrefix ) == true ) { result = new DataAccessResourceFailureException ( reason , SQLState , vendorCode ) ; } else if ( SpringExceptionHandlerConstants . SQL_STATE_PREFIX_TRANSIENT_DATA_ACCESS_RESOURCE_EXCEPTION . contains ( sqlStatePrefix ) == true ) { result = new TransientDataAccessResourceException ( reason , SQLState , vendorCode ) ; } else if ( SpringExceptionHandlerConstants . SQL_STATE_PREFIX_CONCURRENCY_FAILURE . contains ( sqlStatePrefix ) == true ) { result = new ConcurrencyFailureException ( reason , SQLState , vendorCode ) ; } } return result ; }<CODESPLIT>Checks SQL state and tries to convert it into Spring SQL Exception . This implementation is vendor free .
if ( name == null ) { return pattern . equals ( "" ) ; } if ( all != null ) { return all . equals ( name ) ; } if ( middle != null ) { return name . contains ( middle ) ; } if ( start != null && ! name . startsWith ( start ) ) { return false ; } return end == null || name . endsWith ( end ) ; }<CODESPLIT>Checks if Simon name matches this pattern .
nslimitselector obj = new nslimitselector ( ) ; obj . set_selectorname ( selectorname ) ; nslimitselector response = ( nslimitselector ) obj . get_resource ( service ) ; return response ; }<CODESPLIT>Use this API to fetch nslimitselector resource of given name .
double a = eqn [ 2 ] ; double b = eqn [ 1 ] ; double c = eqn [ 0 ] ; int rc = 0 ; if ( a == 0f ) { if ( b == 0f ) { return - 1 ; } res [ rc ++ ] = - c / b ; } else { double d = b * b - 4f * a * c ; if ( d < 0f ) { return 0 ; } d = Math . sqrt ( d ) ; res [ rc ++ ] = ( - b + d ) / ( a * 2f ) ; if ( d != 0f ) { res [ rc ++ ] = ( - b - d ) / ( a * 2f ) ; } } return fixRoots ( res , rc ) ; }<CODESPLIT>Solves quadratic equation
final Set < Term > ret = new HashSet < Term > ( ) ; for ( final StatementGroup sg : statementGroups ) { for ( final Statement stmt : sg . getAllStatements ( ) ) { ret . addAll ( stmt . getAllTerms ( ) ) ; } } return ret ; }<CODESPLIT>Returns the set of all terms contained within the document .
if ( ! hasLock ( op ) ) { throw new PSQLException ( GT . tr ( "Tried to cancel an inactive copy operation" ) , PSQLState . OBJECT_NOT_IN_STATE ) ; } SQLException error = null ; int errors = 0 ; try { if ( op instanceof CopyIn ) { synchronized ( this ) { LOGGER . log ( Level . FINEST , "FE => CopyFail" ) ; final byte [ ] msg = Utils . encodeUTF8 ( "Copy cancel requested" ) ; pgStream . sendChar ( 'f' ) ; pgStream . sendInteger4 ( 5 + msg . length ) ; pgStream . send ( msg ) ; pgStream . sendChar ( 0 ) ; pgStream . flush ( ) ; do { try { processCopyResults ( op , true ) ; } catch ( SQLException se ) { errors ++ ; if ( error != null ) { SQLException e = se ; SQLException next ; while ( ( next = e . getNextException ( ) ) != null ) { e = next ; } e . setNextException ( error ) ; } error = se ; } } while ( hasLock ( op ) ) ; } } else if ( op instanceof CopyOut ) { sendQueryCancel ( ) ; } } catch ( IOException ioe ) { throw new PSQLException ( GT . tr ( "Database connection failed when canceling copy operation" ) , PSQLState . CONNECTION_FAILURE , ioe ) ; } finally { synchronized ( this ) { if ( hasLock ( op ) ) { unlock ( op ) ; } } } if ( op instanceof CopyIn ) { if ( errors < 1 ) { throw new PSQLException ( GT . tr ( "Missing expected error response to copy cancel request" ) , PSQLState . COMMUNICATION_ERROR ) ; } else if ( errors > 1 ) { throw new PSQLException ( GT . tr ( "Got {0} error responses to single copy cancel request" , String . valueOf ( errors ) ) , PSQLState . COMMUNICATION_ERROR , error ) ; } } }<CODESPLIT>Finishes a copy operation and unlocks connection discarding any exchanged data .
return requestedAttributeTypes ; }<CODESPLIT>Gets the requestedAttributeTypes value for this TargetingIdeaSelector .
if ( OntRelationMention_Type . featOkTst && ( ( OntRelationMention_Type ) jcasType ) . casFeat_range == null ) jcasType . jcas . throwFeatMissing ( "range" , "de.julielab.jules.types.OntRelationMention" ) ; jcasType . ll_cas . ll_setRefValue ( addr , ( ( OntRelationMention_Type ) jcasType ) . casFeatCode_range , jcasType . ll_cas . ll_getFSRef ( v ) ) ; }<CODESPLIT>setter for range - sets
if ( relatedRolePlayer == null ) { relatedRolePlayer = new ArrayList < com . ibm . wsspi . security . wim . model . RolePlayer > ( ) ; } return this . relatedRolePlayer ; }<CODESPLIT>Gets the value of the relatedRolePlayer property .
return ( unifier == null ) ? null : unifier . getBinding ( new UFreeIdent . Key ( identifier ( ) ) ) ; }<CODESPLIT>Gets the binding of the underlying identifier in the unifier .
entityCache . clearCache ( CommercePriceEntryImpl . class ) ; finderCache . clearCache ( FINDER_CLASS_NAME_ENTITY ) ; finderCache . clearCache ( FINDER_CLASS_NAME_LIST_WITH_PAGINATION ) ; finderCache . clearCache ( FINDER_CLASS_NAME_LIST_WITHOUT_PAGINATION ) ; }<CODESPLIT>Clears the cache for all commerce price entries .
if ( initial < MINIMUM_CAPACITY ) { return MINIMUM_CAPACITY ; } if ( initial > MAXIMUM_CAPACITY ) { return MAXIMUM_CAPACITY ; } int capacity = 1 ; while ( capacity < initial ) { capacity <<= 1 ; } return capacity ; }<CODESPLIT>Compute capacity given initial capacity .
await ( k , timeout , unit ) ; return cache . get ( k ) ; }<CODESPLIT>Retrieve the value associated with the given key blocking as long as necessary up to the specified maximum .
String classpathProperty = System . getProperty ( "druid.hadoop.internal.classpath" ) ; if ( classpathProperty == null ) { classpathProperty = System . getProperty ( "java.class.path" ) ; } String [ ] jarFiles = classpathProperty . split ( File . pathSeparator ) ; final Configuration conf = job . getConfiguration ( ) ; final FileSystem fs = distributedClassPath . getFileSystem ( conf ) ; if ( fs instanceof LocalFileSystem ) { return ; } for ( String jarFilePath : jarFiles ) { final File jarFile = new File ( jarFilePath ) ; if ( jarFile . getName ( ) . endsWith ( ".jar" ) ) { try { RetryUtils . retry ( ( ) -> { if ( isSnapshot ( jarFile ) ) { addSnapshotJarToClassPath ( jarFile , intermediateClassPath , fs , job ) ; } else { addJarToClassPath ( jarFile , distributedClassPath , intermediateClassPath , fs , job ) ; } return true ; } , shouldRetryPredicate ( ) , NUM_RETRIES ) ; } catch ( Exception e ) { throw new RuntimeException ( e ) ; } } } }<CODESPLIT>Uploads jar files to hdfs and configures the classpath . Snapshot jar files are uploaded to intermediateClasspath and not shared across multiple jobs . Non - Snapshot jar files are uploaded to a distributedClasspath and shared across multiple jobs .
WebElement element = findElement ( false ) ; WebDriver wd = getGUIDriver ( ) . getWrappedDriver ( ) ; try { ( ( JavascriptExecutor ) wd ) . executeScript ( javascript , element ) ; } catch ( Exception e ) { long time = System . currentTimeMillis ( ) + 2000 ; boolean success = false ; while ( ! success && System . currentTimeMillis ( ) < time ) { try { ( ( JavascriptExecutor ) wd ) . executeScript ( javascript , element ) ; success = true ; } catch ( Exception e2 ) { try { Thread . sleep ( 500 ) ; } catch ( InterruptedException e1 ) { } e = e2 ; } } if ( ! success ) { throw new RuntimeException ( e ) ; } } }<CODESPLIT>Executes JavaScript code on the current element in the current frame or window .
return set ( instant , FieldUtils . getWrappedValue ( get ( instant ) , amount , 0 , iDivisor - 1 ) ) ; }<CODESPLIT>Add the specified amount to the specified time instant wrapping around within the remainder range if necessary . The amount added may be negative .
Transaction tx = new Transaction ( wallet . getParams ( ) ) ; if ( ! getTotalValue ( ) . subtract ( valueToMe ) . equals ( Coin . ZERO ) ) { tx . addOutput ( getTotalValue ( ) . subtract ( valueToMe ) , LegacyAddress . fromKey ( wallet . getParams ( ) , getClientKey ( ) ) ) ; } tx . addInput ( contract . getOutput ( 0 ) ) ; return SendRequest . forTx ( tx ) ; }<CODESPLIT>Create a payment transaction with valueToMe going back to us
if ( null == authToken ) { return null ; } return authToken . split ( TOKEN_SEPARATOR ) [ 0 ] ; }<CODESPLIT>Extracts the user name from token .
ClassLoader proxyClassLoader = classLoader ; Class < ? > [ ] interfaces = new Class [ interfaceNames . length ] ; Class < ? > nonPublicInterface = null ; for ( int i = 0 ; i < interfaceNames . length ; i ++ ) { Class < ? > intf = loadClass ( interfaceNames [ i ] ) ; if ( ! Modifier . isPublic ( intf . getModifiers ( ) ) ) { ClassLoader classLoader = getClassLoader ( intf ) ; if ( nonPublicInterface != null ) { if ( classLoader != proxyClassLoader ) { throw new IllegalAccessError ( nonPublicInterface + " and " + intf + " both declared non-public in different class loaders" ) ; } } else { nonPublicInterface = intf ; proxyClassLoader = classLoader ; } } interfaces [ i ] = intf ; } try { return Proxy . getProxyClass ( proxyClassLoader , interfaces ) ; } catch ( IllegalArgumentException ex ) { throw new ClassNotFoundException ( null , ex ) ; } }<CODESPLIT>Delegates class loading to the specified class loader .
double [ ] x = new double [ data . length ] ; for ( int i = 0 ; i < x . length ; i ++ ) { x [ i ] = sum ( data [ i ] ) ; } return x ; }<CODESPLIT>Returns the row sums for a matrix .
int oldCapacity = table . length ; long oldTable [ ] = table ; int oldValues [ ] = values ; byte oldState [ ] = state ; long newTable [ ] = new long [ newCapacity ] ; int newValues [ ] = new int [ newCapacity ] ; byte newState [ ] = new byte [ newCapacity ] ; this . lowWaterMark = chooseLowWaterMark ( newCapacity , this . minLoadFactor ) ; this . highWaterMark = chooseHighWaterMark ( newCapacity , this . maxLoadFactor ) ; this . table = newTable ; this . values = newValues ; this . state = newState ; this . freeEntries = newCapacity - this . distinct ; for ( int i = oldCapacity ; i -- > 0 ; ) { if ( oldState [ i ] == FULL ) { long element = oldTable [ i ] ; int index = indexOfInsertion ( element ) ; newTable [ index ] = element ; newValues [ index ] = oldValues [ i ] ; newState [ index ] = FULL ; } } }<CODESPLIT>Rehashes the contents of the receiver into a new table with a smaller or larger capacity . This method is called automatically when the number of keys in the receiver exceeds the high water mark or falls below the low water mark .
int headerSize = header . size ( ) ; if ( headerSize > capacity ) { clear ( ) ; return ; } while ( capacity - size < headerSize ) { remove ( ) ; } hpackHeaderFields [ head ++ ] = header ; size += header . size ( ) ; if ( head == hpackHeaderFields . length ) { head = 0 ; } }<CODESPLIT>Add the header field to the dynamic table . Entries are evicted from the dynamic table until the size of the table and the new header field is less than or equal to the table s capacity . If the size of the new entry is larger than the table s capacity the dynamic table will be cleared .
for ( final LauncherListener listener : listenersLauncher ) { listener . notifyFired ( ) ; } for ( final LaunchableConfig launchableConfig : launchables ) { final Media media = Medias . create ( launchableConfig . getMedia ( ) ) ; final Featurable featurable = factory . create ( media ) ; try { final Launchable launchable = featurable . getFeature ( Launchable . class ) ; if ( launchableConfig . getDelay ( ) > 0 ) { delayed . add ( new DelayedLaunch ( launchableConfig , initial , featurable , launchable ) ) ; } else { launch ( launchableConfig , initial , featurable , launchable ) ; } } catch ( final LionEngineException exception ) { featurable . getFeature ( Identifiable . class ) . destroy ( ) ; throw exception ; } } }<CODESPLIT>Called when fire is performed .
_invmgr = invmgr ; _omgr = omgr ; invmgr . registerProvider ( new TimeBaseProvider ( ) , TimeBaseMarshaller . class , GLOBAL_GROUP ) ; }<CODESPLIT>Registers the time provider with the appropriate managers . Called by the presents server at startup .
return new UfsJournalFile ( location , start , end , false ) ; }<CODESPLIT>Creates a journal log file .
try { return new CertificateRep ( type , getEncoded ( ) ) ; } catch ( CertificateException e ) { throw new java . io . NotSerializableException ( "java.security.cert.Certificate: " + type + ": " + e . getMessage ( ) ) ; } }<CODESPLIT>Replace the Certificate to be serialized .
return arguments . length == 0 ? null : extractThrowable ( arguments [ arguments . length - 1 ] ) ; }<CODESPLIT>Returns a throwable if the last argument is one .
List < Map < IBond , IBond > > bondMaps = new ArrayList < Map < IBond , IBond > > ( ) ; for ( Map < IAtom , IAtom > mapping : mappings ) { bondMaps . add ( makeBondMapOfAtomMap ( ac1 , ac2 , mapping ) ) ; } return bondMaps ; }<CODESPLIT>Returns bond maps between source and target molecules based on the atoms
LongConstant entry = getLongByValue ( value ) ; if ( entry != null ) return entry ; entry = new LongConstant ( this , _entries . size ( ) , value ) ; addConstant ( entry ) ; addConstant ( null ) ; return entry ; }<CODESPLIT>Adds a long constant .
return getOrOpen ( name , file , true ) ; }<CODESPLIT>Get the cached GeoPackage or open and cache the GeoPackage file
int idx = clz_name . lastIndexOf ( 'V' ) ; if ( idx == - 1 ) return - 1 ; try { return Integer . valueOf ( clz_name . substring ( idx + 1 ) ) ; } catch ( NumberFormatException ex ) { return - 1 ; } }<CODESPLIT>Extract the version number from the schema class name . Returns - 1 if there s no version number at the end of the classname .
if ( shapeAppearanceModel . isRoundRect ( ) ) { float cornerSize = shapeAppearanceModel . getTopRightCorner ( ) . getCornerSize ( ) ; canvas . drawRoundRect ( bounds , cornerSize , cornerSize , paint ) ; } else { canvas . drawPath ( path , paint ) ; } }<CODESPLIT>Draw the path or try to draw a round rect if possible .
List < AnalyzerJob > candidates = new ArrayList < > ( _jobs ) ; candidates = CollectionUtils2 . refineCandidates ( candidates , o -> { final String actualDescriptorName = o . getDescriptor ( ) . getDisplayName ( ) ; return descriptorName . equals ( actualDescriptorName ) ; } ) ; if ( analyzerName != null ) { candidates = CollectionUtils2 . refineCandidates ( candidates , o -> { final String actualAnalyzerName = o . getName ( ) ; return analyzerName . equals ( actualAnalyzerName ) ; } ) ; } if ( analyzerInputName != null ) { candidates = CollectionUtils2 . refineCandidates ( candidates , o -> { final InputColumn < ? > inputColumn = getIdentifyingInputColumn ( o ) ; if ( inputColumn == null ) { return false ; } return analyzerInputName . equals ( inputColumn . getName ( ) ) ; } ) ; } if ( candidates . isEmpty ( ) ) { logger . error ( "No more AnalyzerJob candidates to choose from" ) ; return null ; } else if ( candidates . size ( ) > 1 ) { logger . warn ( "Multiple ({}) AnalyzerJob candidates to choose from, picking first" ) ; } return candidates . iterator ( ) . next ( ) ; }<CODESPLIT>Gets the best candidate analyzer job based on search criteria offered in parameters .
return tradesCallbacks . removeCallback ( tradeSymbol , callback ) ; }<CODESPLIT>Remove a executed trade callback
List < HealthDependency > primaryHealthDependencies = healthDependencies . values ( ) . stream ( ) . filter ( HealthDependency :: isPrimary ) . collect ( Collectors . toList ( ) ) ; return checkHealth ( primaryHealthDependencies ) ; }<CODESPLIT>Performs the Primary Health Check .
appfwxmlerrorpage obj = new appfwxmlerrorpage ( ) ; appfwxmlerrorpage [ ] response = ( appfwxmlerrorpage [ ] ) obj . get_resources ( service ) ; return response [ 0 ] ; }<CODESPLIT>Use this API to fetch all the appfwxmlerrorpage resources that are configured on netscaler .
this . client . addResponseInterceptor ( new HttpResponseInterceptor ( ) { public void process ( final HttpResponse response , final HttpContext context ) throws HttpException , IOException { Header header = response . getFirstHeader ( "Location" ) ; if ( header != null ) context . setAttribute ( "Location" , header . getValue ( ) ) ; } } ) ; }<CODESPLIT>This method is used to capture Location headers after HttpClient redirect handling .
int numPoints = points . size ( ) ; if ( tmp . length < numPoints ) { tmp = new double [ numPoints ] ; indexes = new int [ numPoints ] ; } for ( int i = 0 ; i < numPoints ; i ++ ) { tmp [ i ] = distance . valueAt ( points . get ( i ) , splitAxis ) ; } QuickSelect . selectIndex ( tmp , medianNum , numPoints , indexes ) ; }<CODESPLIT>Uses quick - select to find the median value
StringTokenizer parser = new StringTokenizer ( pHtml , "<>&" , true ) ; while ( parser . hasMoreTokens ( ) ) { String token = parser . nextToken ( ) ; if ( token . equals ( "<" ) ) { pOut . print ( "&lt;" ) ; } else if ( token . equals ( ">" ) ) { pOut . print ( "&gt;" ) ; } else if ( token . equals ( "&" ) ) { pOut . print ( "&amp;" ) ; } else { pOut . print ( token ) ; } } }<CODESPLIT>writeHtml ensures that the text being outputted appears as it was entered . This prevents users from hacking the system by entering html or jsp code into an entry form where that value will be displayed later in the site .
String result = node . getLocalName ( ) ; return result == null ? node . getNodeName ( ) : result ; }<CODESPLIT>Returns the node name . First tries local name . If this is null returns instead the full node name .
mExpiryDateEditText . setText ( DateUtils . createDateStringFromIntegerInput ( month , year ) ) ; }<CODESPLIT>Set the expiration date . Method invokes completion listener and changes focus to the CVC field if a valid date is entered .
scriptInfo . setApplyDdl ( "-- drop dependencies\n" + write . applyDropDependencies ( ) . getBuffer ( ) + "\n" + "-- apply changes\n" + write . apply ( ) . getBuffer ( ) + write . applyForeignKeys ( ) . getBuffer ( ) + write . applyHistoryView ( ) . getBuffer ( ) + write . applyHistoryTrigger ( ) . getBuffer ( ) ) ; }<CODESPLIT>Write the Apply DDL buffers to the writer .
if ( clz1 == null || clz2 == null ) { throw new NullPointerException ( ) ; } return clz1 == clz2 || clz1 . getName ( ) . equals ( clz2 . getName ( ) ) ; }<CODESPLIT>Compares if two classes are equal or their class names are equal .
String fileName = source instanceof FileSource ? ( ( FileSource ) source ) . getFileName ( ) : null ; doAddSharedFunction ( source , fileName ) ; }<CODESPLIT>Add shared function by ISource
this . commercePriceListService = commercePriceListService ; }<CODESPLIT>Sets the commerce price list remote service .
HtmlTree htmltree = new HtmlTree ( HtmlTag . MAIN ) ; htmltree . setRole ( Role . MAIN ) ; return htmltree ; }<CODESPLIT>Generates a MAIN tag with role attribute .
cachepolicylabel_stats obj = new cachepolicylabel_stats ( ) ; obj . set_labelname ( labelname ) ; cachepolicylabel_stats response = ( cachepolicylabel_stats ) obj . stat_resource ( service ) ; return response ; }<CODESPLIT>Use this API to fetch statistics of cachepolicylabel_stats resource of given name .
if ( ! broker . isModified ( ) ) { return ; } try { BufferedWriter bout = new BufferedWriter ( new FileWriter ( mapfile ) ) ; broker . writeTo ( bout ) ; bout . close ( ) ; } catch ( IOException ioe ) { throw new RuntimeException ( "Unable to store component ID map [mapfile=" + mapfile + "]" , ioe ) ; } }<CODESPLIT>Stores a persistent representation of the supplied hashmap ID broker in the specified file .
jdbcTemplate . execute ( new ConnectionCallback < Object > ( ) { public Object doInConnection ( Connection connection ) throws SQLException , DataAccessException { crud . update ( connection , values ) ; return null ; } } ) ; }<CODESPLIT>update the objects .
s . getAsInt ( )          getAsInt ( )            c . accept ( value ) ; return this ; } } ; }<CODESPLIT>Construct a MutableInt that gets and sets an external value using the provided Supplier and Consumer
LOGGER . debug ( "Reloading configuration." ) ; this . configWriteLock . lock ( ) ; try { this . config = config ; processAppPackages ( config ) ; } finally { this . configWriteLock . unlock ( ) ; } }<CODESPLIT>Replace the configuration of this instance directly .
putProperty ( PropertyKey . Host . name ( ) , IpUtils . getHostName ( ) ) ; putProperty ( PropertyKey . Type . name ( ) , type ) ; putProperty ( PropertyKey . Status . name ( ) , Status . Start . name ( ) ) ; }<CODESPLIT>Add properties to properties map on transaction start
if ( sequence == null ) { sequence = new ArrayList < SequenceListType . Sequence > ( ) ; } return this . sequence ; }<CODESPLIT>Gets the value of the sequence property .
if ( include ) { Number value = supplier . get ( ) ; if ( value != null ) { map . put ( getFieldName ( fieldName ) , value ) ; } } return this ; }<CODESPLIT>Adds the number value to the provided map under the provided field name if it should be included . The supplier is only invoked if the field is to be included .
if ( TraceComponent . isAnyTracingEnabled ( ) && tc . isEntryEnabled ( ) ) SibTr . entry ( tc , "disconnectCardOneConsumer" ) ; Object [ ] clonedConsumerPoints = null ; synchronized ( consumerPoints ) { clonedConsumerPoints = consumerPoints . toArray ( ) ; } SILimitExceededException e = new SILimitExceededException ( nls . getFormattedMessage ( "CONSUMERCARDINALITY_LIMIT_REACHED_CWSIP0472" , new Object [ ] { getDestName ( ) , getLocalisationUuid ( ) . toString ( ) } , null ) ) ; FFDCFilter . processException ( e , "com.ibm.ws.sib.processor.impl.RemoteConsumerDispatcher.disconnectCardOneConsumer" , "1:945:1.97.2.21" , this ) ; SibTr . exception ( tc , e ) ; for ( int i = 0 ; i < clonedConsumerPoints . length ; i ++ ) { DispatchableKey ck = ( DispatchableKey ) clonedConsumerPoints [ i ] ; ck . notifyConsumerPointAboutException ( e ) ; } if ( TraceComponent . isAnyTracingEnabled ( ) && tc . isEntryEnabled ( ) ) SibTr . exit ( tc , "disconnectCardOneConsumer" ) ; }<CODESPLIT>The disconnectCardOneConsumer method is invoked by the Anycast Input Handler to notify it that the current cardinality - one consumer must be disconnected . This can happen when this RME becomes unreachable and the DME allows a consumer in a separate RME to connect . As soon as this RME becomes reachable again the DME sends ControlCardinalityInfo to trigger this consumer s disconnection .
return ctx . getUsername ( ) != null && ctx . getUsername ( ) . equals ( adminName ) && ctx . getPassword ( ) != null && ctx . getPassword ( ) . equals ( adminPass ) ; }<CODESPLIT>Check if the given credentials allow administrative access
if ( settings . autostart ( ) ) { runner = settings . getRunner ( ) ; logger . config ( "Using runner " + runner . getClass ( ) . getSimpleName ( ) ) ; } else { settings . setPort ( OperaDefaults . SERVER_DEFAULT_PORT_IDENTIFIER ) ; } createScopeServices ( ) ; if ( runner != null ) { runner . startOpera ( ) ; } services . init ( ) ; debugger = services . getDebugger ( ) ; debugger . setDriver ( this ) ; windowManager = services . getWindowManager ( ) ; exec = services . getExec ( ) ; core = services . getCore ( ) ; cookieManager = services . getCookieManager ( ) ; mouse = new OperaMouse ( this ) ; keyboard = new OperaKeyboard ( this ) ; services . getConsoleLogger ( ) . onConsoleMessage ( new ConsoleMessageConverter ( logs ) ) ; settings . setProduct ( utils ( ) . getProduct ( ) ) ; if ( ! utils ( ) . getUserAgent ( ) . contains ( "Mini" ) ) { preferences = new OperaScopePreferences ( services . getPrefs ( ) ) ; preferences ( ) . set ( "User Prefs" , "Ignore Unrequested Popups" , false ) ; if ( utils ( ) . getProduct ( ) . is ( MOBILE ) ) { preferences ( ) . set ( "User Prefs" , "Allow Autofocus Form Element" , true ) ; } } proxy = new OperaProxy ( this ) ; proxy . parse ( settings . getProxy ( ) ) ; }<CODESPLIT>Initialize required Scope services .
byte [ ] hash ; try { hash = MessageDigest . getInstance ( "MD5" ) . digest ( string . getBytes ( "UTF-8" ) ) ; } catch ( NoSuchAlgorithmException e ) { throw new RuntimeException ( "Huh, MD5 should be supported?" , e ) ; } catch ( UnsupportedEncodingException e ) { throw new RuntimeException ( "Huh, UTF-8 should be supported?" , e ) ; } StringBuilder hex = new StringBuilder ( hash . length * 2 ) ; for ( byte b : hash ) { int i = ( b & 0xFF ) ; if ( i < 0x10 ) hex . append ( '0' ) ; hex . append ( Integer . toHexString ( i ) ) ; } return hex . toString ( ) ; }<CODESPLIT>Calculate the MD5 of a given String
for ( int i = 0 ; dir != null && i < 20 ; i ++ ) { File rawDir = findResRawDir ( dir ) ; if ( rawDir != null ) { return rawDir ; } dir = dir . getParentFile ( ) ; } return null ; }<CODESPLIT>Look for the resource - directory in the current directory or the directories above . Then look for the raw - directory underneath the resource - directory .
ELContext ctx = this . getELContext ( ) ; return ctx . getELResolver ( ) . getValue ( ctx , null , pName ) ; }<CODESPLIT>LIDB4147 - 9 Begin - modified for JSP 2 . 1
KeyValue keyValue ; DependantValue key ; String propertyRef = collection . getReferencedPropertyName ( ) ; if ( propertyRef == null ) { keyValue = collection . getOwner ( ) . getIdentifier ( ) ; } else { keyValue = ( KeyValue ) collection . getOwner ( ) . getProperty ( propertyRef ) . getValue ( ) ; } if ( LOG . isDebugEnabled ( ) ) LOG . debug ( "[GrailsDomainBinder] creating dependant key value to table [" + keyValue . getTable ( ) . getName ( ) + "]" ) ; key = new DependantValue ( metadataBuildingContext , collection . getCollectionTable ( ) , keyValue ) ; key . setTypeName ( null ) ; key . setNullable ( true ) ; key . setUpdateable ( false ) ; return key ; }<CODESPLIT>Creates the DependentValue object that forms a primary key reference for the collection .
AVariableExp var = getVarExp ( name , vardef ) ; var . setType ( type ) ; return var ; }<CODESPLIT>Generate Var Exp with everything!
if ( Strings . isNullOrEmpty ( arg ) || arg . trim ( ) . isEmpty ( ) ) { return true ; } return false ; }<CODESPLIT>Determines whether the parameter string is null empty or whitespace .
return queryBlockByNumber ( getShuffledPeers ( EnumSet . of ( PeerRole . LEDGER_QUERY ) ) , blockNumber ) ; }<CODESPLIT>query this channel for a Block by the blockNumber . The request is retried on all peers till successful
return getGettersAsMap ( type ) . get ( name ) ; }<CODESPLIT>Search getter for given class and property name .
try { return new String ( decodeLZ ( data ) , "UTF-8" ) ; } catch ( UnsupportedEncodingException e ) { throw new RuntimeException ( e ) ; } }<CODESPLIT>Decode lz to string string .
return new AirlineFlightUpdateTemplateBuilder ( introMessage , locale , pnrNumber , updateType ) ; }<CODESPLIT>Adds an Airline Flight Update Template to the response .
StringBuilder buf = new StringBuilder ( ) ; if ( null != aditionalpath ) { arguments . add ( argument ) ; buf . append ( aditionalpath ) ; } if ( modules != null && modules . length > 0 ) { if ( ! arguments . contains ( argument ) ) { arguments . add ( argument ) ; } for ( int i = 0 ; i < modules . length ; ++ i ) { Module module = modules [ i ] ; Artifact artifact = null ; @ SuppressWarnings ( "unchecked" ) Set < Artifact > allArtifacts = project . getArtifacts ( ) ; for ( Artifact art : allArtifacts ) { if ( art . getGroupId ( ) . equals ( module . getGroupId ( ) ) && art . getArtifactId ( ) . equals ( module . getArtifactId ( ) ) && StringUtils . defaultString ( module . getClassifier ( ) ) . equals ( StringUtils . defaultString ( art . getClassifier ( ) ) ) && StringUtils . defaultString ( module . getType ( ) , "jar" ) . equals ( StringUtils . defaultString ( art . getType ( ) ) ) ) { artifact = art ; break ; } } if ( artifact == null ) { throw new MojoExecutionException ( "The artifact " + module . toString ( ) + " referenced in aspectj plugin as " + role + ", is not found the project dependencies" ) ; } if ( buf . length ( ) != 0 ) { buf . append ( File . pathSeparatorChar ) ; } buf . append ( artifact . getFile ( ) . getPath ( ) ) ; } } if ( buf . length ( ) > 0 ) { String pathString = buf . toString ( ) ; arguments . add ( pathString ) ; getLog ( ) . debug ( "Adding " + argument + ": " + pathString ) ; } }<CODESPLIT>Finds all artifacts in the weavemodule property and adds them to the ajc options .
String client = request . getHeader ( "aerogear-sender" ) ; if ( hasValue ( client ) ) { return client ; } return request . getHeader ( "user-agent" ) ; }<CODESPLIT>Reads the aerogear - sender header to check if an AeroGear Sender client was used . If the header value is NULL the value of the standard user - agent header is returned
return Flux . defer ( ( ) -> { requireNonNull ( address , "requestMany address parameter is required and must not be null" ) ; requireNonNull ( transport , "transport is required and must not be null" ) ; return transport . create ( address ) . requestStream ( request ) . map ( message -> ServiceMessageCodec . decodeData ( message , responseType ) ) . map ( this :: throwIfError ) ; } ) ; }<CODESPLIT>Given an address issues request to remote service which returns stream of service messages back .
ObjectInputStream ois = null ; try { ois = new ObjectInputStream ( PrivilegedFileHelper . fileInputStream ( incrementalBackupFile ) ) ; while ( true ) { TransactionChangesLog changesLog = readExternal ( ois ) ; changesLog . setSystemId ( Constants . JCR_CORE_RESTORE_WORKSPACE_INITIALIZER_SYSTEM_ID ) ; ChangesLogIterator cli = changesLog . getLogIterator ( ) ; while ( cli . hasNextLog ( ) ) { if ( cli . nextLog ( ) . getEventType ( ) == ExtendedEvent . LOCK ) { cli . removeLog ( ) ; } } saveChangesLog ( changesLog ) ; } } catch ( EOFException ioe ) { if ( LOG . isTraceEnabled ( ) ) { LOG . trace ( "An exception occurred: " + ioe . getMessage ( ) ) ; } } }<CODESPLIT>Perform incremental restore operation .
object          consumers . put ( object , new Consumer < Integer > ( ) { int count ; public void consume ( final ByteBuffer buffer ) { count += buffer . remaining ( ) ; } public Integer finish ( ) { return count ; } } ) ; return object ; }<CODESPLIT>Initializes a byte counter on this channel .
logger . entering ( locator ) ; boolean flag = false ; try { flag = HtmlElementUtils . locateElement ( locator ) != null ; } catch ( NoSuchElementException e ) { } logger . exiting ( flag ) ; return flag ; }<CODESPLIT>Checks if the provided element is present on the page based on the locator provided
buffer           t1               buffer   buffer . delete ( 0 , 4 )  buffer . append ( " in the middle" )  System . err . println ( "Middle" )  try  Thread . sleep ( 4000 )   catch ( Exception e )   buffer . append ( " of fall" )  System . err . println ( "Fall" )       t2             try { Thread . sleep ( 1000 ) ; } catch ( Exception e ) { } buffer . append ( " jump over the fence" ) ; System . err . println ( "Fence" ) ; } } ; t1 . start ( ) ; t2 . start ( ) ; t1 . join ( ) ; t2 . join ( ) ; System . err . println ( buffer ) ; }<CODESPLIT>We have more input since wait started
double alphaNew ; if ( Double . isNaN ( gp ) ) { alphaNew = SearchInterpolate . quadratic ( fprev , gprev , stprev , fp , stp ) ; } else { alphaNew = SearchInterpolate . cubic2 ( fprev , gprev , stprev , fp , gp , stp ) ; if ( Double . isNaN ( alphaNew ) ) alphaNew = SearchInterpolate . quadratic ( fprev , gprev , stprev , fp , stp ) ; } double l , u ; if ( boundA < boundB ) { l = boundA ; u = boundB ; } else { l = boundB ; u = boundA ; } if ( alphaNew < l ) alphaNew = l ; else if ( alphaNew > u ) alphaNew = u ; return alphaNew ; }<CODESPLIT>Use either quadratic of cubic interpolation to guess the minimum .
logger . finer ( "Checking semantic constraints on datatype " + dataType . name ) ; final List < SemanticError > errors = new ArrayList < SemanticError > ( ) ; final Set < String > constructorNames = new HashSet < String > ( ) ; for ( Constructor constructor : dataType . constructors ) { logger . finest ( "Checking semantic constraints on constructor " + constructor . name + " in datatype " + dataType . name ) ; if ( dataType . constructors . size ( ) > 1 && dataType . name . equals ( constructor . name ) ) { logger . info ( "Constructor with same name as its data type " + dataType . name + "." ) ; errors . add ( _ConstructorDataTypeConflict ( dataType . name ) ) ; } if ( constructorNames . contains ( constructor . name ) ) { logger . info ( "Two constructors with same name " + constructor . name + " in data type " + dataType . name + "." ) ; errors . add ( _DuplicateConstructor ( dataType . name , constructor . name ) ) ; } else { constructorNames . add ( constructor . name ) ; } errors . addAll ( check ( dataType , constructor ) ) ; } return errors ; }<CODESPLIT>Checks a data type for duplicate constructor names or constructors having the same name as the data type
"unchecked" , "rawtypes" } ) protected void registerDependency ( List additionalList , GrailsPlugin plugin ) { if ( ! addedNames . contains ( plugin . getName ( ) ) ) { addedNames . add ( plugin . getName ( ) ) ; additionalList . add ( plugin ) ; addPluginDependencies ( additionalList , plugin ) ; } }<CODESPLIT>Adds a plugin to the additional if this hasn t happened already
HttpResponse response = httpClient . execute ( request ) ; if ( debugLogging ) { logRequest ( request , response ) ; } String responsePayload = CharStreams . toString ( new InputStreamReader ( response . getEntity ( ) . getContent ( ) , Charsets . UTF_8 ) ) ; try { return jsonMapper . readTree ( new StringReader ( responsePayload ) ) ; } catch ( JsonProcessingException e ) { throw new GroovesharkException . ServerErrorException ( "Failed to parse response - received data was not valid JSON: " + responsePayload ) ; } }<CODESPLIT>Boilerplate to send the request and parse the response payload as JSON .
HashMap < String , T > map = new HashMap < String , T > ( ) ; while ( jsonParser . nextToken ( ) != JsonToken . END_OBJECT ) { String key = jsonParser . getText ( ) ; jsonParser . nextToken ( ) ; if ( jsonParser . getCurrentToken ( ) == JsonToken . VALUE_NULL ) { map . put ( key , null ) ; } else { map . put ( key , parse ( jsonParser ) ) ; } } return map ; }<CODESPLIT>Parse a map of objects from a JsonParser .
date . setTime ( date . getTime ( ) - d . parse ( ) ) ; return this ; }<CODESPLIT>subtract date on supported date
double digit = 1.0 / ( double ) base ; double radical = digit ; double inverse = 0.0 ; while ( i > 0 ) { inverse += digit * ( double ) ( i % base ) ; digit *= radical ; i /= base ; } return inverse ; }<CODESPLIT>Compute the radical inverse of i .
synchronized ( FileUtil . class ) { if ( TEMP_DIR == null ) { String tmpDir = System . getProperty ( "java.io.tmpdir" ) ; if ( StringUtil . isEmpty ( tmpDir ) ) { if ( new File ( "/temp" ) . exists ( ) ) { tmpDir = "/temp" ; } else { tmpDir = "/tmp" ; } } TEMP_DIR = tmpDir ; } } return TEMP_DIR ; }<CODESPLIT>Gets the default temp directory for the system .
Accumulator accumulator = init ; for ( Value value : list ) { accumulator = f . eval ( accumulator , value ) ; } return accumulator ; }<CODESPLIT>Applies a binary function between each element of the given list .
if ( command == null ) { this . throwUnsupportedException ( ) ; } String updatedCommand = command ; if ( this . useWindowsCommandPrefix ) { StringBuilder buffer = new StringBuilder ( updatedCommand . length ( ) + this . windowsCommandPrefix . length ( ) + 1 ) ; buffer . append ( this . windowsCommandPrefix ) ; buffer . append ( " " ) ; buffer . append ( updatedCommand ) ; updatedCommand = buffer . toString ( ) ; } ProcessOutput processOutput = ProcessExecutorHelper . executeProcess ( this , updatedCommand ) ; this . validateProcessOutput ( processOutput , faxActionType ) ; this . updateFaxJob ( faxJob , processOutput , faxActionType ) ; return processOutput ; }<CODESPLIT>Executes the process and returns the output .
final Address address = Address . root ( ) . add ( SUBSYSTEM , SUBSYSTEM_WEB , CONNECTOR , name ) ; return readResource ( address , true ) ; }<CODESPLIT>Returns the connector node with all its attributes . Will be null if it doesn t exist .
@ SuppressWarnings ( "unused" ) int singleByteCharCount = 0 ; int doubleByteCharCount = 0 ; int commonCharCount = 0 ; int badCharCount = 0 ; int totalCharCount = 0 ; int confidence = 0 ; iteratedChar iter = new iteratedChar ( ) ; detectBlock : { for ( iter . reset ( ) ; nextChar ( iter , det ) ; ) { totalCharCount ++ ; if ( iter . error ) { badCharCount ++ ; } else { long cv = iter . charValue & 0xFFFFFFFFL ; if ( cv <= 0xff ) { singleByteCharCount ++ ; } else { doubleByteCharCount ++ ; if ( commonChars != null ) { if ( Arrays . binarySearch ( commonChars , ( int ) cv ) >= 0 ) { commonCharCount ++ ; } } } } if ( badCharCount >= 2 && badCharCount * 5 >= doubleByteCharCount ) { break detectBlock ; } } if ( doubleByteCharCount <= 10 && badCharCount == 0 ) { if ( doubleByteCharCount == 0 && totalCharCount < 10 ) { confidence = 0 ; } else { confidence = 10 ; } break detectBlock ; } if ( doubleByteCharCount < 20 * badCharCount ) { confidence = 0 ; break detectBlock ; } if ( commonChars == null ) { confidence = 30 + doubleByteCharCount - 20 * badCharCount ; if ( confidence > 100 ) { confidence = 100 ; } } else { double maxVal = Math . log ( ( float ) doubleByteCharCount / 4 ) ; double scaleFactor = 90.0 / maxVal ; confidence = ( int ) ( Math . log ( commonCharCount + 1 ) * scaleFactor + 10 ) ; confidence = Math . min ( confidence , 100 ) ; } } return confidence ; }<CODESPLIT>Test the match of this charset with the input text data which is obtained via the CharsetDetector object .
( ( ReshapeMatrix ) dst ) . reshape ( srcY1 - srcY0 , srcX1 - srcX0 ) ; extract ( src , srcY0 , srcY1 , srcX0 , srcX1 , dst , 0 , 0 ) ; }<CODESPLIT>Extract where the destination is reshaped to match the extracted region
checkNotNull ( request . getNewBandwidthInMbps ( ) , "newBandwidthInMbps should not be null" ) ; checkStringNotEmpty ( request . getEip ( ) , "eip should not be empty" ) ; if ( Strings . isNullOrEmpty ( request . getClientToken ( ) ) ) { request . setClientToken ( generateDefaultClientToken ( ) ) ; } InternalRequest internalRequest = this . createRequest ( request , HttpMethodName . PUT , request . getEip ( ) ) ; internalRequest . addParameter ( "resize" , null ) ; internalRequest . addParameter ( CLIENT_TOKEN_IDENTIFY , request . getClientToken ( ) ) ; fillPayload ( internalRequest , request ) ; invokeHttpClient ( internalRequest , AbstractBceResponse . class ) ; }<CODESPLIT>Resizing eip The Prepaid eip can not be downgrade . This is an asynchronous interface .
if ( ++ currentContactSeedBrokerIndex == seedBrokerAddresses . length ) { currentContactSeedBrokerIndex = 0 ; } URL newContactUrl = NetUtils . getCorrectHostnamePort ( seedBrokerAddresses [ currentContactSeedBrokerIndex ] ) ; this . consumer = new SimpleConsumer ( newContactUrl . getHost ( ) , newContactUrl . getPort ( ) , soTimeout , bufferSize , dummyClientId ) ; }<CODESPLIT>Re - establish broker connection using the next available seed broker address .
StringBuilder result = new StringBuilder ( ) ; for ( int i = 0 ; i < value . length ( ) ; ++ i ) { char c = value . charAt ( i ) ; if ( c == ESCAPE_PREFIX ) { String codeString = value . substring ( i + 1 , i + 3 ) ; int code = Integer . parseInt ( codeString , 16 ) ; if ( code < reservedChars . length && reservedChars [ code ] == code ) { result . append ( reservedChars [ code ] ) ; i += 2 ; } else { throw new ServiceLocationException ( "Unknown escaped character " + ESCAPE_PREFIX + codeString + " at position " + ( i + 1 ) + " of " + value , SLPError . PARSE_ERROR ) ; } } else { result . append ( c ) ; } } return result . toString ( ) ; }<CODESPLIT>Unescapes the scope string following RFC 2608 6 . 4 . 1
HashMap ret = new HashMap ( ) ; ArrayList < HashMap > expArr = new ArrayList < HashMap > ( ) ; HashMap < String , HashMap > files = readObvData ( brMap ) ; ArrayList < HashMap > obvData ; HashMap obv ; HashMap expData ; for ( String exname : files . keySet ( ) ) { obvData = ( ArrayList ) files . get ( exname ) . get ( obvDataKey ) ; for ( HashMap obvSub : obvData ) { expData = new HashMap ( ) ; obv = new HashMap ( ) ; copyItem ( expData , files . get ( exname ) , "exname" ) ; copyItem ( expData , files . get ( exname ) , "crid" ) ; copyItem ( expData , files . get ( exname ) , "local_name" ) ; expData . put ( jsonKey , obv ) ; obv . put ( obvFileKey , obvSub . get ( obvDataKey ) ) ; expArr . add ( expData ) ; } } ArrayList idNames = new ArrayList ( ) ; idNames . add ( "trno_t" ) ; removeIndex ( expArr , idNames ) ; ret . put ( "experiments" , expArr ) ; return ret ; }<CODESPLIT>DSSAT TFile Data input method for Controller using
String [ ] delimiters = extractDelimiters ( filter ) ; if ( delimiters == null ) { return FixedStringSearchInterpolator . create ( ) ; } DockerAssemblyConfigurationSource configSource = new DockerAssemblyConfigurationSource ( params , null , null ) ; return AssemblyInterpolator . fullInterpolator ( params . getProject ( ) , DefaultAssemblyReader . createProjectInterpolator ( params . getProject ( ) ) . withExpressionMarkers ( delimiters [ 0 ] , delimiters [ 1 ] ) , configSource ) . withExpressionMarkers ( delimiters [ 0 ] , delimiters [ 1 ] ) ; }<CODESPLIT>Create an interpolator for the given maven parameters and filter configuration .
List < String > children = zk . getChildren ( VoltZK . leaders_initiators , null ) ; List < ZKUtil . ChildrenCallback > childrenCallbacks = Lists . newArrayList ( ) ; for ( String child : children ) { ZKUtil . ChildrenCallback callback = new ZKUtil . ChildrenCallback ( ) ; zk . getChildren ( ZKUtil . joinZKPath ( VoltZK . leaders_initiators , child ) , false , callback , null ) ; childrenCallbacks . add ( callback ) ; } for ( ZKUtil . ChildrenCallback callback : childrenCallbacks ) { if ( callback . get ( ) . isEmpty ( ) ) { return true ; } } return false ; }<CODESPLIT>Checks if the cluster suffered an aborted join or node shutdown and is still in the process of cleaning up .
final byte [ ] data ; if ( ldata instanceof CEMILDataEx ) { final CEMILDataEx ext = ( ( CEMILDataEx ) ldata ) ; final List < AddInfo > additionalInfo = ext . additionalInfo ( ) ; synchronized ( additionalInfo ) { for ( final Iterator < AddInfo > i = additionalInfo . iterator ( ) ; i . hasNext ( ) ; ) { final AddInfo info = i . next ( ) ; if ( ! types . contains ( info . getType ( ) ) ) { logger . warn ( "remove L-Data additional info {}" , info ) ; i . remove ( ) ; } } } } data = ldata . toByteArray ( ) ; data [ 0 ] = 0 ; data [ 1 + data [ 1 ] + 1 ] = 0 ; if ( emptySrc ) { data [ 1 + data [ 1 ] + 3 ] = 0 ; data [ 1 + data [ 1 ] + 4 ] = 0 ; } return data ; }<CODESPLIT>additional info . types provides the list of add . info types we want to keep everything else is removed
int [ ] b = new int [ array . length ] ; for ( int i = 0 ; i < b . length ; i ++ ) { b [ i ] = array [ i ] . intValue ( ) ; } return b ; }<CODESPLIT>Convert any number class to array of integer .
Preconditions . checkArgument ( handle == null || ! handle . isReadOnly ( ) , "Active SegmentChunk handle cannot be readonly." ) ; SegmentChunk last = lastChunk ( ) ; Preconditions . checkState ( last != null , "Cannot set an Active SegmentChunk handle when there are no SegmentChunks." ) ; Preconditions . checkArgument ( handle == null || handle . getSegmentName ( ) . equals ( last . getName ( ) ) , "Active SegmentChunk handle must be for the last SegmentChunk." ) ; this . activeChunkHandle = handle ; }<CODESPLIT>Sets the Active SegmentChunk handle .
if ( Timex3Interval_Type . featOkTst && ( ( Timex3Interval_Type ) jcasType ) . casFeat_emptyValue == null ) jcasType . jcas . throwFeatMissing ( "emptyValue" , "de.unihd.dbs.uima.types.heideltime.Timex3Interval" ) ; return jcasType . ll_cas . ll_getStringValue ( addr , ( ( Timex3Interval_Type ) jcasType ) . casFeatCode_emptyValue ) ; }<CODESPLIT>getter for emptyValue - gets
List < Balance > balances = new ArrayList < > ( ) ; for ( org . knowm . xchange . bitstamp . dto . account . BitstampBalance . Balance b : bitstampBalance . getBalances ( ) ) { Balance xchangeBalance = new Balance ( Currency . getInstance ( b . getCurrency ( ) . toUpperCase ( ) ) , b . getBalance ( ) , b . getAvailable ( ) , b . getReserved ( ) , ZERO , ZERO , b . getBalance ( ) . subtract ( b . getAvailable ( ) ) . subtract ( b . getReserved ( ) ) , ZERO ) ; balances . add ( xchangeBalance ) ; } return new AccountInfo ( userName , bitstampBalance . getFee ( ) , new Wallet ( balances ) ) ; }<CODESPLIT>Adapts a BitstampBalance to an AccountInfo
logger . debug ( "WebSocket closed: {}, Close Status: {}" , session , status . toString ( ) ) ; }<CODESPLIT>Invoked after the web socket connection is closed . You can override this method in the child classes .
String [ ] sections = path . split ( "/" ) ; StringBuilder newPath = new StringBuilder ( "/" ) ; for ( int i = 1 ; i < sections . length - 1 ; i ++ ) { newPath . append ( sections [ i ] ) . append ( "/" ) ; } return newPath . toString ( ) ; }<CODESPLIT>Removes the last part of a file path .
final Style style = new Style ( ) ; style . color = PaletteUtils . getSolidColor ( PaletteUtils . MATERIAL_RED ) ; return style ; }<CODESPLIT>Default material red transparent style for SuperToasts .
Bean < T > bean = null ; EjbDescriptor < T > ejbDescriptor = getEjbDescriptor ( ) ; if ( ! ejbDescriptor . isMessageDriven ( ) ) { bean = getBean ( ) ; } WeldManager beanManager = getBeanManager ( ) ; WeldCreationalContext < T > creationalContext = beanManager . createCreationalContext ( bean ) ; ManagedObjectContext managedObjectContext = new CDIManagedObjectState ( creationalContext ) ; return managedObjectContext ; }<CODESPLIT>This version creates a ManagedObjectContext which contains a CreationalContext for an EJB .
DeleteOperationRequest request = DeleteOperationRequest . newBuilder ( ) . setName ( name ) . build ( ) ; deleteOperation ( request ) ; }<CODESPLIT>Deletes a long - running operation . This method indicates that the client is no longer interested in the operation result . It does not cancel the operation . If the server doesn t support this method it returns google . rpc . Code . UNIMPLEMENTED .
Assert . check ( currentState != BitsState . UNKNOWN ) ; return 0 <= x && x < ( bits . length << wordshift ) && ( bits [ x >>> wordshift ] & ( 1 << ( x & wordmask ) ) ) != 0 ; }<CODESPLIT>Is x an element of this set?
return addHandler ( handler , SearchFinishEvent . TYPE ) ; }<CODESPLIT>This handler will be triggered when search is finish
if ( TraceComponent . isAnyTracingEnabled ( ) && tc . isEntryEnabled ( ) ) { SibTr . entry ( tc , "setForeignBusSendAllowed" , Boolean . valueOf ( sendAllowed ) ) ; } _sendAllowedOnTargetForeignBus = Boolean . valueOf ( sendAllowed ) ; if ( aliasesThatTargetThisDest != null ) { synchronized ( aliasesThatTargetThisDest ) { Iterator i = aliasesThatTargetThisDest . iterator ( ) ; while ( i . hasNext ( ) ) { AbstractAliasDestinationHandler abstractAliasDestinationHandler = ( AbstractAliasDestinationHandler ) i . next ( ) ; abstractAliasDestinationHandler . setForeignBusSendAllowed ( sendAllowed ) ; } } } if ( TraceComponent . isAnyTracingEnabled ( ) && tc . isEntryEnabled ( ) ) { SibTr . exit ( tc , "setForeignBusSendAllowed" ) ; } }<CODESPLIT>Set the Foreign Bus Level sendAllowed flag
if ( documentHandler != null ) documentHandler . processingInstruction ( target , data ) ; }<CODESPLIT>Adapt a SAX2 processing instruction event .
Integer result = null ; String replyString = executeCommandOnFTPServer ( hostName , port , userName , password , "SIZE" , filePath ) ; if ( replyString == null || ! replyString . contains ( " " ) ) { throw new RuntimeException ( String . format ( "Unable to get size of the %s file. Got [%s] reply from FTP server." , filePath , replyString ) ) ; } else { result = Integer . valueOf ( replyString . split ( " " ) [ 1 ] . replaceAll ( "[\r\n]" , "" ) ) ; } return result ; }<CODESPLIT>Get size of the FTP file .
base_responses result = null ; if ( trapname != null && trapname . length > 0 ) { snmpalarm enableresources [ ] = new snmpalarm [ trapname . length ] ; for ( int i = 0 ; i < trapname . length ; i ++ ) { enableresources [ i ] = new snmpalarm ( ) ; enableresources [ i ] . trapname = trapname [ i ] ; } result = perform_operation_bulk_request ( client , enableresources , "enable" ) ; } return result ; }<CODESPLIT>Use this API to enable snmpalarm resources of given names .
TopoSorter < T > sorter = new TopoSorter < > ( this ) ; sorter . ordered ( action ) ; }<CODESPLIT>Traverse this graph and performs the given action in topological order
int d1 = asg . indexOf ( '-' ) ; int d2 = asg . indexOf ( '-' , d1 + 1 ) ; int dN = asg . lastIndexOf ( '-' ) ; if ( dN < 0 || ! isSequence ( asg , dN ) ) { dN = asg . length ( ) ; } return new SeqServerGroup ( asg , d1 , d2 , dN ) ; }<CODESPLIT>Create a new instance of a server group object by parsing the group name .
int numMaps = ( int ) ( srcCount / OP_PER_MAP ) ; numMaps = Math . min ( numMaps , numNodes * MAX_MAPS_PER_NODE ) ; return Math . max ( numMaps , 1 ) ; }<CODESPLIT>Calculate how many maps to run .
switch ( msg . getStatus ( ) ) { case SUCCESS : originalPromise . setSuccess ( ) ; ctx . pipeline ( ) . remove ( this ) ; ctx . fireChannelActive ( ) ; break ; case ACCESS_ERROR : originalPromise . setFailure ( new AuthenticationException ( "Authentication failure on Select Bucket command" ) ) ; break ; case NOTFOUND_ERROR : originalPromise . setFailure ( new AuthenticationException ( "Bucket not found on Select Bucket command" ) ) ; break ; default : originalPromise . setFailure ( new AuthenticationException ( "Unhandled select bucket status: " + msg . getStatus ( ) ) ) ; } }<CODESPLIT>Handles incoming Select bucket responses .
final DiceNotationExpression result ; if ( expression instanceof ExpressionWrapper ) { result = ( ( ExpressionWrapper ) expression ) . getWrappedExpression ( ) ; } else { result = expression ; } return result ; }<CODESPLIT>Removes the expression wrappers used to temporally prune the nodes .
checkNotNull ( value , valueName + " must not be null" ) ; for ( int i = 0 ; i < value . length ; ++ i ) { float v = value [ i ] ; if ( Float . isNaN ( v ) ) { throw new IllegalArgumentException ( valueName + "[" + i + "] must not be NaN" ) ; } else if ( v < lower ) { throw new IllegalArgumentException ( String . format ( "%s[%d] is out of range of [%f, %f] (too low)" , valueName , i , lower , upper ) ) ; } else if ( v > upper ) { throw new IllegalArgumentException ( String . format ( "%s[%d] is out of range of [%f, %f] (too high)" , valueName , i , lower , upper ) ) ; } } return value ; }<CODESPLIT>Ensures that all elements in the argument floating point array are within the inclusive range
copy ( inputStream , outputStream , true ) ; }<CODESPLIT>Writes the content provided by the given source input stream into the given destination output stream .
Collection < Tuple > tuples = new ArrayList < Tuple > ( ) ; for ( int i = varStart ; i < varEnd ; i ++ ) { VarDef nextVar = varDefs . get ( i ) ; Iterator < VarValueDef > values = nextVar . getValidValues ( ) ; if ( ! values . hasNext ( ) ) { throw new IllegalStateException ( "Can't complete tuples -- no valid values defined for var=" + nextVar ) ; } Collection < Tuple > subTuples = tupleSize == 1 ? null : getTuples ( varDefs , i + 1 , varEnd + 1 , tupleSize - 1 ) ; if ( subTuples == null ) { while ( values . hasNext ( ) ) { tuples . add ( new Tuple ( new VarBindingDef ( nextVar , values . next ( ) ) ) ) ; } } else if ( ! subTuples . isEmpty ( ) ) { while ( values . hasNext ( ) ) { VarBindingDef nextBinding = new VarBindingDef ( nextVar , values . next ( ) ) ; for ( Tuple subTuple : subTuples ) { Tuple nextTuple = new Tuple ( nextBinding ) . addAll ( subTuple ) ; if ( nextTuple . isCompatible ( ) ) { tuples . add ( nextTuple ) ; } } } } } return tuples ; }<CODESPLIT>Returns all valid tuples of values for the given input variables .
final int hash = hash ( key ) ; final int slot = indexOf ( hash ) ; for ( Entry < K , V > entry = table [ slot ] ; entry != null ; entry = entry . next ) { if ( entry . hashCode == hash && entry . key . equals ( key ) ) { return entry . value ; } } return null ; }<CODESPLIT>Looks up the value mapped under the given key . Returns null if no value is mapped under this key .
Objects . requireNonNull ( secret , Required . SECRET . toString ( ) ) ; Objects . requireNonNull ( number , Required . TOTP . toString ( ) ) ; return TotpUtils . verifiedTotp ( secret , number ) ; }<CODESPLIT>Checks if a given number for 2FA is valid for the given secret
updateOutgoingEdges ( currS , currL , States . DL , prevS , prevL , States . DL , Transitions . t_DL_in , emission ) ; updateOutgoingEdges ( currS , currL , States . DL , prevS , prevL , States . S , Transitions . t_S_to_DL , emission ) ; }<CODESPLIT>Enumerates the possible transitions into state DL .
PdfName fieldname = new PdfName ( key ) ; PdfObject o = get ( fieldname ) ; if ( o == null ) throw new IllegalArgumentException ( "You must set a value before adding a prefix." ) ; PdfDictionary dict = new PdfDictionary ( PdfName . COLLECTIONSUBITEM ) ; dict . put ( PdfName . D , o ) ; dict . put ( PdfName . P , new PdfString ( prefix , PdfObject . TEXT_UNICODE ) ) ; put ( fieldname , dict ) ; }<CODESPLIT>Adds a prefix for the Collection item . You can only use this method after you have set the value of the item .
assert ( expr != null ) ; if ( expr instanceof TupleValueExpression ) { int paramIdx = ParameterizationInfo . getNextParamIndex ( ) ; ParameterValueExpression pve = new ParameterValueExpression ( paramIdx , expr ) ; m_parameterTveMap . put ( paramIdx , expr ) ; return pve ; } if ( expr instanceof AggregateExpression ) { int paramIdx = ParameterizationInfo . getNextParamIndex ( ) ; ParameterValueExpression pve = new ParameterValueExpression ( paramIdx , expr ) ; List < TupleValueExpression > tves = ExpressionUtil . getTupleValueExpressions ( expr ) ; assert ( m_parentStmt != null ) ; for ( TupleValueExpression tve : tves ) { int origId = tve . getOrigStmtId ( ) ; if ( m_stmtId != origId && m_parentStmt . m_stmtId != origId ) { throw new PlanningErrorException ( "Subqueries do not support aggregation of parent statement columns" ) ; } } m_parameterTveMap . put ( paramIdx , expr ) ; return pve ; } if ( expr . getLeft ( ) != null ) { expr . setLeft ( replaceExpressionsWithPve ( expr . getLeft ( ) ) ) ; } if ( expr . getRight ( ) != null ) { expr . setRight ( replaceExpressionsWithPve ( expr . getRight ( ) ) ) ; } if ( expr . getArgs ( ) != null ) { List < AbstractExpression > newArgs = new ArrayList < > ( ) ; for ( AbstractExpression argument : expr . getArgs ( ) ) { newArgs . add ( replaceExpressionsWithPve ( argument ) ) ; } expr . setArgs ( newArgs ) ; } return expr ; }<CODESPLIT>Helper method to replace all TVEs and aggregated expressions with the corresponding PVEs . The original expressions are placed into the map to be propagated to the EE . The key to the map is the parameter index .
boolean isFirst = false ; List < DelayedCallback > list = BACKLOG . get ( applicationId ) ; if ( null == list ) { list = new ArrayList < DelayedCallback > ( ) ; BACKLOG . put ( applicationId , list ) ; isFirst = true ; } list . add ( callback ) ; return isFirst ; }<CODESPLIT>Add a delayed callback for the given application id . Returns whether this is the first request for the application id .
ByteArrayOutputStream bos = new ByteArrayOutputStream ( ( int ) ( compressedBytes . length * 1.5 ) ) ; InflaterOutputStream dos = new InflaterOutputStream ( bos ) ; dos . write ( compressedBytes ) ; dos . close ( ) ; return bos . toByteArray ( ) ; }<CODESPLIT>to avoid linking all that jazz into the client code
SchemaColumn schemaCol = getSchemaColumn ( index ) ; TupleValueExpression tve = new TupleValueExpression ( getTableAlias ( ) , getTableAlias ( ) , schemaCol . getColumnAlias ( ) , schemaCol . getColumnAlias ( ) , index ) ; return tve ; }<CODESPLIT>Produce a tuple value expression for a column produced by this subquery
